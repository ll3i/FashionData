## ÎìúÎùºÏù¥Î∏å ÎßàÏö¥Ìä∏


```python
import os
import re
import json
import pandas as pd
from collections import defaultdict
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from PIL import Image
import numpy as np
from torchvision import models, transforms
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.metrics import precision_recall_fscore_support, accuracy_score
from tqdm import tqdm

from google.colab import drive
drive.mount('/content/drive')
```

    Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount("/content/drive", force_remount=True).




---



##[1-1]


```python
import os
import pandas as pd
from collections import defaultdict

# Îç∞Ïù¥ÌÑ∞ Ìè¥Îçî Í≤ΩÎ°ú ÏÑ§Ï†ï
directories = {
    'training': '/content/drive/MyDrive/dataset/training_image',
    'validation': '/content/drive/MyDrive/dataset/validation_image'
}

# Í∞Å Ìè¥ÎçîÎ≥Ñ ÏßëÍ≥Ñ Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† ÎîïÏÖîÎÑàÎ¶¨
folder_results = {}

# Í∞Å Ìè¥ÎçîÏóê ÎåÄÌï¥ Ïù¥ÎØ∏ÏßÄ Í∞úÏàòÎ•º ÏßëÍ≥Ñ
for folder_name, directory in directories.items():
    # ÏÑ±Î≥Ñ Î∞è Ïä§ÌÉÄÏùºÎ≥Ñ Ïù¥ÎØ∏ÏßÄ Í∞úÏàòÎ•º Ï†ÄÏû•Ìï† Íµ¨Ï°∞
    image_count = defaultdict(lambda: defaultdict(int))  # Ï§ëÏ≤©Îêú ÎîïÏÖîÎÑàÎ¶¨ Íµ¨Ï°∞: {ÏÑ±Î≥Ñ: {Ïä§ÌÉÄÏùº: Ïù¥ÎØ∏ÏßÄ Ïàò}}
    total_images = 0  # Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ ÏàòÎ•º Ï†ÄÏû•Ìï† Î≥ÄÏàò

    # ÌååÏùº Ïù¥Î¶ÑÏóêÏÑú ÏÑ±Î≥ÑÍ≥º Ïä§ÌÉÄÏùºÏùÑ Ï∂îÏ∂úÌïòÏó¨ ÌÜµÍ≥Ñ ÎÇ¥Í∏∞
    for filename in os.listdir(directory):
        if filename.endswith('.jpg'):  # JPG ÌååÏùºÎßå Ï≤òÎ¶¨
            parts = filename.split('_')  # ÌååÏùºÎ™ÖÏùÑ '_'Î°ú Î∂ÑÌï†
            # ÏÑ±Î≥ÑÍ≥º Ïä§ÌÉÄÏùº Ï†ïÎ≥¥ Ï∂îÏ∂ú
            gender_identifier = parts[-1][0]  # ÎßàÏßÄÎßâ Î∂ÄÎ∂ÑÏùò Ï≤´ Í∏ÄÏûê (W or T)
            style = parts[3]  # ÎÑ§ Î≤àÏß∏ Î∂ÄÎ∂ÑÏùÄ Ïä§ÌÉÄÏùº Ï†ïÎ≥¥
            # ÏÑ±Î≥ÑÏùÑ 'Ïó¨ÏÑ±' / 'ÎÇ®ÏÑ±'ÏúºÎ°ú Î≥ÄÌôò
            gender = 'Ïó¨ÏÑ±' if gender_identifier == 'W' else 'ÎÇ®ÏÑ±'
            # ÏÑ±Î≥ÑÍ≥º Ïä§ÌÉÄÏùºÏùò Ïù¥ÎØ∏ÏßÄ ÏàòÎ•º ÏßëÍ≥Ñ
            image_count[gender][style] += 1
            total_images += 1  # Ï†ÑÏ≤¥ Ïù¥ÎØ∏ÏßÄ Ïàò Ï¶ùÍ∞Ä

    # DataFrameÏúºÎ°ú Î≥ÄÌôò
    data = []
    for gender, styles in image_count.items():
        for style, count in styles.items():
            data.append([gender, style, count])

    df = pd.DataFrame(data, columns=['ÏÑ±Î≥Ñ', 'Ïä§ÌÉÄÏùº', 'Ïù¥ÎØ∏ÏßÄ Ïàò'])

    # ÏòàÏÅòÍ≤å Ï∂úÎ†•
    df_sorted = df.sort_values(by=['ÏÑ±Î≥Ñ', 'Ïä§ÌÉÄÏùº']).reset_index(drop=True)

    # Ìè¥ÎçîÎ≥Ñ ÏßëÍ≥Ñ Í≤∞Í≥º Ï†ÄÏû•
    folder_results[folder_name] = {
        'total_images': total_images,
        'df': df_sorted
    }

# Í∞Å Ìè¥ÎçîÏùò Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò Î∞è DataFrame Ï∂úÎ†•
for folder_name, results in folder_results.items():
    print(f"{folder_name.capitalize()} Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî")
    print(f"Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò: {results['total_images']}")
    display(results['df'])
    print("\n" + "="*50 + "\n")

```

    Training Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî
    Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò: 4070




  <div id="df-8afca888-c4aa-443e-ad8f-78b849582200" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ÏÑ±Î≥Ñ</th>
      <th>Ïä§ÌÉÄÏùº</th>
      <th>Ïù¥ÎØ∏ÏßÄ Ïàò</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>bold</td>
      <td>268</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hiphop</td>
      <td>274</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hippie</td>
      <td>260</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>ivy</td>
      <td>237</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>metrosexual</td>
      <td>278</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>mods</td>
      <td>269</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>normcore</td>
      <td>364</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>sportivecasual</td>
      <td>298</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Ïó¨ÏÑ±</td>
      <td>athleisure</td>
      <td>67</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Ïó¨ÏÑ±</td>
      <td>bodyconscious</td>
      <td>95</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Ïó¨ÏÑ±</td>
      <td>cityglam</td>
      <td>67</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Ïó¨ÏÑ±</td>
      <td>classic</td>
      <td>77</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Ïó¨ÏÑ±</td>
      <td>disco</td>
      <td>37</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Ïó¨ÏÑ±</td>
      <td>ecology</td>
      <td>64</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Ïó¨ÏÑ±</td>
      <td>feminine</td>
      <td>154</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Ïó¨ÏÑ±</td>
      <td>genderless</td>
      <td>77</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Ïó¨ÏÑ±</td>
      <td>grunge</td>
      <td>31</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hiphop</td>
      <td>48</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hippie</td>
      <td>91</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Ïó¨ÏÑ±</td>
      <td>kitsch</td>
      <td>91</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lingerie</td>
      <td>55</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lounge</td>
      <td>45</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Ïó¨ÏÑ±</td>
      <td>military</td>
      <td>33</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Ïó¨ÏÑ±</td>
      <td>minimal</td>
      <td>139</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Ïó¨ÏÑ±</td>
      <td>normcore</td>
      <td>153</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Ïó¨ÏÑ±</td>
      <td>oriental</td>
      <td>78</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Ïó¨ÏÑ±</td>
      <td>popart</td>
      <td>41</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Ïó¨ÏÑ±</td>
      <td>powersuit</td>
      <td>120</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Ïó¨ÏÑ±</td>
      <td>punk</td>
      <td>65</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Ïó¨ÏÑ±</td>
      <td>space</td>
      <td>37</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Ïó¨ÏÑ±</td>
      <td>sportivecasual</td>
      <td>157</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-8afca888-c4aa-443e-ad8f-78b849582200')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-8afca888-c4aa-443e-ad8f-78b849582200 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-8afca888-c4aa-443e-ad8f-78b849582200');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-bb7f62c1-7222-46b6-8d35-80b4eaa3ac33">
  <button class="colab-df-quickchart" onclick="quickchart('df-bb7f62c1-7222-46b6-8d35-80b4eaa3ac33')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-bb7f62c1-7222-46b6-8d35-80b4eaa3ac33 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

    </div>
  </div>



    
    ==================================================
    
    Validation Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî
    Ï¥ù Ïù¥ÎØ∏ÏßÄ Ïàò: 951




  <div id="df-d6ea3087-b274-4d10-96d4-59054ffe9950" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ÏÑ±Î≥Ñ</th>
      <th>Ïä§ÌÉÄÏùº</th>
      <th>Ïù¥ÎØ∏ÏßÄ Ïàò</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>bold</td>
      <td>57</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hiphop</td>
      <td>66</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hippie</td>
      <td>82</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>ivy</td>
      <td>79</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>metrosexual</td>
      <td>58</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>mods</td>
      <td>80</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>normcore</td>
      <td>51</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>sportivecasual</td>
      <td>52</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Ïó¨ÏÑ±</td>
      <td>athleisure</td>
      <td>14</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Ïó¨ÏÑ±</td>
      <td>bodyconscious</td>
      <td>23</td>
    </tr>
    <tr>
      <th>10</th>
      <td>Ïó¨ÏÑ±</td>
      <td>cityglam</td>
      <td>18</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Ïó¨ÏÑ±</td>
      <td>classic</td>
      <td>22</td>
    </tr>
    <tr>
      <th>12</th>
      <td>Ïó¨ÏÑ±</td>
      <td>disco</td>
      <td>10</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Ïó¨ÏÑ±</td>
      <td>ecology</td>
      <td>17</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Ïó¨ÏÑ±</td>
      <td>feminine</td>
      <td>44</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Ïó¨ÏÑ±</td>
      <td>genderless</td>
      <td>12</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Ïó¨ÏÑ±</td>
      <td>grunge</td>
      <td>10</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hiphop</td>
      <td>8</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hippie</td>
      <td>14</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Ïó¨ÏÑ±</td>
      <td>kitsch</td>
      <td>22</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lingerie</td>
      <td>5</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lounge</td>
      <td>8</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Ïó¨ÏÑ±</td>
      <td>military</td>
      <td>9</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Ïó¨ÏÑ±</td>
      <td>minimal</td>
      <td>35</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Ïó¨ÏÑ±</td>
      <td>normcore</td>
      <td>20</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Ïó¨ÏÑ±</td>
      <td>oriental</td>
      <td>18</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Ïó¨ÏÑ±</td>
      <td>popart</td>
      <td>8</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Ïó¨ÏÑ±</td>
      <td>powersuit</td>
      <td>34</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Ïó¨ÏÑ±</td>
      <td>punk</td>
      <td>12</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Ïó¨ÏÑ±</td>
      <td>space</td>
      <td>15</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Ïó¨ÏÑ±</td>
      <td>sportivecasual</td>
      <td>48</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-d6ea3087-b274-4d10-96d4-59054ffe9950')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-d6ea3087-b274-4d10-96d4-59054ffe9950 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-d6ea3087-b274-4d10-96d4-59054ffe9950');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-6834cd1a-f04d-414b-9cef-a14532977263">
  <button class="colab-df-quickchart" onclick="quickchart('df-6834cd1a-f04d-414b-9cef-a14532977263')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-6834cd1a-f04d-414b-9cef-a14532977263 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_87553301-50d1-4bac-94d9-670c6d8b89f3">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('df_sorted')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_87553301-50d1-4bac-94d9-670c6d8b89f3 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('df_sorted');
      }
      })();
    </script>
  </div>

    </div>
  </div>



    
    ==================================================
    




---



##[1-2]


```python
!pip install torch_optimizer

```

    Collecting torch_optimizer
      Downloading torch_optimizer-0.3.0-py3-none-any.whl.metadata (55 kB)
    [?25l     [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m0.0/55.9 kB[0m [31m?[0m eta [36m-:--:--[0m[2K     [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m55.9/55.9 kB[0m [31m5.4 MB/s[0m eta [36m0:00:00[0m
    [?25hRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torch_optimizer) (2.4.1+cu121)
    Collecting pytorch-ranger>=0.1.1 (from torch_optimizer)
      Downloading pytorch_ranger-0.1.1-py3-none-any.whl.metadata (509 bytes)
    Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.16.1)
    Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (4.12.2)
    Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (1.13.3)
    Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.3)
    Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (3.1.4)
    Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torch_optimizer) (2024.6.1)
    Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torch_optimizer) (2.1.5)
    Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.5.0->torch_optimizer) (1.3.0)
    Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)
    [2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m61.9/61.9 kB[0m [31m5.6 MB/s[0m eta [36m0:00:00[0m
    [?25hDownloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)
    Installing collected packages: pytorch-ranger, torch_optimizer
    Successfully installed pytorch-ranger-0.1.1 torch_optimizer-0.3.0



```python
import torch
import torch.nn as nn
from torch.optim import lr_scheduler
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms, models
from PIL import Image
import os
import torch_optimizer as optim  # torch_optimizer ÎùºÏù¥Î∏åÎü¨Î¶¨ ÏÇ¨Ïö©

# CUDA ÏÇ¨Ïö© Í∞ÄÎä• Ïó¨Î∂Ä ÌôïÏù∏
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ÌÅ¥ÎûòÏä§ Î™©Î°ù (ÏÑ±Î≥Ñ + Ïä§ÌÉÄÏùº Ï°∞Ìï©ÏúºÎ°ú Íµ¨ÏÑ±)
fashion_classes = [
    "ÎÇ®ÏÑ±_bold", "ÎÇ®ÏÑ±_hiphop", "ÎÇ®ÏÑ±_hippie", "ÎÇ®ÏÑ±_ivy", "ÎÇ®ÏÑ±_metrosexual",
    "ÎÇ®ÏÑ±_mods", "ÎÇ®ÏÑ±_normcore", "ÎÇ®ÏÑ±_sportivecasual", "Ïó¨ÏÑ±_athleisure",
    "Ïó¨ÏÑ±_bodyconscious", "Ïó¨ÏÑ±_cityglam", "Ïó¨ÏÑ±_classic", "Ïó¨ÏÑ±_disco",
    "Ïó¨ÏÑ±_ecology", "Ïó¨ÏÑ±_feminine", "Ïó¨ÏÑ±_genderless", "Ïó¨ÏÑ±_grunge",
    "Ïó¨ÏÑ±_hiphop", "Ïó¨ÏÑ±_hippie", "Ïó¨ÏÑ±_kitsch", "Ïó¨ÏÑ±_lingerie",
    "Ïó¨ÏÑ±_lounge", "Ïó¨ÏÑ±_military", "Ïó¨ÏÑ±_minimal", "Ïó¨ÏÑ±_normcore",
    "Ïó¨ÏÑ±_oriental", "Ïó¨ÏÑ±_popart", "Ïó¨ÏÑ±_powersuit", "Ïó¨ÏÑ±_punk",
    "Ïó¨ÏÑ±_space", "Ïó¨ÏÑ±_sportivecasual"
]

# Ïä§ÌÉÄÏùº Îß§Ìïë (Í∞Å ÌÅ¥ÎûòÏä§ Ï°∞Ìï©ÏùÑ Ïà´ÏûêÎ°ú Îß§Ìïë)
style_mapping = {style: idx for idx, style in enumerate(fashion_classes)}

# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§ Ï†ïÏùò
class CustomImageDataset(Dataset):
    def __init__(self, image_folder, transform=None):
        self.image_folder = image_folder
        self.image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder)]
        self.transform = transform
        self.labels = []

        # ÌååÏùºÎ™ÖÏóêÏÑú ÏÑ±Î≥Ñ Î∞è Ïä§ÌÉÄÏùº Î†àÏù¥Î∏î Ï∂îÏ∂ú
        for img in self.image_paths:
            fname = os.path.basename(img)
            parts = fname.split('_')
            gender = parts[-1].split('.')[0]  # ÏÑ±Î≥Ñ Ï∂îÏ∂ú ('M' ÎòêÎäî 'W')
            style = parts[-2]  # Ïä§ÌÉÄÏùº Ï∂îÏ∂ú

            gender_label = "ÎÇ®ÏÑ±" if gender == 'M' else "Ïó¨ÏÑ±"
            label = f"{gender_label}_{style}"  # ÏÑ±Î≥Ñ + Ïä§ÌÉÄÏùº Ï°∞Ìï©
            style_label = style_mapping.get(label, -1)  # Ïä§ÌÉÄÏùº Îß§Ìïë

            if style_label != -1:
                self.labels.append(style_label)

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        img_path = self.image_paths[idx]
        img = Image.open(img_path).convert("RGB")

        if self.transform:
            img = self.transform(img)

        label = self.labels[idx]
        return img, label

# Ìä∏Î†àÏù¥Îãù Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï Í∞ïÌôî
train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(),  # Ï¢åÏö∞ Îí§ÏßëÍ∏∞
    transforms.RandomRotation(degrees=30),  # ÌöåÏ†Ñ Î≤îÏúÑ Ï¶ùÍ∞Ä
    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # ÏÉâÏÉÅ Ï°∞Ï†ï
    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Î¨¥ÏûëÏúÑ ÏûêÎ•¥Í∏∞ Î∞è Î¶¨ÏÇ¨Ïù¥Ï¶à
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ï¶ùÍ∞ï Ï†úÍ±∞
val_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Ìä∏Î†àÏù¥Îãù Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú
train_dataset = CustomImageDataset('/content/drive/MyDrive/dataset/processed_segmentation_cleaned', transform=train_transform)

# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÏÖã Î°úÎìú (Î≥ÑÎèÑÏùò Í≤ÄÏ¶ù Ïù¥ÎØ∏ÏßÄ Ìè¥Îçî ÏÇ¨Ïö©)
val_dataset = CustomImageDataset('/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val', transform=val_transform)

# Îç∞Ïù¥ÌÑ∞ Î°úÎçî ÏÑ§Ï†ï
train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False)

# ResNet-18 Í∏∞Î∞ò Ìå®ÏÖò Ïä§ÌÉÄÏùº Î∞è ÏÑ±Î≥Ñ ÏòàÏ∏° Î™®Îç∏
class FashionGenderModel(nn.Module):
    def __init__(self, num_classes=31):  # Ï¥ù 31Í∞úÏùò ÌÅ¥ÎûòÏä§
        super(FashionGenderModel, self).__init__()
        self.resnet = models.resnet18(weights=None)  # Pretrained weights ÏÇ¨Ïö© Ïïà Ìï®
        self.resnet.fc = nn.Identity()  # ResNetÏùò Í∏∞Î≥∏ fully connected Î†àÏù¥Ïñ¥Î•º Ï†úÍ±∞

        # 31Í∞ú ÌÅ¥ÎûòÏä§(ÏÑ±Î≥Ñ + Ïä§ÌÉÄÏùº Ï°∞Ìï©)Î•º ÏúÑÌïú Ï∂úÎ†• Î†àÏù¥Ïñ¥ Ï∂îÍ∞Ä
        self.fc = nn.Linear(512, num_classes)
        self.dropout = nn.Dropout(p=0.4)  # Dropout ÎπÑÏú® Ï°∞Ï†ï (0.4)

    def forward(self, x):
        x = self.resnet(x)
        x = self.dropout(x)
        out = self.fc(x)  # 31Í∞ú ÌÅ¥ÎûòÏä§ ÏòàÏ∏°
        return out

# Î™®Îç∏, ÏÜêÏã§ Ìï®Ïàò, ÏòµÌã∞ÎßàÏù¥Ï†Ä, Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
model = FashionGenderModel(num_classes=31).to(device)  # Î™®Îç∏ÏùÑ CUDAÎ°ú Ïù¥Îèô
criterion = nn.CrossEntropyLoss()  # ÌïòÎÇòÏùò CrossEntropyLoss ÏÇ¨Ïö©

# AdamP ÏòµÌã∞ÎßàÏù¥Ï†Ä ÏÑ§Ï†ï
optimizer = optim.AdamP(model.parameters(), lr=0.005, weight_decay=0.02)

# ÌïôÏäµÎ•† Ïä§ÏºÄÏ§ÑÎü¨ ÏÑ§Ï†ï
scheduler = lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)

# Î™®Îç∏ ÌïôÏäµ Ìï®Ïàò
def train_model(train_loader, val_loader, model, optimizer, criterion, scheduler, epochs=300, save_path='/content/drive/MyDrive/ÏßÑÌÇ¥/model_final5.pth', start_epoch=0):
    best_val_accuracy = 0.0  # ÏµúÏÉÅÏùò Í≤ÄÏ¶ù Ï†ïÌôïÎèÑÎ•º Ï†ÄÏû•ÌïòÍ∏∞ ÏúÑÌïú Î≥ÄÏàò

    # Ï†ÄÏû•Îêú Î™®Îç∏Ïù¥ ÏûàÎäî Í≤ΩÏö∞ Î∂àÎü¨Ïò§Í∏∞
    if os.path.exists(save_path):
        print(f"Loading saved model from {save_path}...")
        model.load_state_dict(torch.load(save_path))
        print("Model loaded successfully!")

    for epoch in range(start_epoch, epochs):
        model.train()
        total_train_loss = 0
        correct_train = 0
        total_train = 0

        # ÌïôÏäµ Îã®Í≥Ñ
        for images, labels in train_loader:
            images = images.to(device)  # Îç∞Ïù¥ÌÑ∞Î•º CUDAÎ°ú Ïù¥Îèô
            labels = labels.to(device)

            optimizer.zero_grad()

            # Î™®Îç∏ ÏòàÏ∏°
            outputs = model(images)

            # ÏÜêÏã§ Í≥ÑÏÇ∞
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            total_train_loss += loss.item()

            # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞
            _, predicted = torch.max(outputs, 1)
            correct_train += (predicted == labels).sum().item()
            total_train += labels.size(0)

        train_accuracy = correct_train / total_train

        # Í≤ÄÏ¶ù Îã®Í≥Ñ
        model.eval()
        total_val_loss = 0
        correct_val = 0
        total_val = 0
        with torch.no_grad():
            for val_images, val_labels in val_loader:
                val_images = val_images.to(device)  # Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ÎèÑ CUDAÎ°ú Ïù¥Îèô
                val_labels = val_labels.to(device)

                val_outputs = model(val_images)

                val_loss = criterion(val_outputs, val_labels)
                total_val_loss += val_loss.item()

                _, val_predicted = torch.max(val_outputs, 1)
                correct_val += (val_predicted == val_labels).sum().item()
                total_val += val_labels.size(0)

        val_accuracy = correct_val / total_val

        # ÌïôÏäµÎ•†ÏùÑ ÌçºÏÑºÌä∏Î°ú ÌëúÏãú
        lr_percent = optimizer.param_groups[0]['lr'] * 100
        scheduler.step()

        # ÏóêÌè¨ÌÅ¨ ÎßàÎã§ Ï∂úÎ†•
        print(f'Epoch {epoch+1}, Train Loss: {total_train_loss / len(train_loader):.4f}, '
              f'Train Accuracy: {train_accuracy * 100:.2f}%, '
              f'Validation Loss: {total_val_loss / len(val_loader):.4f}, '
              f'Validation Accuracy: {val_accuracy * 100:.2f}%, '
              f'Learning Rate: {lr_percent:.2f}%')
        # ÏµúÏÉÅÏùò Í≤ÄÏ¶ù Ï†ïÌôïÎèÑÎ•º Í∞ÄÏßÑ Î™®Îç∏ Ï†ÄÏû•
        if val_accuracy > best_val_accuracy:
            best_val_accuracy = val_accuracy
            torch.save(model.state_dict(), save_path)
            print(f'Model saved with Validation Accuracy: {val_accuracy * 100:.2f}%')

# Î™®Îç∏ ÌïôÏäµ ÏãúÏûë
train_model(train_loader, val_loader, model, optimizer, criterion, scheduler, epochs=300, save_path='/content/drive/MyDrive/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö≥·ÑÖ·Öµ·Ñã·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö¢·Ü∑·Ñë·Ö≥ ·Ñé·Ö¨·Ñå·Ö©·Üº ·Ñå·Ö•·Üº·ÑÖ·Öµ/·ÑÄ·Öµ·Ü∑·Ñå·Öµ·Ü´/model_final5.pth')

```

    Loading saved model from /content/drive/MyDrive/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö≥·ÑÖ·Öµ·Ñã·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö¢·Ü∑·Ñë·Ö≥ ·Ñé·Ö¨·Ñå·Ö©·Üº ·Ñå·Ö•·Üº·ÑÖ·Öµ/·ÑÄ·Öµ·Ü∑·Ñå·Öµ·Ü´/model_final5.pth...


    <ipython-input-5-a9d2595e4d2d>:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
      model.load_state_dict(torch.load(save_path))


    Model loaded successfully!
    Epoch 1, Train Loss: 0.9508, Train Accuracy: 71.62%, Validation Loss: 3.3253, Validation Accuracy: 37.22%, Learning Rate: 0.50%
    Model saved with Validation Accuracy: 37.22%
    Epoch 2, Train Loss: 0.7871, Train Accuracy: 75.06%, Validation Loss: 2.4328, Validation Accuracy: 50.89%, Learning Rate: 0.49%
    Model saved with Validation Accuracy: 50.89%
    Epoch 3, Train Loss: 0.6034, Train Accuracy: 81.11%, Validation Loss: 2.3584, Validation Accuracy: 54.36%, Learning Rate: 0.45%
    Model saved with Validation Accuracy: 54.36%
    Epoch 4, Train Loss: 0.5124, Train Accuracy: 83.96%, Validation Loss: 2.3095, Validation Accuracy: 58.57%, Learning Rate: 0.40%
    Model saved with Validation Accuracy: 58.57%
    Epoch 5, Train Loss: 0.4264, Train Accuracy: 86.93%, Validation Loss: 2.5402, Validation Accuracy: 57.73%, Learning Rate: 0.33%
    Epoch 6, Train Loss: 0.3088, Train Accuracy: 90.93%, Validation Loss: 2.1602, Validation Accuracy: 61.51%, Learning Rate: 0.25%
    Model saved with Validation Accuracy: 61.51%
    Epoch 7, Train Loss: 0.2035, Train Accuracy: 94.20%, Validation Loss: 2.2680, Validation Accuracy: 63.30%, Learning Rate: 0.17%
    Model saved with Validation Accuracy: 63.30%
    Epoch 8, Train Loss: 0.1645, Train Accuracy: 94.99%, Validation Loss: 4.4736, Validation Accuracy: 26.08%, Learning Rate: 0.10%
    Epoch 9, Train Loss: 0.1198, Train Accuracy: 96.86%, Validation Loss: 2.2251, Validation Accuracy: 63.30%, Learning Rate: 0.05%
    Epoch 10, Train Loss: 0.1087, Train Accuracy: 97.13%, Validation Loss: 2.2258, Validation Accuracy: 63.20%, Learning Rate: 0.01%
    Epoch 11, Train Loss: 0.3528, Train Accuracy: 89.73%, Validation Loss: 2.9792, Validation Accuracy: 55.73%, Learning Rate: 0.50%
    Epoch 12, Train Loss: 1.1495, Train Accuracy: 66.14%, Validation Loss: 2.6674, Validation Accuracy: 41.01%, Learning Rate: 0.49%
    Epoch 13, Train Loss: 1.2031, Train Accuracy: 63.39%, Validation Loss: 2.1395, Validation Accuracy: 45.64%, Learning Rate: 0.45%
    Epoch 14, Train Loss: 0.8104, Train Accuracy: 75.28%, Validation Loss: 8.1862, Validation Accuracy: 7.68%, Learning Rate: 0.40%
    Epoch 15, Train Loss: 0.5830, Train Accuracy: 81.45%, Validation Loss: 2.0214, Validation Accuracy: 58.36%, Learning Rate: 0.33%
    Epoch 16, Train Loss: 0.3965, Train Accuracy: 88.18%, Validation Loss: 2.0297, Validation Accuracy: 61.51%, Learning Rate: 0.25%
    Epoch 17, Train Loss: 0.2615, Train Accuracy: 92.56%, Validation Loss: 2.0045, Validation Accuracy: 62.46%, Learning Rate: 0.17%
    Epoch 18, Train Loss: 0.1805, Train Accuracy: 95.01%, Validation Loss: 2.0184, Validation Accuracy: 62.88%, Learning Rate: 0.10%
    Epoch 19, Train Loss: 0.1394, Train Accuracy: 96.54%, Validation Loss: 2.0235, Validation Accuracy: 63.72%, Learning Rate: 0.05%
    Model saved with Validation Accuracy: 63.72%
    Epoch 20, Train Loss: 0.1271, Train Accuracy: 96.34%, Validation Loss: 2.0356, Validation Accuracy: 63.51%, Learning Rate: 0.01%


    ERROR:root:Internal Python error in the inspect module.
    Below is the traceback from this internal error.
    
    
    KeyboardInterrupt
    


## ÌòÑÏû¨ Í≤∞Í≥ºÎäî Ïû¨Î°úÎìúÎêú Î™®Îç∏ p

## BEST SCORE => 64.14%

## 1~210 ÏóêÌè≠ Ïã§Ìñâ Í≤∞Í≥º.

Epoch 1, Train Loss: 3.4663, Train Accuracy: 7.32%, Validation Loss: 3.1772, Validation Accuracy: 10.09%, Learning Rate: 0.50%
Model saved with Validation Accuracy: 10.09%
Epoch 2, Train Loss: 3.2314, Train Accuracy: 8.82%, Validation Loss: 3.1504, Validation Accuracy: 6.73%, Learning Rate: 0.49%
Epoch 3, Train Loss: 3.1916, Train Accuracy: 8.97%, Validation Loss: 3.1084, Validation Accuracy: 8.94%, Learning Rate: 0.45%
Epoch 4, Train Loss: 3.1679, Train Accuracy: 8.94%, Validation Loss: 3.1160, Validation Accuracy: 8.94%, Learning Rate: 0.40%
Epoch 5, Train Loss: 3.1495, Train Accuracy: 9.53%, Validation Loss: 3.0940, Validation Accuracy: 7.47%, Learning Rate: 0.33%
Epoch 6, Train Loss: 3.1186, Train Accuracy: 9.68%, Validation Loss: 3.0751, Validation Accuracy: 10.62%, Learning Rate: 0.25%
Model saved with Validation Accuracy: 10.62%
Epoch 7, Train Loss: 3.1092, Train Accuracy: 10.00%, Validation Loss: 3.0494, Validation Accuracy: 10.30%, Learning Rate: 0.17%
Epoch 8, Train Loss: 3.0825, Train Accuracy: 10.98%, Validation Loss: 3.0716, Validation Accuracy: 9.67%, Learning Rate: 0.10%
Epoch 9, Train Loss: 3.0612, Train Accuracy: 11.15%, Validation Loss: 3.0390, Validation Accuracy: 11.15%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 11.15%
Epoch 10, Train Loss: 3.0398, Train Accuracy: 11.62%, Validation Loss: 3.0220, Validation Accuracy: 11.99%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 11.99%
Epoch 11, Train Loss: 3.1480, Train Accuracy: 8.94%, Validation Loss: 3.1235, Validation Accuracy: 7.36%, Learning Rate: 0.50%
Epoch 12, Train Loss: 3.1314, Train Accuracy: 9.46%, Validation Loss: 3.0657, Validation Accuracy: 8.73%, Learning Rate: 0.49%
Epoch 13, Train Loss: 3.1154, Train Accuracy: 10.22%, Validation Loss: 3.1156, Validation Accuracy: 6.83%, Learning Rate: 0.45%
Epoch 14, Train Loss: 3.1076, Train Accuracy: 9.75%, Validation Loss: 3.1239, Validation Accuracy: 5.78%, Learning Rate: 0.40%
Epoch 15, Train Loss: 3.0853, Train Accuracy: 10.10%, Validation Loss: 3.0584, Validation Accuracy: 11.25%, Learning Rate: 0.33%
Epoch 16, Train Loss: 3.0768, Train Accuracy: 10.96%, Validation Loss: 3.7500, Validation Accuracy: 9.04%, Learning Rate: 0.25%
Epoch 17, Train Loss: 3.0523, Train Accuracy: 11.33%, Validation Loss: 2.9880, Validation Accuracy: 12.20%, Learning Rate: 0.17%
Model saved with Validation Accuracy: 12.20%
Epoch 18, Train Loss: 3.0221, Train Accuracy: 11.15%, Validation Loss: 2.9888, Validation Accuracy: 11.57%, Learning Rate: 0.10%
Epoch 19, Train Loss: 2.9889, Train Accuracy: 12.11%, Validation Loss: 3.0026, Validation Accuracy: 11.88%, Learning Rate: 0.05%
Epoch 20, Train Loss: 2.9598, Train Accuracy: 13.00%, Validation Loss: 2.9678, Validation Accuracy: 12.30%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 12.30%
Epoch 21, Train Loss: 3.1093, Train Accuracy: 9.83%, Validation Loss: 3.1159, Validation Accuracy: 9.15%, Learning Rate: 0.50%
Epoch 22, Train Loss: 3.1044, Train Accuracy: 10.32%, Validation Loss: 3.1442, Validation Accuracy: 10.30%, Learning Rate: 0.49%
Epoch 23, Train Loss: 3.0878, Train Accuracy: 10.20%, Validation Loss: 3.0245, Validation Accuracy: 11.04%, Learning Rate: 0.45%
Epoch 24, Train Loss: 3.0555, Train Accuracy: 11.62%, Validation Loss: 3.2219, Validation Accuracy: 9.25%, Learning Rate: 0.40%
Epoch 25, Train Loss: 3.0235, Train Accuracy: 11.35%, Validation Loss: 3.1496, Validation Accuracy: 11.99%, Learning Rate: 0.33%
Epoch 26, Train Loss: 3.0166, Train Accuracy: 11.77%, Validation Loss: 3.0155, Validation Accuracy: 10.94%, Learning Rate: 0.25%
Epoch 27, Train Loss: 2.9613, Train Accuracy: 13.96%, Validation Loss: 2.9157, Validation Accuracy: 13.88%, Learning Rate: 0.17%
Model saved with Validation Accuracy: 13.88%
Epoch 28, Train Loss: 2.9423, Train Accuracy: 13.51%, Validation Loss: 2.9462, Validation Accuracy: 13.25%, Learning Rate: 0.10%
Epoch 29, Train Loss: 2.9006, Train Accuracy: 15.18%, Validation Loss: 2.8681, Validation Accuracy: 14.72%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 14.72%
Epoch 30, Train Loss: 2.8622, Train Accuracy: 14.67%, Validation Loss: 2.8456, Validation Accuracy: 15.25%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 15.25%
Epoch 31, Train Loss: 3.0743, Train Accuracy: 10.49%, Validation Loss: 3.2270, Validation Accuracy: 7.99%, Learning Rate: 0.50%
Epoch 32, Train Loss: 3.0405, Train Accuracy: 11.23%, Validation Loss: 3.5236, Validation Accuracy: 8.41%, Learning Rate: 0.49%
Epoch 33, Train Loss: 3.0282, Train Accuracy: 11.84%, Validation Loss: 3.5930, Validation Accuracy: 6.52%, Learning Rate: 0.45%
Epoch 34, Train Loss: 3.0125, Train Accuracy: 11.89%, Validation Loss: 3.3190, Validation Accuracy: 7.26%, Learning Rate: 0.40%
Epoch 35, Train Loss: 2.9919, Train Accuracy: 11.77%, Validation Loss: 3.0180, Validation Accuracy: 11.67%, Learning Rate: 0.33%
Epoch 36, Train Loss: 2.9532, Train Accuracy: 12.63%, Validation Loss: 2.9305, Validation Accuracy: 13.99%, Learning Rate: 0.25%
Epoch 37, Train Loss: 2.9008, Train Accuracy: 13.32%, Validation Loss: 3.0025, Validation Accuracy: 13.14%, Learning Rate: 0.17%
Epoch 38, Train Loss: 2.8536, Train Accuracy: 14.86%, Validation Loss: 2.8455, Validation Accuracy: 14.62%, Learning Rate: 0.10%
Epoch 39, Train Loss: 2.7994, Train Accuracy: 15.97%, Validation Loss: 2.7802, Validation Accuracy: 17.14%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 17.14%
Epoch 40, Train Loss: 2.7609, Train Accuracy: 17.76%, Validation Loss: 2.7348, Validation Accuracy: 18.61%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 18.61%
Epoch 41, Train Loss: 2.9830, Train Accuracy: 12.11%, Validation Loss: 6.2685, Validation Accuracy: 9.15%, Learning Rate: 0.50%
Epoch 42, Train Loss: 2.9932, Train Accuracy: 12.73%, Validation Loss: 3.5409, Validation Accuracy: 8.20%, Learning Rate: 0.49%
Epoch 43, Train Loss: 2.9611, Train Accuracy: 12.78%, Validation Loss: 3.6492, Validation Accuracy: 6.41%, Learning Rate: 0.45%
Epoch 44, Train Loss: 2.9554, Train Accuracy: 11.87%, Validation Loss: 3.2587, Validation Accuracy: 8.62%, Learning Rate: 0.40%
Epoch 45, Train Loss: 2.9079, Train Accuracy: 14.69%, Validation Loss: 3.3203, Validation Accuracy: 9.36%, Learning Rate: 0.33%
Epoch 46, Train Loss: 2.8594, Train Accuracy: 14.94%, Validation Loss: 2.9498, Validation Accuracy: 14.20%, Learning Rate: 0.25%
Epoch 47, Train Loss: 2.8157, Train Accuracy: 15.80%, Validation Loss: 2.9870, Validation Accuracy: 12.20%, Learning Rate: 0.17%
Epoch 48, Train Loss: 2.7480, Train Accuracy: 17.67%, Validation Loss: 2.7833, Validation Accuracy: 16.61%, Learning Rate: 0.10%
Epoch 49, Train Loss: 2.6877, Train Accuracy: 18.82%, Validation Loss: 2.6860, Validation Accuracy: 18.30%, Learning Rate: 0.05%
Epoch 50, Train Loss: 2.6526, Train Accuracy: 19.34%, Validation Loss: 2.6475, Validation Accuracy: 18.61%, Learning Rate: 0.01%
Epoch 51, Train Loss: 2.9142, Train Accuracy: 13.73%, Validation Loss: 3.5068, Validation Accuracy: 7.15%, Learning Rate: 0.50%
Epoch 52, Train Loss: 2.9055, Train Accuracy: 13.56%, Validation Loss: 3.1434, Validation Accuracy: 9.67%, Learning Rate: 0.49%
Epoch 53, Train Loss: 2.8982, Train Accuracy: 14.45%, Validation Loss: 4.1728, Validation Accuracy: 5.99%, Learning Rate: 0.45%
Epoch 54, Train Loss: 2.8468, Train Accuracy: 15.18%, Validation Loss: 3.0330, Validation Accuracy: 11.15%, Learning Rate: 0.40%
Epoch 55, Train Loss: 2.8292, Train Accuracy: 15.23%, Validation Loss: 4.2324, Validation Accuracy: 6.10%, Learning Rate: 0.33%
Epoch 56, Train Loss: 2.7948, Train Accuracy: 16.49%, Validation Loss: 2.9269, Validation Accuracy: 14.93%, Learning Rate: 0.25%
Epoch 57, Train Loss: 2.7246, Train Accuracy: 17.49%, Validation Loss: 2.9857, Validation Accuracy: 12.72%, Learning Rate: 0.17%
Epoch 58, Train Loss: 2.6601, Train Accuracy: 19.75%, Validation Loss: 2.8334, Validation Accuracy: 14.83%, Learning Rate: 0.10%
Epoch 59, Train Loss: 2.5973, Train Accuracy: 21.13%, Validation Loss: 2.6645, Validation Accuracy: 19.35%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 19.35%
Epoch 60, Train Loss: 2.5698, Train Accuracy: 20.66%, Validation Loss: 2.5779, Validation Accuracy: 21.87%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 21.87%
Epoch 61, Train Loss: 2.8366, Train Accuracy: 15.50%, Validation Loss: 6.0041, Validation Accuracy: 9.04%, Learning Rate: 0.50%
Epoch 62, Train Loss: 2.8649, Train Accuracy: 15.09%, Validation Loss: 2.9742, Validation Accuracy: 11.25%, Learning Rate: 0.49%
Epoch 63, Train Loss: 2.8259, Train Accuracy: 15.77%, Validation Loss: 3.2828, Validation Accuracy: 13.35%, Learning Rate: 0.45%
Epoch 64, Train Loss: 2.8225, Train Accuracy: 15.45%, Validation Loss: 2.7892, Validation Accuracy: 15.88%, Learning Rate: 0.40%
Epoch 65, Train Loss: 2.7525, Train Accuracy: 16.58%, Validation Loss: 3.1659, Validation Accuracy: 9.67%, Learning Rate: 0.33%
Epoch 66, Train Loss: 2.7179, Train Accuracy: 18.08%, Validation Loss: 2.6430, Validation Accuracy: 19.45%, Learning Rate: 0.25%
Epoch 67, Train Loss: 2.6360, Train Accuracy: 19.66%, Validation Loss: 4.5873, Validation Accuracy: 4.94%, Learning Rate: 0.17%
Epoch 68, Train Loss: 2.5686, Train Accuracy: 21.50%, Validation Loss: 4.2480, Validation Accuracy: 6.41%, Learning Rate: 0.10%
Epoch 69, Train Loss: 2.5190, Train Accuracy: 23.54%, Validation Loss: 2.5330, Validation Accuracy: 23.55%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 23.55%
Epoch 70, Train Loss: 2.4754, Train Accuracy: 23.51%, Validation Loss: 2.5487, Validation Accuracy: 21.77%, Learning Rate: 0.01%
Epoch 71, Train Loss: 2.7655, Train Accuracy: 16.54%, Validation Loss: 4.1402, Validation Accuracy: 6.10%, Learning Rate: 0.50%
Epoch 72, Train Loss: 2.7941, Train Accuracy: 16.90%, Validation Loss: 3.6412, Validation Accuracy: 6.10%, Learning Rate: 0.49%
Epoch 73, Train Loss: 2.7850, Train Accuracy: 16.44%, Validation Loss: 4.2531, Validation Accuracy: 6.10%, Learning Rate: 0.45%
Epoch 74, Train Loss: 2.7380, Train Accuracy: 17.64%, Validation Loss: 3.5508, Validation Accuracy: 7.68%, Learning Rate: 0.40%
Epoch 75, Train Loss: 2.7082, Train Accuracy: 18.55%, Validation Loss: 4.8181, Validation Accuracy: 5.99%, Learning Rate: 0.33%
Epoch 76, Train Loss: 2.6452, Train Accuracy: 19.16%, Validation Loss: 2.6157, Validation Accuracy: 21.24%, Learning Rate: 0.25%
Epoch 77, Train Loss: 2.5840, Train Accuracy: 20.96%, Validation Loss: 3.3389, Validation Accuracy: 14.20%, Learning Rate: 0.17%
Epoch 78, Train Loss: 2.5115, Train Accuracy: 22.53%, Validation Loss: 3.7727, Validation Accuracy: 8.10%, Learning Rate: 0.10%
Epoch 79, Train Loss: 2.4376, Train Accuracy: 24.82%, Validation Loss: 2.4746, Validation Accuracy: 24.29%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 24.29%
Epoch 80, Train Loss: 2.3864, Train Accuracy: 26.34%, Validation Loss: 2.4348, Validation Accuracy: 24.82%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 24.82%
Epoch 81, Train Loss: 2.8083, Train Accuracy: 16.24%, Validation Loss: 3.0772, Validation Accuracy: 12.51%, Learning Rate: 0.50%
Epoch 82, Train Loss: 2.8211, Train Accuracy: 16.14%, Validation Loss: 3.0748, Validation Accuracy: 11.25%, Learning Rate: 0.49%
Epoch 83, Train Loss: 2.7610, Train Accuracy: 17.15%, Validation Loss: 4.0104, Validation Accuracy: 6.94%, Learning Rate: 0.45%
Epoch 84, Train Loss: 2.7262, Train Accuracy: 17.79%, Validation Loss: 4.0074, Validation Accuracy: 4.31%, Learning Rate: 0.40%
Epoch 85, Train Loss: 2.6724, Train Accuracy: 18.01%, Validation Loss: 4.1713, Validation Accuracy: 6.10%, Learning Rate: 0.33%
Epoch 86, Train Loss: 2.6113, Train Accuracy: 20.57%, Validation Loss: 2.8933, Validation Accuracy: 15.98%, Learning Rate: 0.25%
Epoch 87, Train Loss: 2.5563, Train Accuracy: 22.04%, Validation Loss: 2.5416, Validation Accuracy: 21.77%, Learning Rate: 0.17%
Epoch 88, Train Loss: 2.4642, Train Accuracy: 23.56%, Validation Loss: 3.5174, Validation Accuracy: 12.83%, Learning Rate: 0.10%
Epoch 89, Train Loss: 2.3829, Train Accuracy: 26.09%, Validation Loss: 2.4291, Validation Accuracy: 26.71%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 26.71%
Epoch 90, Train Loss: 2.3486, Train Accuracy: 26.17%, Validation Loss: 2.4049, Validation Accuracy: 26.08%, Learning Rate: 0.01%
Epoch 91, Train Loss: 2.7065, Train Accuracy: 18.53%, Validation Loss: 6.0996, Validation Accuracy: 2.84%, Learning Rate: 0.50%
Epoch 92, Train Loss: 2.7312, Train Accuracy: 17.13%, Validation Loss: 3.4842, Validation Accuracy: 6.41%, Learning Rate: 0.49%
Epoch 93, Train Loss: 2.7011, Train Accuracy: 18.06%, Validation Loss: 5.7472, Validation Accuracy: 5.99%, Learning Rate: 0.45%
Epoch 94, Train Loss: 2.6748, Train Accuracy: 19.53%, Validation Loss: 4.3593, Validation Accuracy: 5.89%, Learning Rate: 0.40%
Epoch 95, Train Loss: 2.6048, Train Accuracy: 21.03%, Validation Loss: 5.4017, Validation Accuracy: 4.63%, Learning Rate: 0.33%
Epoch 96, Train Loss: 2.5269, Train Accuracy: 22.21%, Validation Loss: 2.6972, Validation Accuracy: 18.61%, Learning Rate: 0.25%
Epoch 97, Train Loss: 2.4487, Train Accuracy: 24.37%, Validation Loss: 2.5884, Validation Accuracy: 23.24%, Learning Rate: 0.17%
Epoch 98, Train Loss: 2.3770, Train Accuracy: 26.39%, Validation Loss: 2.4516, Validation Accuracy: 25.03%, Learning Rate: 0.10%
Epoch 99, Train Loss: 2.2738, Train Accuracy: 28.99%, Validation Loss: 3.3474, Validation Accuracy: 12.93%, Learning Rate: 0.05%
Epoch 100, Train Loss: 2.2280, Train Accuracy: 30.47%, Validation Loss: 2.3387, Validation Accuracy: 27.34%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 27.34%
Epoch 101, Train Loss: 2.6553, Train Accuracy: 20.61%, Validation Loss: 3.8495, Validation Accuracy: 7.26%, Learning Rate: 0.50%
Epoch 102, Train Loss: 2.6996, Train Accuracy: 18.97%, Validation Loss: 4.6220, Validation Accuracy: 5.99%, Learning Rate: 0.49%
Epoch 103, Train Loss: 2.6864, Train Accuracy: 19.41%, Validation Loss: 2.7376, Validation Accuracy: 17.25%, Learning Rate: 0.45%
Epoch 104, Train Loss: 2.6225, Train Accuracy: 19.61%, Validation Loss: 3.0538, Validation Accuracy: 14.83%, Learning Rate: 0.40%
Epoch 105, Train Loss: 2.5826, Train Accuracy: 21.38%, Validation Loss: 2.8658, Validation Accuracy: 15.04%, Learning Rate: 0.33%
Epoch 106, Train Loss: 2.4879, Train Accuracy: 22.60%, Validation Loss: 2.5646, Validation Accuracy: 21.03%, Learning Rate: 0.25%
Epoch 107, Train Loss: 2.4102, Train Accuracy: 26.14%, Validation Loss: 2.4501, Validation Accuracy: 24.19%, Learning Rate: 0.17%
Epoch 108, Train Loss: 2.2803, Train Accuracy: 29.98%, Validation Loss: 2.3659, Validation Accuracy: 25.87%, Learning Rate: 0.10%
Epoch 109, Train Loss: 2.1895, Train Accuracy: 30.34%, Validation Loss: 2.2697, Validation Accuracy: 29.23%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 29.23%
Epoch 110, Train Loss: 2.1133, Train Accuracy: 33.10%, Validation Loss: 2.2624, Validation Accuracy: 28.39%, Learning Rate: 0.01%
Epoch 111, Train Loss: 2.6320, Train Accuracy: 20.39%, Validation Loss: 5.4777, Validation Accuracy: 5.99%, Learning Rate: 0.50%
Epoch 112, Train Loss: 2.6670, Train Accuracy: 19.48%, Validation Loss: 5.0101, Validation Accuracy: 5.78%, Learning Rate: 0.49%
Epoch 113, Train Loss: 2.5851, Train Accuracy: 21.52%, Validation Loss: 2.7461, Validation Accuracy: 18.40%, Learning Rate: 0.45%
Epoch 114, Train Loss: 2.5515, Train Accuracy: 21.65%, Validation Loss: 2.7049, Validation Accuracy: 20.40%, Learning Rate: 0.40%
Epoch 115, Train Loss: 2.4929, Train Accuracy: 23.78%, Validation Loss: 2.6291, Validation Accuracy: 20.29%, Learning Rate: 0.33%
Epoch 116, Train Loss: 2.3647, Train Accuracy: 26.14%, Validation Loss: 4.6654, Validation Accuracy: 7.57%, Learning Rate: 0.25%
Epoch 117, Train Loss: 2.2900, Train Accuracy: 28.87%, Validation Loss: 2.5517, Validation Accuracy: 24.19%, Learning Rate: 0.17%
Epoch 118, Train Loss: 2.1673, Train Accuracy: 31.52%, Validation Loss: 2.2941, Validation Accuracy: 30.28%, Learning Rate: 0.10%
Model saved with Validation Accuracy: 30.28%
Epoch 119, Train Loss: 2.0369, Train Accuracy: 36.68%, Validation Loss: 2.1890, Validation Accuracy: 34.17%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 34.17%
Epoch 120, Train Loss: 1.9426, Train Accuracy: 38.94%, Validation Loss: 2.1795, Validation Accuracy: 33.54%, Learning Rate: 0.01%
Epoch 121, Train Loss: 2.5101, Train Accuracy: 24.59%, Validation Loss: 2.8003, Validation Accuracy: 18.93%, Learning Rate: 0.50%
Epoch 122, Train Loss: 2.5860, Train Accuracy: 20.91%, Validation Loss: 3.0289, Validation Accuracy: 14.83%, Learning Rate: 0.49%
Epoch 123, Train Loss: 2.5340, Train Accuracy: 22.33%, Validation Loss: 3.0094, Validation Accuracy: 15.46%, Learning Rate: 0.45%
Epoch 124, Train Loss: 2.4739, Train Accuracy: 23.56%, Validation Loss: 4.1949, Validation Accuracy: 8.94%, Learning Rate: 0.40%
Epoch 125, Train Loss: 2.3990, Train Accuracy: 25.16%, Validation Loss: 6.2985, Validation Accuracy: 6.31%, Learning Rate: 0.33%
Epoch 126, Train Loss: 2.2927, Train Accuracy: 28.92%, Validation Loss: 4.4978, Validation Accuracy: 7.15%, Learning Rate: 0.25%
Epoch 127, Train Loss: 2.1596, Train Accuracy: 32.41%, Validation Loss: 2.2800, Validation Accuracy: 29.97%, Learning Rate: 0.17%
Epoch 128, Train Loss: 2.0058, Train Accuracy: 36.93%, Validation Loss: 6.0727, Validation Accuracy: 8.52%, Learning Rate: 0.10%
Epoch 129, Train Loss: 1.8851, Train Accuracy: 40.69%, Validation Loss: 2.1018, Validation Accuracy: 36.91%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 36.91%
Epoch 130, Train Loss: 1.7812, Train Accuracy: 44.03%, Validation Loss: 2.0509, Validation Accuracy: 38.49%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 38.49%
Epoch 131, Train Loss: 2.5021, Train Accuracy: 24.57%, Validation Loss: 6.0328, Validation Accuracy: 5.57%, Learning Rate: 0.50%
Epoch 132, Train Loss: 2.5585, Train Accuracy: 22.19%, Validation Loss: 3.2446, Validation Accuracy: 12.30%, Learning Rate: 0.49%
Epoch 133, Train Loss: 2.4793, Train Accuracy: 23.76%, Validation Loss: 4.1814, Validation Accuracy: 6.20%, Learning Rate: 0.45%
Epoch 134, Train Loss: 2.4193, Train Accuracy: 25.11%, Validation Loss: 6.7185, Validation Accuracy: 5.78%, Learning Rate: 0.40%
Epoch 135, Train Loss: 2.3384, Train Accuracy: 27.67%, Validation Loss: 4.6271, Validation Accuracy: 7.99%, Learning Rate: 0.33%
Epoch 136, Train Loss: 2.1758, Train Accuracy: 32.16%, Validation Loss: 2.3515, Validation Accuracy: 27.87%, Learning Rate: 0.25%
Epoch 137, Train Loss: 2.0334, Train Accuracy: 36.46%, Validation Loss: 5.5695, Validation Accuracy: 6.31%, Learning Rate: 0.17%
Epoch 138, Train Loss: 1.8764, Train Accuracy: 40.79%, Validation Loss: 2.1311, Validation Accuracy: 35.75%, Learning Rate: 0.10%
Epoch 139, Train Loss: 1.7062, Train Accuracy: 46.04%, Validation Loss: 2.2946, Validation Accuracy: 32.49%, Learning Rate: 0.05%
Epoch 140, Train Loss: 1.5926, Train Accuracy: 50.10%, Validation Loss: 1.9789, Validation Accuracy: 42.90%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 42.90%
Epoch 141, Train Loss: 2.4057, Train Accuracy: 26.46%, Validation Loss: 5.7100, Validation Accuracy: 6.10%, Learning Rate: 0.50%
Epoch 142, Train Loss: 2.5313, Train Accuracy: 22.85%, Validation Loss: 2.6607, Validation Accuracy: 21.45%, Learning Rate: 0.49%
Epoch 143, Train Loss: 2.4165, Train Accuracy: 25.48%, Validation Loss: 4.2636, Validation Accuracy: 5.05%, Learning Rate: 0.45%
Epoch 144, Train Loss: 2.3326, Train Accuracy: 28.26%, Validation Loss: 2.7531, Validation Accuracy: 20.61%, Learning Rate: 0.40%
Epoch 145, Train Loss: 2.2376, Train Accuracy: 30.15%, Validation Loss: 3.7592, Validation Accuracy: 14.72%, Learning Rate: 0.33%
Epoch 146, Train Loss: 2.0662, Train Accuracy: 34.94%, Validation Loss: 4.7301, Validation Accuracy: 6.41%, Learning Rate: 0.25%
Epoch 147, Train Loss: 1.8691, Train Accuracy: 41.03%, Validation Loss: 2.2836, Validation Accuracy: 34.38%, Learning Rate: 0.17%
Epoch 148, Train Loss: 1.6958, Train Accuracy: 47.30%, Validation Loss: 1.9852, Validation Accuracy: 42.80%, Learning Rate: 0.10%
Epoch 149, Train Loss: 1.5242, Train Accuracy: 51.70%, Validation Loss: 1.9063, Validation Accuracy: 47.95%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 47.95%
Epoch 150, Train Loss: 1.4039, Train Accuracy: 56.81%, Validation Loss: 1.8582, Validation Accuracy: 49.95%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 49.95%
Epoch 151, Train Loss: 2.2632, Train Accuracy: 31.55%, Validation Loss: 2.6859, Validation Accuracy: 17.35%, Learning Rate: 0.50%
Epoch 152, Train Loss: 2.4618, Train Accuracy: 24.23%, Validation Loss: 2.7248, Validation Accuracy: 20.72%, Learning Rate: 0.49%
Epoch 153, Train Loss: 2.3761, Train Accuracy: 26.46%, Validation Loss: 4.6959, Validation Accuracy: 7.47%, Learning Rate: 0.45%
Epoch 154, Train Loss: 2.2112, Train Accuracy: 29.75%, Validation Loss: 4.5713, Validation Accuracy: 8.52%, Learning Rate: 0.40%
Epoch 155, Train Loss: 2.1300, Train Accuracy: 34.20%, Validation Loss: 2.4556, Validation Accuracy: 28.08%, Learning Rate: 0.33%
Epoch 156, Train Loss: 1.9436, Train Accuracy: 38.65%, Validation Loss: 2.3550, Validation Accuracy: 29.76%, Learning Rate: 0.25%
Epoch 157, Train Loss: 1.7492, Train Accuracy: 45.14%, Validation Loss: 2.0155, Validation Accuracy: 44.16%, Learning Rate: 0.17%
Epoch 158, Train Loss: 1.5071, Train Accuracy: 53.10%, Validation Loss: 1.8961, Validation Accuracy: 47.42%, Learning Rate: 0.10%
Epoch 159, Train Loss: 1.2930, Train Accuracy: 60.47%, Validation Loss: 1.8094, Validation Accuracy: 51.95%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 51.95%
Epoch 160, Train Loss: 1.1850, Train Accuracy: 64.59%, Validation Loss: 1.7655, Validation Accuracy: 52.37%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 52.37%
Epoch 161, Train Loss: 2.2295, Train Accuracy: 31.92%, Validation Loss: 4.6216, Validation Accuracy: 3.68%, Learning Rate: 0.50%
Epoch 162, Train Loss: 2.4273, Train Accuracy: 25.58%, Validation Loss: 6.0453, Validation Accuracy: 7.05%, Learning Rate: 0.49%
Epoch 163, Train Loss: 2.2920, Train Accuracy: 29.66%, Validation Loss: 2.8013, Validation Accuracy: 21.66%, Learning Rate: 0.45%
Epoch 164, Train Loss: 2.1225, Train Accuracy: 33.78%, Validation Loss: 2.3587, Validation Accuracy: 29.23%, Learning Rate: 0.40%
Epoch 165, Train Loss: 1.9606, Train Accuracy: 38.01%, Validation Loss: 2.3932, Validation Accuracy: 28.92%, Learning Rate: 0.33%
Epoch 166, Train Loss: 1.7739, Train Accuracy: 43.49%, Validation Loss: 5.1708, Validation Accuracy: 7.78%, Learning Rate: 0.25%
Epoch 167, Train Loss: 1.5504, Train Accuracy: 51.50%, Validation Loss: 1.9519, Validation Accuracy: 47.95%, Learning Rate: 0.17%
Epoch 168, Train Loss: 1.2936, Train Accuracy: 59.63%, Validation Loss: 1.9195, Validation Accuracy: 49.95%, Learning Rate: 0.10%
Epoch 169, Train Loss: 1.1326, Train Accuracy: 65.11%, Validation Loss: 1.7676, Validation Accuracy: 54.36%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 54.36%
Epoch 170, Train Loss: 1.0155, Train Accuracy: 69.80%, Validation Loss: 1.7554, Validation Accuracy: 55.42%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 55.42%
Epoch 171, Train Loss: 1.9807, Train Accuracy: 40.17%, Validation Loss: 9.0600, Validation Accuracy: 6.10%, Learning Rate: 0.50%
Epoch 172, Train Loss: 2.3354, Train Accuracy: 27.49%, Validation Loss: 4.8622, Validation Accuracy: 6.31%, Learning Rate: 0.49%
Epoch 173, Train Loss: 2.1517, Train Accuracy: 32.95%, Validation Loss: 2.6531, Validation Accuracy: 25.34%, Learning Rate: 0.45%
Epoch 174, Train Loss: 1.9933, Train Accuracy: 37.37%, Validation Loss: 9.3888, Validation Accuracy: 5.99%, Learning Rate: 0.40%
Epoch 175, Train Loss: 1.8467, Train Accuracy: 41.20%, Validation Loss: 2.3365, Validation Accuracy: 34.17%, Learning Rate: 0.33%
Epoch 176, Train Loss: 1.6240, Train Accuracy: 48.57%, Validation Loss: 2.1376, Validation Accuracy: 40.48%, Learning Rate: 0.25%
Epoch 177, Train Loss: 1.3714, Train Accuracy: 56.49%, Validation Loss: 6.4622, Validation Accuracy: 6.94%, Learning Rate: 0.17%
Epoch 178, Train Loss: 1.1183, Train Accuracy: 65.26%, Validation Loss: 1.8601, Validation Accuracy: 53.42%, Learning Rate: 0.10%
Epoch 179, Train Loss: 0.9373, Train Accuracy: 71.70%, Validation Loss: 1.7462, Validation Accuracy: 57.31%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 57.31%
Epoch 180, Train Loss: 0.8350, Train Accuracy: 76.76%, Validation Loss: 1.7228, Validation Accuracy: 59.10%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 59.10%
Epoch 181, Train Loss: 1.8454, Train Accuracy: 44.08%, Validation Loss: 4.2979, Validation Accuracy: 11.78%, Learning Rate: 0.50%
Epoch 182, Train Loss: 2.1792, Train Accuracy: 32.78%, Validation Loss: 2.5853, Validation Accuracy: 25.76%, Learning Rate: 0.49%
Epoch 183, Train Loss: 2.0310, Train Accuracy: 36.46%, Validation Loss: 2.7644, Validation Accuracy: 24.40%, Learning Rate: 0.45%
Epoch 184, Train Loss: 1.9279, Train Accuracy: 40.49%, Validation Loss: 5.9566, Validation Accuracy: 6.20%, Learning Rate: 0.40%
Epoch 185, Train Loss: 1.7559, Train Accuracy: 44.79%, Validation Loss: 4.1403, Validation Accuracy: 9.25%, Learning Rate: 0.33%
Epoch 186, Train Loss: 1.4338, Train Accuracy: 55.11%, Validation Loss: 3.8000, Validation Accuracy: 13.56%, Learning Rate: 0.25%
Epoch 187, Train Loss: 1.1745, Train Accuracy: 63.64%, Validation Loss: 1.8219, Validation Accuracy: 55.21%, Learning Rate: 0.17%
Epoch 188, Train Loss: 0.9597, Train Accuracy: 70.84%, Validation Loss: 3.4327, Validation Accuracy: 21.45%, Learning Rate: 0.10%
Epoch 189, Train Loss: 0.7946, Train Accuracy: 76.73%, Validation Loss: 1.7730, Validation Accuracy: 60.15%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 60.15%
Epoch 190, Train Loss: 0.6947, Train Accuracy: 80.42%, Validation Loss: 1.7082, Validation Accuracy: 60.67%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 60.67%
Epoch 191, Train Loss: 1.5893, Train Accuracy: 51.43%, Validation Loss: 5.9744, Validation Accuracy: 7.26%, Learning Rate: 0.50%
Epoch 192, Train Loss: 2.1404, Train Accuracy: 34.00%, Validation Loss: 5.6132, Validation Accuracy: 7.05%, Learning Rate: 0.49%
Epoch 193, Train Loss: 1.9117, Train Accuracy: 39.36%, Validation Loss: 2.8331, Validation Accuracy: 29.13%, Learning Rate: 0.45%
Epoch 194, Train Loss: 1.7123, Train Accuracy: 45.55%, Validation Loss: 2.2967, Validation Accuracy: 37.85%, Learning Rate: 0.40%
Epoch 195, Train Loss: 1.5236, Train Accuracy: 51.50%, Validation Loss: 2.1972, Validation Accuracy: 44.06%, Learning Rate: 0.33%
Epoch 196, Train Loss: 1.2650, Train Accuracy: 60.61%, Validation Loss: 5.1810, Validation Accuracy: 10.20%, Learning Rate: 0.25%
Epoch 197, Train Loss: 0.9943, Train Accuracy: 69.21%, Validation Loss: 1.7878, Validation Accuracy: 57.10%, Learning Rate: 0.17%
Epoch 198, Train Loss: 0.7701, Train Accuracy: 76.36%, Validation Loss: 1.7506, Validation Accuracy: 60.25%, Learning Rate: 0.10%
Epoch 199, Train Loss: 0.6096, Train Accuracy: 82.85%, Validation Loss: 1.7249, Validation Accuracy: 61.72%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 61.72%
Epoch 200, Train Loss: 0.5517, Train Accuracy: 84.91%, Validation Loss: 1.7373, Validation Accuracy: 61.93%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 61.93%
Epoch 201, Train Loss: 1.4805, Train Accuracy: 55.18%, Validation Loss: 5.1142, Validation Accuracy: 11.15%, Learning Rate: 0.50%
Epoch 202, Train Loss: 2.0850, Train Accuracy: 35.31%, Validation Loss: 4.1473, Validation Accuracy: 7.89%, Learning Rate: 0.49%
Epoch 203, Train Loss: 1.7918, Train Accuracy: 44.28%, Validation Loss: 2.3408, Validation Accuracy: 34.28%, Learning Rate: 0.45%
Epoch 204, Train Loss: 1.5429, Train Accuracy: 51.74%, Validation Loss: 2.1132, Validation Accuracy: 44.48%, Learning Rate: 0.40%
Epoch 205, Train Loss: 1.3515, Train Accuracy: 57.27%, Validation Loss: 2.1628, Validation Accuracy: 46.06%, Learning Rate: 0.33%
Epoch 206, Train Loss: 1.1263, Train Accuracy: 64.72%, Validation Loss: 4.4192, Validation Accuracy: 15.04%, Learning Rate: 0.25%
Epoch 207, Train Loss: 0.8746, Train Accuracy: 73.91%, Validation Loss: 1.9391, Validation Accuracy: 57.31%, Learning Rate: 0.17%
Epoch 208, Train Loss: 0.6691, Train Accuracy: 79.66%, Validation Loss: 3.5393, Validation Accuracy: 24.61%, Learning Rate: 0.10%
Epoch 209, Train Loss: 0.5226, Train Accuracy: 85.31%, Validation Loss: 1.7691, Validation Accuracy: 61.93%, Learning Rate: 0.05%
Epoch 210, Train Loss: 0.4556, Train Accuracy: 87.76%, Validation Loss: 1.7964, Validation Accuracy: 61.83%, Learning Rate: 0.01%
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-9-fa98badd98ed> in <cell line: 194>()
    192
    193 # Î™®Îç∏ ÌïôÏäµ ÏãúÏûë
--> 194 train_model(train_loader, val_loader, model, optimizer, criterion, scheduler, epochs=300, save_path='/content/drive/MyDrive/ÏßÑÌÇ¥/model_final5.pth')

10 frames
/usr/local/lib/python3.10/dist-packages/torchvision/transforms/transforms.py in get_params(img, scale, ratio)
    943
    944             if 0 < w <= width and 0 < h <= height:
--> 945                 i = torch.randint(0, height - h + 1, size=(1,)).item()
    946                 j = torch.randint(0, width - w + 1, size=(1,)).item()
    947                 return i, j, h, w

KeyboardInterrupt:


## 210~400 ÏóêÌè≠ Ïã§Ìñâ Í≤∞Í≥º => 210ÏóêÏÑú ÌïôÏäµ ÎÅäÏóàÎã§Í∞Ä Ï†ÄÏû•Îêú Î™®Îç∏ Î°úÎìúÌï¥ÏÑú Îã§Ïãú ÌïôÏäµ ÏãúÏûë

Loading saved model from /content/drive/MyDrive/ÏßÑÌÇ¥/model_final5.pth...
<ipython-input-7-fa98badd98ed>:123: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(save_path))
Model loaded successfully!
Epoch 1, Train Loss: 1.5580, Train Accuracy: 51.38%, Validation Loss: 10.3372, Validation Accuracy: 6.73%, Learning Rate: 0.50%
Model saved with Validation Accuracy: 6.73%
Epoch 2, Train Loss: 1.4383, Train Accuracy: 54.35%, Validation Loss: 2.1517, Validation Accuracy: 42.80%, Learning Rate: 0.49%
Model saved with Validation Accuracy: 42.80%
Epoch 3, Train Loss: 1.2633, Train Accuracy: 59.75%, Validation Loss: 2.7484, Validation Accuracy: 35.65%, Learning Rate: 0.45%
Epoch 4, Train Loss: 1.1385, Train Accuracy: 63.66%, Validation Loss: 7.1169, Validation Accuracy: 7.68%, Learning Rate: 0.40%
Epoch 5, Train Loss: 0.9818, Train Accuracy: 69.56%, Validation Loss: 2.1541, Validation Accuracy: 51.63%, Learning Rate: 0.33%
Model saved with Validation Accuracy: 51.63%
Epoch 6, Train Loss: 0.7652, Train Accuracy: 76.76%, Validation Loss: 2.0186, Validation Accuracy: 60.15%, Learning Rate: 0.25%
Model saved with Validation Accuracy: 60.15%
Epoch 7, Train Loss: 0.6069, Train Accuracy: 81.79%, Validation Loss: 2.0728, Validation Accuracy: 56.68%, Learning Rate: 0.17%
Epoch 8, Train Loss: 0.4628, Train Accuracy: 86.36%, Validation Loss: 1.9738, Validation Accuracy: 60.78%, Learning Rate: 0.10%
Model saved with Validation Accuracy: 60.78%
Epoch 9, Train Loss: 0.3836, Train Accuracy: 89.75%, Validation Loss: 1.9083, Validation Accuracy: 61.93%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 61.93%
Epoch 10, Train Loss: 0.3371, Train Accuracy: 90.74%, Validation Loss: 1.9024, Validation Accuracy: 62.04%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 62.04%
Epoch 11, Train Loss: 0.9558, Train Accuracy: 70.79%, Validation Loss: 4.0211, Validation Accuracy: 23.24%, Learning Rate: 0.50%
Epoch 12, Train Loss: 1.7764, Train Accuracy: 45.16%, Validation Loss: 2.7372, Validation Accuracy: 29.55%, Learning Rate: 0.49%
Epoch 13, Train Loss: 1.4756, Train Accuracy: 53.61%, Validation Loss: 2.4310, Validation Accuracy: 40.69%, Learning Rate: 0.45%
Epoch 14, Train Loss: 1.2130, Train Accuracy: 62.83%, Validation Loss: 2.0787, Validation Accuracy: 49.84%, Learning Rate: 0.40%
Epoch 15, Train Loss: 1.0507, Train Accuracy: 68.55%, Validation Loss: 4.7683, Validation Accuracy: 14.30%, Learning Rate: 0.33%
Epoch 16, Train Loss: 0.7794, Train Accuracy: 75.70%, Validation Loss: 3.1659, Validation Accuracy: 31.55%, Learning Rate: 0.25%
Epoch 17, Train Loss: 0.5656, Train Accuracy: 82.46%, Validation Loss: 1.9884, Validation Accuracy: 60.04%, Learning Rate: 0.17%
Epoch 18, Train Loss: 0.4115, Train Accuracy: 87.86%, Validation Loss: 1.9507, Validation Accuracy: 61.62%, Learning Rate: 0.10%
Epoch 19, Train Loss: 0.3197, Train Accuracy: 91.18%, Validation Loss: 1.9563, Validation Accuracy: 61.83%, Learning Rate: 0.05%
Epoch 20, Train Loss: 0.3037, Train Accuracy: 91.70%, Validation Loss: 1.9436, Validation Accuracy: 62.25%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 62.25%
Epoch 21, Train Loss: 0.9235, Train Accuracy: 72.21%, Validation Loss: 2.9740, Validation Accuracy: 25.97%, Learning Rate: 0.50%
Epoch 22, Train Loss: 1.6220, Train Accuracy: 49.29%, Validation Loss: 6.6767, Validation Accuracy: 9.57%, Learning Rate: 0.49%
Epoch 23, Train Loss: 1.3890, Train Accuracy: 57.30%, Validation Loss: 4.4381, Validation Accuracy: 19.87%, Learning Rate: 0.45%
Epoch 24, Train Loss: 1.2128, Train Accuracy: 61.35%, Validation Loss: 2.5213, Validation Accuracy: 39.64%, Learning Rate: 0.40%
Epoch 25, Train Loss: 1.0326, Train Accuracy: 68.18%, Validation Loss: 3.0384, Validation Accuracy: 36.38%, Learning Rate: 0.33%
Epoch 26, Train Loss: 0.8038, Train Accuracy: 74.62%, Validation Loss: 1.9214, Validation Accuracy: 60.88%, Learning Rate: 0.25%
Epoch 27, Train Loss: 0.5492, Train Accuracy: 83.73%, Validation Loss: 1.9707, Validation Accuracy: 60.04%, Learning Rate: 0.17%
Epoch 28, Train Loss: 0.3932, Train Accuracy: 88.35%, Validation Loss: 1.9215, Validation Accuracy: 62.15%, Learning Rate: 0.10%
Epoch 29, Train Loss: 0.3060, Train Accuracy: 91.82%, Validation Loss: 1.9733, Validation Accuracy: 62.99%, Learning Rate: 0.05%
Model saved with Validation Accuracy: 62.99%
Epoch 30, Train Loss: 0.2556, Train Accuracy: 93.12%, Validation Loss: 1.9378, Validation Accuracy: 63.51%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 63.51%
Epoch 31, Train Loss: 0.7539, Train Accuracy: 77.17%, Validation Loss: 2.8117, Validation Accuracy: 41.11%, Learning Rate: 0.50%
Epoch 32, Train Loss: 1.5633, Train Accuracy: 51.77%, Validation Loss: 4.3871, Validation Accuracy: 9.15%, Learning Rate: 0.49%
Epoch 33, Train Loss: 1.3930, Train Accuracy: 55.70%, Validation Loss: 3.2248, Validation Accuracy: 28.81%, Learning Rate: 0.45%
Epoch 34, Train Loss: 1.1354, Train Accuracy: 64.20%, Validation Loss: 2.4129, Validation Accuracy: 46.69%, Learning Rate: 0.40%
Epoch 35, Train Loss: 0.9292, Train Accuracy: 71.03%, Validation Loss: 2.0759, Validation Accuracy: 56.05%, Learning Rate: 0.33%
Epoch 36, Train Loss: 0.6493, Train Accuracy: 79.75%, Validation Loss: 1.9451, Validation Accuracy: 60.15%, Learning Rate: 0.25%
Epoch 37, Train Loss: 0.4431, Train Accuracy: 87.17%, Validation Loss: 2.0262, Validation Accuracy: 58.99%, Learning Rate: 0.17%
Epoch 38, Train Loss: 0.3571, Train Accuracy: 89.71%, Validation Loss: 1.9019, Validation Accuracy: 63.72%, Learning Rate: 0.10%
Model saved with Validation Accuracy: 63.72%
Epoch 39, Train Loss: 0.2641, Train Accuracy: 92.43%, Validation Loss: 1.9525, Validation Accuracy: 62.78%, Learning Rate: 0.05%
Epoch 40, Train Loss: 0.2289, Train Accuracy: 93.98%, Validation Loss: 1.9315, Validation Accuracy: 63.20%, Learning Rate: 0.01%
Epoch 41, Train Loss: 0.7508, Train Accuracy: 77.03%, Validation Loss: 2.7431, Validation Accuracy: 45.43%, Learning Rate: 0.50%
Epoch 42, Train Loss: 1.5456, Train Accuracy: 53.14%, Validation Loss: 2.9263, Validation Accuracy: 25.97%, Learning Rate: 0.49%
Epoch 43, Train Loss: 1.4056, Train Accuracy: 55.23%, Validation Loss: 3.2257, Validation Accuracy: 30.18%, Learning Rate: 0.45%
Epoch 44, Train Loss: 1.0991, Train Accuracy: 65.36%, Validation Loss: 2.1738, Validation Accuracy: 51.42%, Learning Rate: 0.40%
Epoch 45, Train Loss: 0.8221, Train Accuracy: 73.96%, Validation Loss: 7.4588, Validation Accuracy: 8.52%, Learning Rate: 0.33%
Epoch 46, Train Loss: 0.6119, Train Accuracy: 82.14%, Validation Loss: 1.9653, Validation Accuracy: 62.36%, Learning Rate: 0.25%
Epoch 47, Train Loss: 0.4240, Train Accuracy: 87.52%, Validation Loss: 2.0236, Validation Accuracy: 63.20%, Learning Rate: 0.17%
Epoch 48, Train Loss: 0.3182, Train Accuracy: 90.54%, Validation Loss: 2.0335, Validation Accuracy: 62.99%, Learning Rate: 0.10%
Epoch 49, Train Loss: 0.2442, Train Accuracy: 93.49%, Validation Loss: 1.9505, Validation Accuracy: 62.04%, Learning Rate: 0.05%
Epoch 50, Train Loss: 0.2198, Train Accuracy: 94.25%, Validation Loss: 1.9837, Validation Accuracy: 62.46%, Learning Rate: 0.01%
Epoch 51, Train Loss: 0.6596, Train Accuracy: 79.75%, Validation Loss: 3.6988, Validation Accuracy: 33.44%, Learning Rate: 0.50%
Epoch 52, Train Loss: 1.5387, Train Accuracy: 53.64%, Validation Loss: 9.4810, Validation Accuracy: 2.00%, Learning Rate: 0.49%
Epoch 53, Train Loss: 1.3354, Train Accuracy: 57.79%, Validation Loss: 2.2164, Validation Accuracy: 47.21%, Learning Rate: 0.45%
Epoch 54, Train Loss: 1.0393, Train Accuracy: 67.42%, Validation Loss: 2.0285, Validation Accuracy: 55.21%, Learning Rate: 0.40%
Epoch 55, Train Loss: 0.8224, Train Accuracy: 74.30%, Validation Loss: 2.2561, Validation Accuracy: 51.52%, Learning Rate: 0.33%
Epoch 56, Train Loss: 0.5903, Train Accuracy: 81.45%, Validation Loss: 5.5662, Validation Accuracy: 14.93%, Learning Rate: 0.25%
Epoch 57, Train Loss: 0.3948, Train Accuracy: 88.55%, Validation Loss: 4.7456, Validation Accuracy: 18.30%, Learning Rate: 0.17%
Epoch 58, Train Loss: 0.3047, Train Accuracy: 91.30%, Validation Loss: 1.9793, Validation Accuracy: 62.57%, Learning Rate: 0.10%
Epoch 59, Train Loss: 0.2165, Train Accuracy: 94.05%, Validation Loss: 1.9665, Validation Accuracy: 62.67%, Learning Rate: 0.05%
Epoch 60, Train Loss: 0.1908, Train Accuracy: 95.23%, Validation Loss: 1.9632, Validation Accuracy: 62.36%, Learning Rate: 0.01%
Epoch 61, Train Loss: 0.5720, Train Accuracy: 82.73%, Validation Loss: 14.5702, Validation Accuracy: 8.73%, Learning Rate: 0.50%
Epoch 62, Train Loss: 1.2915, Train Accuracy: 59.61%, Validation Loss: 2.6566, Validation Accuracy: 41.32%, Learning Rate: 0.49%
Epoch 63, Train Loss: 1.2904, Train Accuracy: 59.93%, Validation Loss: 2.2573, Validation Accuracy: 46.69%, Learning Rate: 0.45%
Epoch 64, Train Loss: 0.9418, Train Accuracy: 70.66%, Validation Loss: 2.3194, Validation Accuracy: 51.31%, Learning Rate: 0.40%
Epoch 65, Train Loss: 0.7819, Train Accuracy: 75.04%, Validation Loss: 2.2865, Validation Accuracy: 54.05%, Learning Rate: 0.33%
Epoch 66, Train Loss: 0.5718, Train Accuracy: 81.84%, Validation Loss: 2.1152, Validation Accuracy: 60.15%, Learning Rate: 0.25%
Epoch 67, Train Loss: 0.3815, Train Accuracy: 88.70%, Validation Loss: 2.0511, Validation Accuracy: 61.41%, Learning Rate: 0.17%
Epoch 68, Train Loss: 0.2676, Train Accuracy: 92.48%, Validation Loss: 2.0931, Validation Accuracy: 62.78%, Learning Rate: 0.10%
Epoch 69, Train Loss: 0.1988, Train Accuracy: 94.45%, Validation Loss: 2.0770, Validation Accuracy: 63.20%, Learning Rate: 0.05%
Epoch 70, Train Loss: 0.1828, Train Accuracy: 95.06%, Validation Loss: 2.0508, Validation Accuracy: 62.88%, Learning Rate: 0.01%
Epoch 71, Train Loss: 0.4387, Train Accuracy: 86.39%, Validation Loss: 2.6482, Validation Accuracy: 48.37%, Learning Rate: 0.50%
Epoch 72, Train Loss: 1.2247, Train Accuracy: 62.60%, Validation Loss: 8.2978, Validation Accuracy: 6.73%, Learning Rate: 0.49%
Epoch 73, Train Loss: 1.3093, Train Accuracy: 60.29%, Validation Loss: 6.4850, Validation Accuracy: 9.15%, Learning Rate: 0.45%
Epoch 74, Train Loss: 0.9702, Train Accuracy: 69.88%, Validation Loss: 2.5752, Validation Accuracy: 46.27%, Learning Rate: 0.40%
Epoch 75, Train Loss: 0.6957, Train Accuracy: 78.35%, Validation Loss: 2.1316, Validation Accuracy: 57.31%, Learning Rate: 0.33%
Epoch 76, Train Loss: 0.5219, Train Accuracy: 83.73%, Validation Loss: 2.0470, Validation Accuracy: 58.25%, Learning Rate: 0.25%
Epoch 77, Train Loss: 0.3522, Train Accuracy: 89.85%, Validation Loss: 2.0711, Validation Accuracy: 61.51%, Learning Rate: 0.17%
Epoch 78, Train Loss: 0.2353, Train Accuracy: 93.49%, Validation Loss: 2.0312, Validation Accuracy: 63.41%, Learning Rate: 0.10%
Epoch 79, Train Loss: 0.1976, Train Accuracy: 94.25%, Validation Loss: 2.0604, Validation Accuracy: 63.62%, Learning Rate: 0.05%
Epoch 80, Train Loss: 0.1776, Train Accuracy: 95.38%, Validation Loss: 2.0569, Validation Accuracy: 63.51%, Learning Rate: 0.01%
Epoch 81, Train Loss: 0.4586, Train Accuracy: 86.02%, Validation Loss: 8.9934, Validation Accuracy: 9.36%, Learning Rate: 0.50%
Epoch 82, Train Loss: 1.2572, Train Accuracy: 62.53%, Validation Loss: 11.3852, Validation Accuracy: 7.36%, Learning Rate: 0.49%
Epoch 83, Train Loss: 1.1860, Train Accuracy: 63.17%, Validation Loss: 2.3386, Validation Accuracy: 45.74%, Learning Rate: 0.45%
Epoch 84, Train Loss: 0.8974, Train Accuracy: 71.30%, Validation Loss: 5.1083, Validation Accuracy: 9.78%, Learning Rate: 0.40%
Epoch 85, Train Loss: 0.6686, Train Accuracy: 79.04%, Validation Loss: 2.0672, Validation Accuracy: 58.68%, Learning Rate: 0.33%
Epoch 86, Train Loss: 0.4640, Train Accuracy: 86.19%, Validation Loss: 2.6122, Validation Accuracy: 50.79%, Learning Rate: 0.25%
Epoch 87, Train Loss: 0.3181, Train Accuracy: 90.29%, Validation Loss: 2.2199, Validation Accuracy: 53.63%, Learning Rate: 0.17%
Epoch 88, Train Loss: 0.2268, Train Accuracy: 93.37%, Validation Loss: 2.0634, Validation Accuracy: 63.09%, Learning Rate: 0.10%
Epoch 89, Train Loss: 0.1769, Train Accuracy: 94.79%, Validation Loss: 2.0426, Validation Accuracy: 63.51%, Learning Rate: 0.05%
Epoch 90, Train Loss: 0.1583, Train Accuracy: 95.48%, Validation Loss: 2.0258, Validation Accuracy: 63.72%, Learning Rate: 0.01%
Epoch 91, Train Loss: 0.3826, Train Accuracy: 88.01%, Validation Loss: 11.7006, Validation Accuracy: 10.09%, Learning Rate: 0.50%
Epoch 92, Train Loss: 1.3109, Train Accuracy: 61.23%, Validation Loss: 10.3495, Validation Accuracy: 5.47%, Learning Rate: 0.49%
Epoch 93, Train Loss: 1.2236, Train Accuracy: 61.74%, Validation Loss: 2.0588, Validation Accuracy: 53.73%, Learning Rate: 0.45%
Epoch 94, Train Loss: 0.9063, Train Accuracy: 71.72%, Validation Loss: 5.1297, Validation Accuracy: 11.15%, Learning Rate: 0.40%
Epoch 95, Train Loss: 0.6722, Train Accuracy: 79.46%, Validation Loss: 2.0176, Validation Accuracy: 57.31%, Learning Rate: 0.33%
Epoch 96, Train Loss: 0.4570, Train Accuracy: 86.46%, Validation Loss: 2.0125, Validation Accuracy: 60.88%, Learning Rate: 0.25%
Epoch 97, Train Loss: 0.3003, Train Accuracy: 91.52%, Validation Loss: 2.1386, Validation Accuracy: 61.09%, Learning Rate: 0.17%
Epoch 98, Train Loss: 0.2211, Train Accuracy: 93.51%, Validation Loss: 2.0366, Validation Accuracy: 64.04%, Learning Rate: 0.10%
Model saved with Validation Accuracy: 64.04%
Epoch 99, Train Loss: 0.1661, Train Accuracy: 95.50%, Validation Loss: 2.0732, Validation Accuracy: 63.30%, Learning Rate: 0.05%
Epoch 100, Train Loss: 0.1627, Train Accuracy: 95.50%, Validation Loss: 2.0866, Validation Accuracy: 62.99%, Learning Rate: 0.01%
Epoch 101, Train Loss: 0.3998, Train Accuracy: 87.62%, Validation Loss: 2.7482, Validation Accuracy: 48.69%, Learning Rate: 0.50%
Epoch 102, Train Loss: 1.1540, Train Accuracy: 64.79%, Validation Loss: 6.4551, Validation Accuracy: 9.25%, Learning Rate: 0.49%
Epoch 103, Train Loss: 1.1474, Train Accuracy: 64.37%, Validation Loss: 10.7821, Validation Accuracy: 8.52%, Learning Rate: 0.45%
Epoch 104, Train Loss: 0.7873, Train Accuracy: 76.17%, Validation Loss: 2.1819, Validation Accuracy: 56.89%, Learning Rate: 0.40%
Epoch 105, Train Loss: 0.6064, Train Accuracy: 81.23%, Validation Loss: 2.0777, Validation Accuracy: 58.36%, Learning Rate: 0.33%
Epoch 106, Train Loss: 0.4247, Train Accuracy: 87.35%, Validation Loss: 2.0624, Validation Accuracy: 60.99%, Learning Rate: 0.25%
Epoch 107, Train Loss: 0.2913, Train Accuracy: 91.43%, Validation Loss: 5.5841, Validation Accuracy: 15.46%, Learning Rate: 0.17%
Epoch 108, Train Loss: 0.1762, Train Accuracy: 95.21%, Validation Loss: 2.5248, Validation Accuracy: 48.79%, Learning Rate: 0.10%
Epoch 109, Train Loss: 0.1585, Train Accuracy: 95.58%, Validation Loss: 2.0594, Validation Accuracy: 63.30%, Learning Rate: 0.05%
Epoch 110, Train Loss: 0.1398, Train Accuracy: 96.02%, Validation Loss: 2.0695, Validation Accuracy: 64.14%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 64.14%
Epoch 111, Train Loss: 0.4282, Train Accuracy: 86.93%, Validation Loss: 6.5868, Validation Accuracy: 12.30%, Learning Rate: 0.50%
Epoch 112, Train Loss: 1.2478, Train Accuracy: 61.62%, Validation Loss: 8.3507, Validation Accuracy: 6.41%, Learning Rate: 0.49%
Epoch 113, Train Loss: 1.2411, Train Accuracy: 61.82%, Validation Loss: 2.1824, Validation Accuracy: 51.31%, Learning Rate: 0.45%
Epoch 114, Train Loss: 0.9071, Train Accuracy: 72.26%, Validation Loss: 2.2339, Validation Accuracy: 50.68%, Learning Rate: 0.40%
Epoch 115, Train Loss: 0.6145, Train Accuracy: 81.13%, Validation Loss: 2.1071, Validation Accuracy: 60.25%, Learning Rate: 0.33%
Epoch 116, Train Loss: 0.4151, Train Accuracy: 87.15%, Validation Loss: 2.2847, Validation Accuracy: 60.15%, Learning Rate: 0.25%
Epoch 117, Train Loss: 0.2786, Train Accuracy: 91.77%, Validation Loss: 2.1494, Validation Accuracy: 60.25%, Learning Rate: 0.17%
Epoch 118, Train Loss: 0.1978, Train Accuracy: 94.57%, Validation Loss: 2.0365, Validation Accuracy: 63.09%, Learning Rate: 0.10%
Epoch 119, Train Loss: 0.1565, Train Accuracy: 95.85%, Validation Loss: 2.0890, Validation Accuracy: 62.46%, Learning Rate: 0.05%
Epoch 120, Train Loss: 0.1428, Train Accuracy: 95.97%, Validation Loss: 2.0861, Validation Accuracy: 62.67%, Learning Rate: 0.01%
Epoch 121, Train Loss: 0.3919, Train Accuracy: 88.08%, Validation Loss: 5.2155, Validation Accuracy: 12.83%, Learning Rate: 0.50%
Epoch 122, Train Loss: 1.0838, Train Accuracy: 65.82%, Validation Loss: 8.7766, Validation Accuracy: 8.20%, Learning Rate: 0.49%
Epoch 123, Train Loss: 1.0796, Train Accuracy: 65.70%, Validation Loss: 8.7501, Validation Accuracy: 9.15%, Learning Rate: 0.45%
Epoch 124, Train Loss: 0.8421, Train Accuracy: 73.46%, Validation Loss: 2.0915, Validation Accuracy: 55.31%, Learning Rate: 0.40%
Epoch 125, Train Loss: 0.6019, Train Accuracy: 81.67%, Validation Loss: 2.1512, Validation Accuracy: 60.04%, Learning Rate: 0.33%
Epoch 126, Train Loss: 0.3685, Train Accuracy: 89.14%, Validation Loss: 2.1413, Validation Accuracy: 61.41%, Learning Rate: 0.25%
Epoch 127, Train Loss: 0.2494, Train Accuracy: 92.70%, Validation Loss: 2.1651, Validation Accuracy: 62.04%, Learning Rate: 0.17%
Epoch 128, Train Loss: 0.1744, Train Accuracy: 95.41%, Validation Loss: 2.1301, Validation Accuracy: 62.57%, Learning Rate: 0.10%
Epoch 129, Train Loss: 0.1425, Train Accuracy: 96.49%, Validation Loss: 2.1673, Validation Accuracy: 63.09%, Learning Rate: 0.05%
Epoch 130, Train Loss: 0.1239, Train Accuracy: 96.58%, Validation Loss: 2.1605, Validation Accuracy: 63.20%, Learning Rate: 0.01%
Epoch 131, Train Loss: 0.3124, Train Accuracy: 90.44%, Validation Loss: 2.5950, Validation Accuracy: 52.26%, Learning Rate: 0.50%
Epoch 132, Train Loss: 0.9210, Train Accuracy: 71.45%, Validation Loss: 9.0433, Validation Accuracy: 8.20%, Learning Rate: 0.49%
Epoch 133, Train Loss: 1.0649, Train Accuracy: 67.42%, Validation Loss: 5.7985, Validation Accuracy: 13.04%, Learning Rate: 0.45%
Epoch 134, Train Loss: 0.7612, Train Accuracy: 77.00%, Validation Loss: 6.7273, Validation Accuracy: 9.25%, Learning Rate: 0.40%
Epoch 135, Train Loss: 0.5685, Train Accuracy: 82.83%, Validation Loss: 4.2528, Validation Accuracy: 20.08%, Learning Rate: 0.33%
Epoch 136, Train Loss: 0.3772, Train Accuracy: 88.57%, Validation Loss: 2.1928, Validation Accuracy: 61.83%, Learning Rate: 0.25%
Epoch 137, Train Loss: 0.2411, Train Accuracy: 92.51%, Validation Loss: 2.0765, Validation Accuracy: 62.57%, Learning Rate: 0.17%
Epoch 138, Train Loss: 0.1741, Train Accuracy: 95.31%, Validation Loss: 2.0770, Validation Accuracy: 62.57%, Learning Rate: 0.10%
Epoch 139, Train Loss: 0.1415, Train Accuracy: 95.90%, Validation Loss: 2.0918, Validation Accuracy: 62.99%, Learning Rate: 0.05%
Epoch 140, Train Loss: 0.1141, Train Accuracy: 96.88%, Validation Loss: 2.0800, Validation Accuracy: 63.41%, Learning Rate: 0.01%
Epoch 141, Train Loss: 0.3190, Train Accuracy: 90.15%, Validation Loss: 11.1988, Validation Accuracy: 10.62%, Learning Rate: 0.50%
Epoch 142, Train Loss: 0.9544, Train Accuracy: 71.65%, Validation Loss: 7.0254, Validation Accuracy: 9.25%, Learning Rate: 0.49%
Epoch 143, Train Loss: 1.1003, Train Accuracy: 66.09%, Validation Loss: 2.3984, Validation Accuracy: 46.06%, Learning Rate: 0.45%
Epoch 144, Train Loss: 0.7721, Train Accuracy: 76.09%, Validation Loss: 2.3662, Validation Accuracy: 54.57%, Learning Rate: 0.40%
Epoch 145, Train Loss: 0.5554, Train Accuracy: 82.73%, Validation Loss: 2.1279, Validation Accuracy: 55.73%, Learning Rate: 0.33%
Epoch 146, Train Loss: 0.3726, Train Accuracy: 88.53%, Validation Loss: 2.2298, Validation Accuracy: 59.83%, Learning Rate: 0.25%
Epoch 147, Train Loss: 0.2352, Train Accuracy: 92.92%, Validation Loss: 2.1352, Validation Accuracy: 61.51%, Learning Rate: 0.17%
Epoch 148, Train Loss: 0.1789, Train Accuracy: 95.16%, Validation Loss: 2.1628, Validation Accuracy: 62.36%, Learning Rate: 0.10%
Epoch 149, Train Loss: 0.1184, Train Accuracy: 96.51%, Validation Loss: 2.1587, Validation Accuracy: 63.20%, Learning Rate: 0.05%
Epoch 150, Train Loss: 0.1205, Train Accuracy: 96.73%, Validation Loss: 2.1476, Validation Accuracy: 63.20%, Learning Rate: 0.01%
Epoch 151, Train Loss: 0.2788, Train Accuracy: 91.94%, Validation Loss: 2.7563, Validation Accuracy: 52.58%, Learning Rate: 0.50%
Epoch 152, Train Loss: 0.7569, Train Accuracy: 76.58%, Validation Loss: 9.9319, Validation Accuracy: 6.52%, Learning Rate: 0.49%
Epoch 153, Train Loss: 0.9821, Train Accuracy: 69.34%, Validation Loss: 2.3844, Validation Accuracy: 49.63%, Learning Rate: 0.45%
Epoch 154, Train Loss: 0.8075, Train Accuracy: 75.31%, Validation Loss: 2.3838, Validation Accuracy: 55.21%, Learning Rate: 0.40%
Epoch 155, Train Loss: 0.5914, Train Accuracy: 81.57%, Validation Loss: 7.5986, Validation Accuracy: 10.09%, Learning Rate: 0.33%
Epoch 156, Train Loss: 0.3626, Train Accuracy: 89.14%, Validation Loss: 2.1929, Validation Accuracy: 58.99%, Learning Rate: 0.25%
Epoch 157, Train Loss: 0.2254, Train Accuracy: 93.44%, Validation Loss: 2.1452, Validation Accuracy: 62.15%, Learning Rate: 0.17%
Epoch 158, Train Loss: 0.1558, Train Accuracy: 95.50%, Validation Loss: 2.1095, Validation Accuracy: 61.93%, Learning Rate: 0.10%
Epoch 159, Train Loss: 0.1162, Train Accuracy: 96.95%, Validation Loss: 2.1030, Validation Accuracy: 62.57%, Learning Rate: 0.05%
Epoch 160, Train Loss: 0.0973, Train Accuracy: 97.35%, Validation Loss: 2.1146, Validation Accuracy: 62.36%, Learning Rate: 0.01%
Epoch 161, Train Loss: 0.2772, Train Accuracy: 91.74%, Validation Loss: 5.6835, Validation Accuracy: 15.56%, Learning Rate: 0.50%
Epoch 162, Train Loss: 0.8425, Train Accuracy: 74.15%, Validation Loss: 5.2124, Validation Accuracy: 18.09%, Learning Rate: 0.49%
Epoch 163, Train Loss: 0.9530, Train Accuracy: 70.42%, Validation Loss: 5.7160, Validation Accuracy: 18.40%, Learning Rate: 0.45%
Epoch 164, Train Loss: 0.7466, Train Accuracy: 76.71%, Validation Loss: 4.5811, Validation Accuracy: 16.82%, Learning Rate: 0.40%
Epoch 165, Train Loss: 0.4870, Train Accuracy: 84.84%, Validation Loss: 2.0713, Validation Accuracy: 61.83%, Learning Rate: 0.33%
Epoch 166, Train Loss: 0.3305, Train Accuracy: 90.27%, Validation Loss: 9.2305, Validation Accuracy: 9.36%, Learning Rate: 0.25%
Epoch 167, Train Loss: 0.2140, Train Accuracy: 93.88%, Validation Loss: 2.1899, Validation Accuracy: 61.93%, Learning Rate: 0.17%
Epoch 168, Train Loss: 0.1445, Train Accuracy: 95.95%, Validation Loss: 2.1130, Validation Accuracy: 63.62%, Learning Rate: 0.10%
Epoch 169, Train Loss: 0.1087, Train Accuracy: 97.20%, Validation Loss: 2.1448, Validation Accuracy: 63.41%, Learning Rate: 0.05%
Epoch 170, Train Loss: 0.1083, Train Accuracy: 96.90%, Validation Loss: 2.1348, Validation Accuracy: 63.20%, Learning Rate: 0.01%
Epoch 171, Train Loss: 0.2361, Train Accuracy: 93.17%, Validation Loss: 2.7857, Validation Accuracy: 58.36%, Learning Rate: 0.50%
Epoch 172, Train Loss: 0.6862, Train Accuracy: 78.60%, Validation Loss: 3.6622, Validation Accuracy: 33.54%, Learning Rate: 0.49%
Epoch 173, Train Loss: 0.9750, Train Accuracy: 69.95%, Validation Loss: 2.6617, Validation Accuracy: 44.58%, Learning Rate: 0.45%
Epoch 174, Train Loss: 0.7457, Train Accuracy: 76.73%, Validation Loss: 3.0731, Validation Accuracy: 41.01%, Learning Rate: 0.40%
Epoch 175, Train Loss: 0.5324, Train Accuracy: 83.24%, Validation Loss: 2.1683, Validation Accuracy: 59.31%, Learning Rate: 0.33%
Epoch 176, Train Loss: 0.3431, Train Accuracy: 89.75%, Validation Loss: 2.2594, Validation Accuracy: 61.41%, Learning Rate: 0.25%
Epoch 177, Train Loss: 0.2218, Train Accuracy: 93.39%, Validation Loss: 2.2977, Validation Accuracy: 62.25%, Learning Rate: 0.17%
Epoch 178, Train Loss: 0.1431, Train Accuracy: 96.04%, Validation Loss: 2.1874, Validation Accuracy: 63.09%, Learning Rate: 0.10%
Epoch 179, Train Loss: 0.1152, Train Accuracy: 96.76%, Validation Loss: 2.1867, Validation Accuracy: 62.99%, Learning Rate: 0.05%
Epoch 180, Train Loss: 0.0958, Train Accuracy: 97.59%, Validation Loss: 2.1838, Validation Accuracy: 62.78%, Learning Rate: 0.01%
Epoch 181, Train Loss: 0.2330, Train Accuracy: 93.05%, Validation Loss: 2.8395, Validation Accuracy: 56.68%, Learning Rate: 0.50%
Epoch 182, Train Loss: 0.7953, Train Accuracy: 75.82%, Validation Loss: 4.4324, Validation Accuracy: 17.25%, Learning Rate: 0.49%
Epoch 183, Train Loss: 0.8989, Train Accuracy: 72.21%, Validation Loss: 3.2423, Validation Accuracy: 21.87%, Learning Rate: 0.45%
Epoch 184, Train Loss: 0.7410, Train Accuracy: 76.95%, Validation Loss: 2.3929, Validation Accuracy: 52.58%, Learning Rate: 0.40%
Epoch 185, Train Loss: 0.4758, Train Accuracy: 84.82%, Validation Loss: 2.2530, Validation Accuracy: 60.57%, Learning Rate: 0.33%
Epoch 186, Train Loss: 0.3243, Train Accuracy: 89.68%, Validation Loss: 2.2728, Validation Accuracy: 61.30%, Learning Rate: 0.25%
Epoch 187, Train Loss: 0.2113, Train Accuracy: 93.49%, Validation Loss: 2.2645, Validation Accuracy: 61.72%, Learning Rate: 0.17%
Epoch 188, Train Loss: 0.1393, Train Accuracy: 96.49%, Validation Loss: 2.2233, Validation Accuracy: 62.25%, Learning Rate: 0.10%
Epoch 189, Train Loss: 0.1089, Train Accuracy: 96.78%, Validation Loss: 2.2134, Validation Accuracy: 62.67%, Learning Rate: 0.05%
Epoch 190, Train Loss: 0.1020, Train Accuracy: 97.27%, Validation Loss: 2.2099, Validation Accuracy: 62.57%, Learning Rate: 0.01%
Epoch 191, Train Loss: 0.2585, Train Accuracy: 91.79%, Validation Loss: 6.3546, Validation Accuracy: 11.67%, Learning Rate: 0.50%
Epoch 192, Train Loss: 0.8559, Train Accuracy: 74.15%, Validation Loss: 6.7039, Validation Accuracy: 9.15%, Learning Rate: 0.49%
Epoch 193, Train Loss: 0.9579, Train Accuracy: 70.00%, Validation Loss: 4.7026, Validation Accuracy: 16.72%, Learning Rate: 0.45%
Epoch 194, Train Loss: 0.6836, Train Accuracy: 79.29%, Validation Loss: 2.3651, Validation Accuracy: 53.31%, Learning Rate: 0.40%
Epoch 195, Train Loss: 0.4732, Train Accuracy: 86.00%, Validation Loss: 2.3155, Validation Accuracy: 57.83%, Learning Rate: 0.33%
Epoch 196, Train Loss: 0.3259, Train Accuracy: 90.27%, Validation Loss: 2.2987, Validation Accuracy: 62.04%, Learning Rate: 0.25%
Epoch 197, Train Loss: 0.2036, Train Accuracy: 94.10%, Validation Loss: 2.1233, Validation Accuracy: 61.41%, Learning Rate: 0.17%
Epoch 198, Train Loss: 0.1241, Train Accuracy: 96.54%, Validation Loss: 2.3204, Validation Accuracy: 62.04%, Learning Rate: 0.10%
Epoch 199, Train Loss: 0.1063, Train Accuracy: 97.15%, Validation Loss: 2.2339, Validation Accuracy: 62.46%, Learning Rate: 0.05%
Epoch 200, Train Loss: 0.0907, Train Accuracy: 97.49%, Validation Loss: 2.2450, Validation Accuracy: 62.57%, Learning Rate: 0.01%
---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
<ipython-input-7-fa98badd98ed> in <cell line: 194>()
    192
    193 # Î™®Îç∏ ÌïôÏäµ ÏãúÏûë
--> 194 train_model(train_loader, val_loader, model, optimizer, criterion, scheduler, epochs=300, save_path='/content/drive/MyDrive/ÏßÑÌÇ¥/model_final5.pth')

6 frames
/usr/local/lib/python3.10/dist-packages/PIL/Image.py in open(fp, mode, formats)
   3429
   3430     if filename:
-> 3431         fp = builtins.open(filename, "rb")
   3432         exclusive_fp = True
   3433     else:

KeyboardInterrupt:


## Í≤ÄÏ¶ù Ï†ïÌôïÎèÑ ÏµúÍ≥†Í≤∞Í≥º

Epoch 110, Train Loss: 0.1398, Train Accuracy: 96.02%, Validation Loss: 2.0695, Validation Accuracy: 64.14%, Learning Rate: 0.01%
Model saved with Validation Accuracy: 64.14%

ÏÇ¨Ïã§ÏÉÅ 320 ÏóêÌè≠.



---



##[2-1]


```python
!pip install ujson
```

    Requirement already satisfied: ujson in /usr/local/lib/python3.10/dist-packages (5.10.0)



```python
# Î™®Îì† ÌñâÍ≥º Ïó¥ÏùÑ Ï∂úÎ†•ÌïòÎèÑÎ°ù ÏÑ§Ï†ï
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)
pd.set_option('display.max_colwidth', None)

# Ïù¥ÎØ∏ÏßÄÏôÄ JSON ÌååÏùºÏùò Í≤ΩÎ°ú
image_dir = '/content/drive/MyDrive/dataset/'
training_image_dir = os.path.join(image_dir, 'training_image')
validation_image_dir = os.path.join(image_dir, 'validation_image')
training_label_dir = os.path.join(image_dir, 'training_label')
validation_label_dir = os.path.join(image_dir, 'validation_label')

# Ïù¥ÎØ∏ÏßÄ ÌååÏùºÍ≥º JSON ÌååÏùºÏùò Ìå®ÌÑ¥ Ï†ïÏùò
image_pattern = re.compile(r"^(W|T)_(\d+)_(\d+)_(\w+)_(\w)\.jpg$")
label_pattern = re.compile(r"^(W|T)_(\d+)_(\d+)_(\w+)_(\w)_(\d+)\.json$")

# Ïú†Ìö®Ìïú Ïù¥ÎØ∏ÏßÄ IDÎ•º Ï†ÄÏû•Ìï† ÏßëÌï©
def get_valid_image_ids(image_dir):
    valid_image_ids = set()
    for filename in os.listdir(image_dir):
        if image_pattern.match(filename):
            img_id = image_pattern.match(filename).group(2)
            valid_image_ids.add(img_id)
    return valid_image_ids

# ÌÜµÍ≥Ñ Í≥ÑÏÇ∞ Ìï®Ïàò (Q5 Ìè¨Ìï®)
def calculate_statistics_with_q5(label_dir, valid_image_ids):
    stats = []
    valid_labels = []

    for filename in os.listdir(label_dir):
        match = label_pattern.match(filename)
        if match:
            img_id = match.group(2)
            style = match.group(4)
            gender = "Ïó¨ÏÑ±" if match.group(1) == "W" else "ÎÇ®ÏÑ±"
            if img_id in valid_image_ids:
                with open(os.path.join(label_dir, filename), 'r') as f:
                    data = json.load(f)
                    # ÌÜµÍ≥ÑÏóê ÏÇ¨Ïö©Ìï† Ï†ïÎ≥¥ Ï∂îÍ∞Ä
                    stats.append({"ÏÑ±Î≥Ñ": gender, "Ïä§ÌÉÄÏùº": style, "Ïù¥ÎØ∏ÏßÄ Ïàò": 1})
                    # Q5 Ìè¨Ìï®ÌïòÏó¨ Ïú†Ìö®Ìïú ÎùºÎ≤® Ï†ÄÏû•
                    valid_labels.append({
                        "respondent_id": data["user"]["R_id"],
                        "gender": gender,
                        "style": style,
                        "image_id": img_id,
                        "Q5": data["item"]["survey"]["Q5"],
                        "img_name": data["item"]["imgName"]
                    })

    # ÌÜµÍ≥Ñ Îç∞Ïù¥ÌÑ∞ÌîÑÎ†àÏûÑ ÏÉùÏÑ± Î∞è ÏßëÍ≥Ñ
    stats_df = pd.DataFrame(stats)
    stats_df = stats_df.groupby(["ÏÑ±Î≥Ñ", "Ïä§ÌÉÄÏùº"]).sum().reset_index()
    return stats_df, valid_labels

# Ïú†Ìö®Ìïú Ïù¥ÎØ∏ÏßÄ ID ÌôïÏù∏
valid_training_ids = get_valid_image_ids(training_image_dir)
valid_validation_ids = get_valid_image_ids(validation_image_dir)

# ÌÜµÍ≥Ñ ÌÖåÏù¥Î∏î Î∞è Ïú†Ìö® ÎùºÎ≤® Îç∞Ïù¥ÌÑ∞ ÏÉùÏÑ±
training_stats, valid_training_labels = calculate_statistics_with_q5(training_label_dir, valid_training_ids)
validation_stats, valid_validation_labels = calculate_statistics_with_q5(validation_label_dir, valid_validation_ids)

# Ï∂úÎ†•
print("Training ÌÜµÍ≥ÑÌëú:")
display(training_stats)
print("\nValidation ÌÜµÍ≥ÑÌëú:")
display(validation_stats)
```

    Training ÌÜµÍ≥ÑÌëú:




  <div id="df-5d88f3ba-447c-4a2d-8cd3-fcb301fb9400" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ÏÑ±Î≥Ñ</th>
      <th>Ïä§ÌÉÄÏùº</th>
      <th>Ïù¥ÎØ∏ÏßÄ Ïàò</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>athleisure</td>
      <td>2</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>bodyconscious</td>
      <td>10</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>bold</td>
      <td>18</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>cityglam</td>
      <td>11</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>classic</td>
      <td>21</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>disco</td>
      <td>1</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>ecology</td>
      <td>9</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>genderless</td>
      <td>18</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>grunge</td>
      <td>3</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hiphop</td>
      <td>64</td>
    </tr>
    <tr>
      <th>10</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hippie</td>
      <td>21</td>
    </tr>
    <tr>
      <th>11</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>ivy</td>
      <td>27</td>
    </tr>
    <tr>
      <th>12</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>kitsch</td>
      <td>17</td>
    </tr>
    <tr>
      <th>13</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>lingerie</td>
      <td>7</td>
    </tr>
    <tr>
      <th>14</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>lounge</td>
      <td>20</td>
    </tr>
    <tr>
      <th>15</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>metrosexual</td>
      <td>32</td>
    </tr>
    <tr>
      <th>16</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>military</td>
      <td>1</td>
    </tr>
    <tr>
      <th>17</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>minimal</td>
      <td>17</td>
    </tr>
    <tr>
      <th>18</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>mods</td>
      <td>36</td>
    </tr>
    <tr>
      <th>19</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>normcore</td>
      <td>154</td>
    </tr>
    <tr>
      <th>20</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>oriental</td>
      <td>17</td>
    </tr>
    <tr>
      <th>21</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>popart</td>
      <td>1</td>
    </tr>
    <tr>
      <th>22</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>powersuit</td>
      <td>9</td>
    </tr>
    <tr>
      <th>23</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>punk</td>
      <td>3</td>
    </tr>
    <tr>
      <th>24</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>space</td>
      <td>3</td>
    </tr>
    <tr>
      <th>25</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>sportivecasual</td>
      <td>215</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Ïó¨ÏÑ±</td>
      <td>athleisure</td>
      <td>65</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Ïó¨ÏÑ±</td>
      <td>bodyconscious</td>
      <td>71</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Ïó¨ÏÑ±</td>
      <td>bold</td>
      <td>180</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Ïó¨ÏÑ±</td>
      <td>cityglam</td>
      <td>40</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Ïó¨ÏÑ±</td>
      <td>classic</td>
      <td>54</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Ïó¨ÏÑ±</td>
      <td>disco</td>
      <td>31</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Ïó¨ÏÑ±</td>
      <td>ecology</td>
      <td>36</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Ïó¨ÏÑ±</td>
      <td>feminine</td>
      <td>144</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Ïó¨ÏÑ±</td>
      <td>genderless</td>
      <td>33</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Ïó¨ÏÑ±</td>
      <td>grunge</td>
      <td>16</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hiphop</td>
      <td>216</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hippie</td>
      <td>314</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Ïó¨ÏÑ±</td>
      <td>ivy</td>
      <td>308</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Ïó¨ÏÑ±</td>
      <td>kitsch</td>
      <td>44</td>
    </tr>
    <tr>
      <th>40</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lingerie</td>
      <td>26</td>
    </tr>
    <tr>
      <th>41</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lounge</td>
      <td>12</td>
    </tr>
    <tr>
      <th>42</th>
      <td>Ïó¨ÏÑ±</td>
      <td>metrosexual</td>
      <td>186</td>
    </tr>
    <tr>
      <th>43</th>
      <td>Ïó¨ÏÑ±</td>
      <td>military</td>
      <td>20</td>
    </tr>
    <tr>
      <th>44</th>
      <td>Ïó¨ÏÑ±</td>
      <td>minimal</td>
      <td>114</td>
    </tr>
    <tr>
      <th>45</th>
      <td>Ïó¨ÏÑ±</td>
      <td>mods</td>
      <td>266</td>
    </tr>
    <tr>
      <th>46</th>
      <td>Ïó¨ÏÑ±</td>
      <td>normcore</td>
      <td>165</td>
    </tr>
    <tr>
      <th>47</th>
      <td>Ïó¨ÏÑ±</td>
      <td>oriental</td>
      <td>54</td>
    </tr>
    <tr>
      <th>48</th>
      <td>Ïó¨ÏÑ±</td>
      <td>popart</td>
      <td>32</td>
    </tr>
    <tr>
      <th>49</th>
      <td>Ïó¨ÏÑ±</td>
      <td>powersuit</td>
      <td>96</td>
    </tr>
    <tr>
      <th>50</th>
      <td>Ïó¨ÏÑ±</td>
      <td>punk</td>
      <td>32</td>
    </tr>
    <tr>
      <th>51</th>
      <td>Ïó¨ÏÑ±</td>
      <td>space</td>
      <td>28</td>
    </tr>
    <tr>
      <th>52</th>
      <td>Ïó¨ÏÑ±</td>
      <td>sportivecasual</td>
      <td>288</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-5d88f3ba-447c-4a2d-8cd3-fcb301fb9400')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-5d88f3ba-447c-4a2d-8cd3-fcb301fb9400 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-5d88f3ba-447c-4a2d-8cd3-fcb301fb9400');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-a2188f00-9c07-4d9e-9eee-be4d0a8cd9e8">
  <button class="colab-df-quickchart" onclick="quickchart('df-a2188f00-9c07-4d9e-9eee-be4d0a8cd9e8')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-a2188f00-9c07-4d9e-9eee-be4d0a8cd9e8 button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_5d2a27d1-ead8-4217-b1cb-8ab3b54f28b3">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('training_stats')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_5d2a27d1-ead8-4217-b1cb-8ab3b54f28b3 button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('training_stats');
      }
      })();
    </script>
  </div>

    </div>
  </div>



    
    Validation ÌÜµÍ≥ÑÌëú:




  <div id="df-f15cef79-2f68-42d7-88ea-661ee8d6f914" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ÏÑ±Î≥Ñ</th>
      <th>Ïä§ÌÉÄÏùº</th>
      <th>Ïù¥ÎØ∏ÏßÄ Ïàò</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>bodyconscious</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>bold</td>
      <td>3</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>cityglam</td>
      <td>2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>classic</td>
      <td>5</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>ecology</td>
      <td>1</td>
    </tr>
    <tr>
      <th>5</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hiphop</td>
      <td>3</td>
    </tr>
    <tr>
      <th>6</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>hippie</td>
      <td>1</td>
    </tr>
    <tr>
      <th>7</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>ivy</td>
      <td>3</td>
    </tr>
    <tr>
      <th>8</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>mods</td>
      <td>1</td>
    </tr>
    <tr>
      <th>9</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>normcore</td>
      <td>4</td>
    </tr>
    <tr>
      <th>10</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>oriental</td>
      <td>2</td>
    </tr>
    <tr>
      <th>11</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>popart</td>
      <td>1</td>
    </tr>
    <tr>
      <th>12</th>
      <td>ÎÇ®ÏÑ±</td>
      <td>sportivecasual</td>
      <td>17</td>
    </tr>
    <tr>
      <th>13</th>
      <td>Ïó¨ÏÑ±</td>
      <td>athleisure</td>
      <td>16</td>
    </tr>
    <tr>
      <th>14</th>
      <td>Ïó¨ÏÑ±</td>
      <td>bodyconscious</td>
      <td>23</td>
    </tr>
    <tr>
      <th>15</th>
      <td>Ïó¨ÏÑ±</td>
      <td>bold</td>
      <td>47</td>
    </tr>
    <tr>
      <th>16</th>
      <td>Ïó¨ÏÑ±</td>
      <td>cityglam</td>
      <td>13</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Ïó¨ÏÑ±</td>
      <td>classic</td>
      <td>22</td>
    </tr>
    <tr>
      <th>18</th>
      <td>Ïó¨ÏÑ±</td>
      <td>disco</td>
      <td>7</td>
    </tr>
    <tr>
      <th>19</th>
      <td>Ïó¨ÏÑ±</td>
      <td>ecology</td>
      <td>18</td>
    </tr>
    <tr>
      <th>20</th>
      <td>Ïó¨ÏÑ±</td>
      <td>feminine</td>
      <td>46</td>
    </tr>
    <tr>
      <th>21</th>
      <td>Ïó¨ÏÑ±</td>
      <td>genderless</td>
      <td>7</td>
    </tr>
    <tr>
      <th>22</th>
      <td>Ïó¨ÏÑ±</td>
      <td>grunge</td>
      <td>3</td>
    </tr>
    <tr>
      <th>23</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hiphop</td>
      <td>66</td>
    </tr>
    <tr>
      <th>24</th>
      <td>Ïó¨ÏÑ±</td>
      <td>hippie</td>
      <td>114</td>
    </tr>
    <tr>
      <th>25</th>
      <td>Ïó¨ÏÑ±</td>
      <td>ivy</td>
      <td>127</td>
    </tr>
    <tr>
      <th>26</th>
      <td>Ïó¨ÏÑ±</td>
      <td>kitsch</td>
      <td>11</td>
    </tr>
    <tr>
      <th>27</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lingerie</td>
      <td>5</td>
    </tr>
    <tr>
      <th>28</th>
      <td>Ïó¨ÏÑ±</td>
      <td>lounge</td>
      <td>5</td>
    </tr>
    <tr>
      <th>29</th>
      <td>Ïó¨ÏÑ±</td>
      <td>metrosexual</td>
      <td>54</td>
    </tr>
    <tr>
      <th>30</th>
      <td>Ïó¨ÏÑ±</td>
      <td>military</td>
      <td>8</td>
    </tr>
    <tr>
      <th>31</th>
      <td>Ïó¨ÏÑ±</td>
      <td>minimal</td>
      <td>40</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Ïó¨ÏÑ±</td>
      <td>mods</td>
      <td>99</td>
    </tr>
    <tr>
      <th>33</th>
      <td>Ïó¨ÏÑ±</td>
      <td>normcore</td>
      <td>35</td>
    </tr>
    <tr>
      <th>34</th>
      <td>Ïó¨ÏÑ±</td>
      <td>oriental</td>
      <td>11</td>
    </tr>
    <tr>
      <th>35</th>
      <td>Ïó¨ÏÑ±</td>
      <td>popart</td>
      <td>10</td>
    </tr>
    <tr>
      <th>36</th>
      <td>Ïó¨ÏÑ±</td>
      <td>powersuit</td>
      <td>22</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Ïó¨ÏÑ±</td>
      <td>punk</td>
      <td>3</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Ïó¨ÏÑ±</td>
      <td>space</td>
      <td>18</td>
    </tr>
    <tr>
      <th>39</th>
      <td>Ïó¨ÏÑ±</td>
      <td>sportivecasual</td>
      <td>92</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">

  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-f15cef79-2f68-42d7-88ea-661ee8d6f914')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>

  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-f15cef79-2f68-42d7-88ea-661ee8d6f914 button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-f15cef79-2f68-42d7-88ea-661ee8d6f914');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>


<div id="df-86bcaa79-bee4-42de-973b-1805704696ba">
  <button class="colab-df-quickchart" onclick="quickchart('df-86bcaa79-bee4-42de-973b-1805704696ba')"
            title="Suggest charts"
            style="display:none;">

<svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
     width="24px">
    <g>
        <path d="M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z"/>
    </g>
</svg>
  </button>

<style>
  .colab-df-quickchart {
      --bg-color: #E8F0FE;
      --fill-color: #1967D2;
      --hover-bg-color: #E2EBFA;
      --hover-fill-color: #174EA6;
      --disabled-fill-color: #AAA;
      --disabled-bg-color: #DDD;
  }

  [theme=dark] .colab-df-quickchart {
      --bg-color: #3B4455;
      --fill-color: #D2E3FC;
      --hover-bg-color: #434B5C;
      --hover-fill-color: #FFFFFF;
      --disabled-bg-color: #3B4455;
      --disabled-fill-color: #666;
  }

  .colab-df-quickchart {
    background-color: var(--bg-color);
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: none;
    fill: var(--fill-color);
    height: 32px;
    padding: 0;
    width: 32px;
  }

  .colab-df-quickchart:hover {
    background-color: var(--hover-bg-color);
    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);
    fill: var(--button-hover-fill-color);
  }

  .colab-df-quickchart-complete:disabled,
  .colab-df-quickchart-complete:disabled:hover {
    background-color: var(--disabled-bg-color);
    fill: var(--disabled-fill-color);
    box-shadow: none;
  }

  .colab-df-spinner {
    border: 2px solid var(--fill-color);
    border-color: transparent;
    border-bottom-color: var(--fill-color);
    animation:
      spin 1s steps(1) infinite;
  }

  @keyframes spin {
    0% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
      border-left-color: var(--fill-color);
    }
    20% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    30% {
      border-color: transparent;
      border-left-color: var(--fill-color);
      border-top-color: var(--fill-color);
      border-right-color: var(--fill-color);
    }
    40% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-top-color: var(--fill-color);
    }
    60% {
      border-color: transparent;
      border-right-color: var(--fill-color);
    }
    80% {
      border-color: transparent;
      border-right-color: var(--fill-color);
      border-bottom-color: var(--fill-color);
    }
    90% {
      border-color: transparent;
      border-bottom-color: var(--fill-color);
    }
  }
</style>

  <script>
    async function quickchart(key) {
      const quickchartButtonEl =
        document.querySelector('#' + key + ' button');
      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.
      quickchartButtonEl.classList.add('colab-df-spinner');
      try {
        const charts = await google.colab.kernel.invokeFunction(
            'suggestCharts', [key], {});
      } catch (error) {
        console.error('Error during call to suggestCharts:', error);
      }
      quickchartButtonEl.classList.remove('colab-df-spinner');
      quickchartButtonEl.classList.add('colab-df-quickchart-complete');
    }
    (() => {
      let quickchartButtonEl =
        document.querySelector('#df-86bcaa79-bee4-42de-973b-1805704696ba button');
      quickchartButtonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';
    })();
  </script>
</div>

  <div id="id_a08bcf84-4232-4add-91df-e18eb3d6c82b">
    <style>
      .colab-df-generate {
        background-color: #E8F0FE;
        border: none;
        border-radius: 50%;
        cursor: pointer;
        display: none;
        fill: #1967D2;
        height: 32px;
        padding: 0 0 0 0;
        width: 32px;
      }

      .colab-df-generate:hover {
        background-color: #E2EBFA;
        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
        fill: #174EA6;
      }

      [theme=dark] .colab-df-generate {
        background-color: #3B4455;
        fill: #D2E3FC;
      }

      [theme=dark] .colab-df-generate:hover {
        background-color: #434B5C;
        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
        fill: #FFFFFF;
      }
    </style>
    <button class="colab-df-generate" onclick="generateWithVariable('validation_stats')"
            title="Generate code using this dataframe."
            style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z"/>
  </svg>
    </button>
    <script>
      (() => {
      const buttonEl =
        document.querySelector('#id_a08bcf84-4232-4add-91df-e18eb3d6c82b button.colab-df-generate');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      buttonEl.onclick = () => {
        google.colab.notebook.generateWithVariable('validation_stats');
      }
      })();
    </script>
  </div>

    </div>
  </div>





---



##[2-2] [2-1]ÎèÑ Ï∂úÎ†• Í∞ôÏù¥ ÎÇòÏò¥. ÏÇ¨Ïã§ÏÉÅ Ïù¥ ÏΩîÎìúÍ∞Ä ÎØ∏ÏÖò 2 ÏûêÏ≤¥


```python
import os
import re
import json
from collections import defaultdict, Counter
import pandas as pd

# Îç∞Ïù¥ÌÑ∞ ÎîîÎ†âÌÑ∞Î¶¨ Í≤ΩÎ°ú
train_image_dir = '/content/drive/MyDrive/dataset/training_image'
val_image_dir = '/content/drive/MyDrive/dataset/validation_image'

train_label_dir = '/content/drive/MyDrive/dataset/training_label'
val_label_dir = '/content/drive/MyDrive/dataset/validation_label'

# Ï†ïÍ∑ú ÌëúÌòÑÏãù Ìå®ÌÑ¥ Ï†ïÏùò
image_pattern = re.compile(r'^(W|T)_(\d+)_(.*?)_(.*?)_(W|M)\.jpg$')
label_pattern = re.compile(r'^(W|T)_(\d+)_(.*?)_(.*?)_(W|M)_(\d+)\.json$')

# Ïú†Ìö®Ìïú Ïù¥ÎØ∏ÏßÄ ID Í∞ÄÏ†∏Ïò§Îäî Ìï®Ïàò
def get_valid_image_ids(image_dir):
    image_ids = set()
    for filename in os.listdir(image_dir):
        match = image_pattern.match(filename)
        if match:
            W_T, image_id, era, style, gender = match.groups()
            image_ids.add(image_id)
    return image_ids

# ÎùºÎ≤® Îç∞Ïù¥ÌÑ∞Î•º Ï≤òÎ¶¨ÌïòÎäî Ìï®Ïàò
def process_labeling_data(label_dir, valid_image_ids, dataset_name):
    stats = defaultdict(int)
    respondent_counts = defaultdict(int)
    style_preferences = defaultdict(lambda: defaultdict(list))  # R_id -> {'ÏÑ†Ìò∏ Ïä§ÌÉÄÏùº': [ÌååÏùºÎ™Ö], ...}
    all_r_ids = set()

    for filename in os.listdir(label_dir):
        match = label_pattern.match(filename)
        if match:
            W_T, image_id, era, style, gender, survey_id = match.groups()

            # Ïú†Ìö®Ìïú Ïù¥ÎØ∏ÏßÄ IDÎßå Ï≤òÎ¶¨
            if image_id not in valid_image_ids:
                continue

            # ÏÑ±Î≥Ñ Îß§Ìïë ('W'Îäî 'Ïó¨ÏÑ±', 'M'ÏùÄ 'ÎÇ®ÏÑ±')
            if gender == 'W':
                gender_label = 'Female'
            elif gender == 'M':
                gender_label = 'Male'
            else:
                continue

            label = f"{gender_label}_{style}"

            # ÏÑ±Î≥Ñ Î∞è Ïä§ÌÉÄÏùºÎ≥Ñ Ï°∞ÏÇ¨ ID Ïπ¥Ïö¥ÌåÖ
            stats[label] += 1

            # JSON ÌååÏùº ÏùΩÍ∏∞
            json_path = os.path.join(label_dir, filename)
            with open(json_path, 'r') as f:
                data = json.load(f)

            # ÏùëÎãµÏûê ID Î∞è Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑ Í∞ÄÏ†∏Ïò§Í∏∞
            R_id = data['user']['R_id']
            Q5 = data['item']['survey'].get('Q5', None)

            # ÏùëÎãµÏûê Ï†ïÎ≥¥ ÏàòÏßë
            respondent_counts[R_id] += 1
            all_r_ids.add(R_id)

            if Q5 is not None:
                preference = 'Preferred' if Q5 == 2 else 'Not Preferred' if Q5 == 1 else 'Unknown'
                if preference in ['Preferred', 'Not Preferred']:
                    # ÏÑ†Ìò∏ Ïó¨Î∂ÄÏôÄ Ïó∞Í¥ÄÎêú ÌååÏùºÎ™Ö Ï†ÄÏû•
                    full_filename = data['imgName']  # 'imgName'Ïù¥ JSONÏóê ÏûàÎã§Í≥† Í∞ÄÏ†ï
                    key = f"{dataset_name} Style {preference}"
                    style_preferences[R_id][key].append(full_filename)

    return stats, respondent_counts, style_preferences, all_r_ids

# ÌÜµÍ≥Ñ ÌÖåÏù¥Î∏î ÏÉùÏÑ± Ìï®Ïàò
def create_stats_table(stats):
    # ÏÑ±Î≥ÑÍ≥º Ïä§ÌÉÄÏùº Ï∂îÏ∂ú
    gender_style_counts = defaultdict(lambda: defaultdict(int))
    for label, count in stats.items():
        gender, style = label.split('_', 1)
        gender_style_counts[gender][style] += count

    # DataFrame ÏÉùÏÑ±
    df = pd.DataFrame(gender_style_counts).fillna(0).astype(int).sort_index()
    df = df.transpose()
    df['Total'] = df.sum(axis=1)
    df.loc['Total'] = df.sum()

    return df

# ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
print("ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ï§ë...")
train_valid_image_ids = get_valid_image_ids(train_image_dir)
train_stats, train_respondent_counts, train_style_preferences, train_r_ids = process_labeling_data(
    train_label_dir, train_valid_image_ids, 'Training')

train_stats_table = create_stats_table(train_stats)
print("ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ:")
print(train_stats_table)

# Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨
print("\nÍ≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ï§ë...")
val_valid_image_ids = get_valid_image_ids(val_image_dir)
val_stats, val_respondent_counts, val_style_preferences, val_r_ids = process_labeling_data(
    val_label_dir, val_valid_image_ids, 'Validation')

val_stats_table = create_stats_table(val_stats)
print("Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ:")
print(val_stats_table)

# Î™®Îì† ÏùëÎãµÏûêÏùò Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑÎ•º Í≤∞Ìï©
combined_style_preferences = defaultdict(lambda: defaultdict(list))

all_r_ids = train_style_preferences.keys() | val_style_preferences.keys()

for R_id in all_r_ids:
    # ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÏÑ†Ìò∏ÎèÑ Î≥ëÌï©
    for key, filenames in train_style_preferences.get(R_id, {}).items():
        combined_style_preferences[R_id][key].extend(filenames)
    # Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÏÑ†Ìò∏ÎèÑ Î≥ëÌï©
    for key, filenames in val_style_preferences.get(R_id, {}).items():
        combined_style_preferences[R_id][key].extend(filenames)

# ÏùëÎãµÏûê ÏàòÎ•º Ìï©ÏÇ∞
total_respondent_counts = Counter()
for R_id in all_r_ids:
    total_responses = train_respondent_counts.get(R_id, 0) + val_respondent_counts.get(R_id, 0)
    total_respondent_counts[R_id] = total_responses

# Ï¥ù ÏùëÎãµ ÏàòÎ•º Í∏∞Ï§ÄÏúºÎ°ú ÏÉÅÏúÑ 100Î™Ö Ï∂îÏ∂ú
top_respondents = total_respondent_counts.most_common(100)
top_r_ids = [R_id for R_id, count in top_respondents]

# DataFrame ÏÉùÏÑ±ÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Ï§ÄÎπÑ
rows = []
for R_id in top_r_ids:
    preferences = combined_style_preferences.get(R_id, {})
    row = {
        'Respondent ID': R_id,
        'Training Style Preferred': ', '.join(preferences.get('Training Style Preferred', [])),
        'Training Style Not Preferred': ', '.join(preferences.get('Training Style Not Preferred', [])),
        'Validation Style Preferred': ', '.join(preferences.get('Validation Style Preferred', [])),
        'Validation Style Not Preferred': ', '.join(preferences.get('Validation Style Not Preferred', [])),
    }
    rows.append(row)

# ÏÉÅÏúÑ 100Î™ÖÏùò ÏùëÎãµÏûê Îç∞Ïù¥ÌÑ∞Î•º DataFrameÏúºÎ°ú ÏÉùÏÑ±
top_preference_df = pd.DataFrame(rows)

# DataFrameÏùÑ Excel ÌååÏùºÎ°ú Ï†ÄÏû•
output_excel_path = '/content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ Ï∫†ÌîÑ ÏµúÏ¢Ö Ï†ïÎ¶¨/ÍπÄÏßÑ/top_100_respondents_preferences.xlsx'
top_preference_df.to_excel(output_excel_path, index=False, engine='openpyxl')
print(f"\nÏÉÅÏúÑ 100Î™ÖÏùò ÏùëÎãµÏûê ÏÑ†Ìò∏ÎèÑÍ∞Ä {output_excel_path}Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.")


# DataFrame Ï∂úÎ†•
print("\nÏÉÅÏúÑ 100Î™ÖÏùò ÏùëÎãµÏûê Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑ Ï†ïÎ≥¥ ÌÖåÏù¥Î∏î:")
print(top_preference_df.head())

```

    ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ï§ë...
    ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ:
            athleisure  bodyconscious  bold  cityglam  classic  disco  ecology  \
    Female          67             81     0        51       75     32       45   
    Male             0              0   198         0        0      0        0   
    Total           67             81   198        51       75     32       45   
    
            feminine  genderless  grunge  hiphop  hippie  ivy  kitsch  lingerie  \
    Female       144          51      19      50      62    0      61        33   
    Male           0           0       0     230     273  335       0         0   
    Total        144          51      19     280     335  335      61        33   
    
            lounge  metrosexual  military  minimal  mods  normcore  oriental  \
    Female      32            0        21      131     0       119        71   
    Male         0          218         0        0   302       200         0   
    Total       32          218        21      131   302       319        71   
    
            popart  powersuit  punk  space  sportivecasual  Total  
    Female      33        105    35     31             205   1554  
    Male         0          0     0      0             298   2054  
    Total       33        105    35     31             503   3608  
    
    Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ Ï≤òÎ¶¨ Ï§ë...
    Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÌÜµÍ≥Ñ:
            athleisure  bodyconscious  bold  cityglam  classic  disco  ecology  \
    Male             0              0    50         0        0      0        0   
    Female          16             24     0        15       27      7       19   
    Total           16             24    50        15       27      7       19   
    
            feminine  genderless  grunge  hiphop  hippie  ivy  kitsch  lingerie  \
    Male           0           0       0      58     105  130       0         0   
    Female        46           7       3      11      10    0      11         5   
    Total         46           7       3      69     115  130      11         5   
    
            lounge  metrosexual  military  minimal  mods  normcore  oriental  \
    Male         0           54         0        0   100        24         0   
    Female       5            0         8       40     0        15        13   
    Total        5           54         8       40   100        39        13   
    
            popart  powersuit  punk  space  sportivecasual  Total  
    Male         0          0     0      0              47    568  
    Female      11         22     3     18              62    398  
    Total       11         22     3     18             109    966  
    
    ÏÉÅÏúÑ 100Î™ÖÏùò ÏùëÎãµÏûê ÏÑ†Ìò∏ÎèÑÍ∞Ä /content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ Ï∫†ÌîÑ ÏµúÏ¢Ö Ï†ïÎ¶¨/ÍπÄÏßÑ/top_100_respondents_preferences.xlsxÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.
    
    ÏÉÅÏúÑ 100Î™ÖÏùò ÏùëÎãµÏûê Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑ Ï†ïÎ≥¥ ÌÖåÏù¥Î∏î:
       Respondent ID  \
    0          64221   
    1          21432   
    2          63913   
    3          60184   
    4          60234   
    
                                                                                                                                            Training Style Preferred  \
    0                            W_28698_10_sportivecasual_M.jpg, W_25039_90_hiphop_M.jpg, W_32524_00_metrosexual_M.jpg, W_28728_50_ivy_M.jpg, W_24013_60_mods_M.jpg   
    1                                     W_28523_90_hiphop_M.jpg, W_09891_90_hiphop_M.jpg, W_29023_00_metrosexual_M.jpg, W_15294_50_ivy_M.jpg, W_32448_50_ivy_M.jpg   
    2  W_00553_10_sportivecasual_M.jpg, W_07066_10_sportivecasual_M.jpg, W_07255_50_ivy_M.jpg, W_07150_70_hippie_M.jpg, W_06573_60_mods_M.jpg, W_06883_60_mods_M.jpg   
    3                                                                                  W_01687_19_normcore_M.jpg, W_17427_00_metrosexual_M.jpg, W_17348_50_ivy_M.jpg   
    4                                              W_01693_19_normcore_M.jpg, W_17337_50_ivy_M.jpg, W_16539_50_ivy_M.jpg, W_07102_50_ivy_M.jpg, W_12748_50_ivy_M.jpg   
    
                                                                                                                                                                                                  Training Style Not Preferred  \
    0                                                   W_26397_70_hippie_M.jpg, W_25471_70_hippie_M.jpg, W_12130_80_bold_M.jpg, W_28207_90_hiphop_M.jpg, W_17747_80_bold_M.jpg, W_15129_50_ivy_M.jpg, W_07333_70_hippie_M.jpg   
    1  W_29224_10_sportivecasual_M.jpg, W_26017_10_sportivecasual_M.jpg, W_26151_80_bold_M.jpg, W_26296_70_hippie_M.jpg, W_12383_80_bold_M.jpg, W_24439_00_metrosexual_M.jpg, W_26397_70_hippie_M.jpg, W_25107_70_hippie_M.jpg   
    2                                                                                                           W_17009_19_normcore_M.jpg, W_16444_10_sportivecasual_M.jpg, W_15843_00_metrosexual_M.jpg, W_10066_50_ivy_M.jpg   
    3          W_12453_10_sportivecasual_M.jpg, W_12095_80_bold_M.jpg, W_28377_80_bold_M.jpg, W_27913_00_metrosexual_M.jpg, W_25030_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_16016_70_hippie_M.jpg, W_04245_70_hippie_M.jpg   
    4                        W_17508_80_bold_M.jpg, W_02844_90_hiphop_M.jpg, W_16755_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_16673_70_hippie_M.jpg, W_15423_80_bold_M.jpg, W_06546_60_mods_M.jpg, W_15259_60_mods_M.jpg   
    
                                                     Validation Style Preferred  \
    0                  W_28925_90_hiphop_M.jpg, W_25086_10_sportivecasual_M.jpg   
    1  W_06522_50_ivy_M.jpg, W_15294_50_ivy_M.jpg, W_29023_00_metrosexual_M.jpg   
    2                                                     W_06883_60_mods_M.jpg   
    3                                                                             
    4                                                     W_10107_60_mods_M.jpg   
    
                                                                                                            Validation Style Not Preferred  
    0                                W_17747_80_bold_M.jpg, W_07333_70_hippie_M.jpg, W_26397_70_hippie_M.jpg, W_02936_00_metrosexual_M.jpg  
    1                                                                                                              W_26397_70_hippie_M.jpg  
    2  W_10066_50_ivy_M.jpg, W_15843_00_metrosexual_M.jpg, W_15947_80_bold_M.jpg, W_16444_10_sportivecasual_M.jpg, W_05876_70_hippie_M.jpg  
    3                              W_12744_50_ivy_M.jpg, W_04245_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_12453_10_sportivecasual_M.jpg  
    4                                                                                                         W_16755_00_metrosexual_M.jpg  




---



##[3-1]

[3-1]

### Ï†ïÏùò
 - ÏïÑÏù¥ÌÖú Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ (Item-based Filtering): ÏÇ¨Ïö©ÏûêÎì§Ïù¥ ÏÑ†Ìò∏ÌïòÎäî Ìï≠Î™© Í∞ÑÏùò Ïú†ÏÇ¨ÏÑ±ÏùÑ Î∂ÑÏÑùÌïòÏó¨, ÏÇ¨Ïö©ÏûêÍ∞Ä Ï¢ãÏïÑÌïòÎäî Ìï≠Î™©Í≥º Ïú†ÏÇ¨Ìïú Îã§Î•∏ Ìï≠Î™©ÏùÑ Ï∂îÏ≤úÌïòÎäî Î∞©Î≤ïÏù¥Îã§. Ïù¥ Î∞©ÏãùÏùÄ ÏÇ¨Ïö©ÏûêÎì§ Í∞ÑÏùò Ïú†ÏÇ¨ÏÑ±Î≥¥Îã§Îäî ÏïÑÏù¥ÌÖú Í∞ÑÏùò Í¥ÄÍ≥ÑÏóê Ï¥àÏ†êÏùÑ ÎßûÏ∂òÎã§.

 - ÏÇ¨Ïö©Ïûê Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ (User-based Filtering): ÎπÑÏä∑Ìïú Ï∑®Ìñ•ÏùÑ Í∞ÄÏßÑ ÏÇ¨Ïö©ÏûêÎì§ Í∞ÑÏùò Í¥ÄÍ≥ÑÎ•º Î∂ÑÏÑùÌïòÏó¨, Ïú†ÏÇ¨Ìïú ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†Ìò∏ÌïòÎäî Ìï≠Î™©ÏùÑ Ï∂îÏ≤úÌïòÎäî Î∞©Î≤ïÏù¥Îã§. Ïù¥ Î∞©ÏãùÏùÄ ÏÇ¨Ïö©ÏûêÏùòÍ≥ºÍ±∞ ÏÑ†Ìò∏ÎèÑÏôÄ Îã§Î•∏ ÏÇ¨Ïö©ÏûêÏùò ÌñâÎèôÏùÑ Í∏∞Î∞òÏúºÎ°ú Ï∂îÏ≤úÏùÑ ÏÉùÏÑ±ÌïúÎã§.  

 #### 1.ÏïÑÏù¥ÌÖú Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ
 ##### Ï†ÅÏö©Î∞©Î≤ï
  - Ïú†ÏÇ¨ÏÑ± Ï∏°Ï†ï: ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†Ìò∏Ìïú Ïä§ÌÉÄÏùº(2)ÏùÑ Î∞îÌÉïÏúºÎ°ú Ïä§ÌÉÄÏùº Í∞ÑÏùò Ïú†ÏÇ¨ÏÑ±ÏùÑ Í≥ÑÏÇ∞ÌïúÎã§.ÏòàÎ•º Îì§Ïñ¥, ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ(cosine similarity) ÎòêÎäî ÏûêÏπ¥Îìú Ïú†ÏÇ¨ÎèÑ(Jaccardsimilarity) Îì±ÏùÑ ÏÇ¨Ïö©ÌïòÏó¨ Ïä§ÌÉÄÏùº Í∞ÑÏùò Í¥ÄÍ≥ÑÎ•º Î∂ÑÏÑùÌïúÎã§.
  
  - Ï∂îÏ≤ú ÏÉùÏÑ±: ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†Ìò∏ÌïòÎäî Ïä§ÌÉÄÏùºÍ≥º Ïú†ÏÇ¨Ìïú Îã§Î•∏ Ïä§ÌÉÄÏùºÏùÑ Ï∂îÏ≤úÌïúÎã§. ÏÇ¨Ïö©ÏûêÍ∞Ä A Ïä§ÌÉÄÏùºÏùÑ ÏÑ†Ìò∏ÌïúÎã§Î©¥, A Ïä§ÌÉÄÏùºÍ≥º Ïú†ÏÇ¨Ìïú B, C, D Ïä§ÌÉÄÏùºÏùÑ Ï∂îÏ≤úÌï† Ïàò ÏûàÎã§.

 ##### Ïû•Ï†ê
  - ÏÇ¨Ïö©ÏûêÏùò ÏûêÏã†Ïùò ÌèâÍ∞Ä Îç∞Ïù¥ÌÑ∞Î•º ÌôúÏö©ÌïòÏó¨ Ï∂îÏ≤úÏùÑ ÏàòÌñâÌïòÍ∏∞ ÎïåÎ¨∏Ïóê Îçî Í¥ÄÎ†®ÏÑ± ÎÜíÏùÄ Ï∂îÏ≤úÏ†úÍ≥µÌïúÎã§.
   
  - Îã§ÏñëÌïú Ìï≠Î™©ÏùÑ Ï∂îÏ≤úÌï† Í∞ÄÎä•ÏÑ±Ïù¥ ÎÜíÏïÑ Ï∂îÏ≤ú Î™©Î°ùÏùò Îã§ÏñëÏÑ± Îçî Ïª§ÏßÑÎã§.

  - ÎπÑÏÑ†Ìò∏ Ïä§ÌÉÄÏùºÏóê ÎåÄÌïú Ï†ïÎ≥¥Í∞Ä Î∂ÄÏ°±ÌïòÎçîÎùºÎèÑ, Ïù¥ÎØ∏ ÏÑ†Ìò∏Ìïú Ïä§ÌÉÄÏùºÏùÑ Í∏∞Î∞òÏúºÎ°ú Ï∂îÏ≤úÏù¥ Ïù¥Î£®Ïñ¥ÏßÄÎØÄÎ°ú Ï∂îÏ≤úÏùò ÏßàÏù¥ ÎπÑÍµêÏ†Å ÏïàÏ†ïÏ†ÅÏù¥Îã§.

  - Ïä§ÌÉÄÏùºÏùò ÌäπÏÑ±ÏùÑ Î∂ÑÏÑùÌïòÏó¨ Ïú†ÏÇ¨Ìïú Ïä§ÌÉÄÏùºÏùÑ Ï∂îÏ≤úÌï®ÏúºÎ°úÏç®, ÏÇ¨Ïö©ÏûêÏùò Ï∑®Ìñ•ÏùÑ Ïûò Î∞òÏòÅÌï† Ïàò ÏûàÎã§.

  - Í∏∞Ï°¥ Ïä§ÌÉÄÏùºÍ≥ºÏùò Ïú†ÏÇ¨ÏÑ±ÏùÑ ÌôúÏö©ÌïòÏó¨ ÏÉàÎ°úÏö¥ Ïä§ÌÉÄÏùºÏùÑ Ï∂îÏ≤úÌï† ÏàòÏûàÎäî Ïú†Ïó∞ÏÑ±ÏùÑ Í∞ÄÏßÑÎã§.

   ##### Îã®Ï†ê
   - Ïù¥ÏõÉ ÏÇ¨Ïö©ÏûêÏùò Ï†ïÎ≥¥Í∞Ä ÏùµÎ™ÖÏúºÎ°ú Ï≤òÎ¶¨ÎêòÍ∏∞ ÎïåÎ¨∏Ïóê ÏÑ§Î™ÖÌïòÍ∏∞ Ïñ¥Î†µÎã§.

   - Ïä§ÌÉÄÏùº Í∞ÑÏùò Ïú†ÏÇ¨ÏÑ±ÏùÑ Ï†úÎåÄÎ°ú Î∂ÑÏÑùÌïòÏßÄ Î™ªÌïòÎ©¥ Ï∂îÏ≤úÏùò ÌíàÏßàÏù¥Îñ®Ïñ¥Ïßà Ïàò ÏûàÎã§.

   #### 2.ÏÇ¨Ïö©Ïûê Í∏∞Î∞ò ÌïÑÌÑ∞ÎßÅ
   ##### Ï†ÅÏö©Î∞©Î≤ï
   - Ïú†ÏÇ¨ ÏÇ¨Ïö©Ïûê Ï∏°Ï†ï: ÏÇ¨Ïö©ÏûêÏùò ÏÑ†Ìò∏(2)ÏôÄ ÎπÑÏÑ†Ìò∏(1) Îç∞Ïù¥ÌÑ∞Î•º Î∞îÌÉïÏúºÎ°ú Ïú†ÏÇ¨Ìïú ÏÇ¨Ïö©ÏûêÎ•º Ï∞æÎäîÎã§. Ïù¥Îïå, ÏÇ¨Ïö©ÏûêÏùò ÎπÑÏÑ†Ìò∏ Ï†ïÎ≥¥ÎèÑ Ìè¨Ìï®ÌïòÏó¨ Ïú†ÏÇ¨ÏÑ±ÏùÑ Î∂ÑÏÑùÌïúÎã§.

   - Ï∂îÏ≤ú ÏÉùÏÑ±: Ïú†ÏÇ¨Ìïú ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†Ìò∏ÌïòÎäî Ïä§ÌÉÄÏùºÏùÑ Ï∂îÏ≤úÌïúÎã§. ÏòàÎ•º Îì§Ïñ¥, ÏÇ¨Ïö©ÏûêÍ∞Ä B Ïä§ÌÉÄÏùºÏùÑ ÎπÑÏÑ†Ìò∏ÌïòÎäî Í≤ΩÏö∞, Í∑∏ÏôÄ ÎπÑÏä∑Ìïú ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†Ìò∏ÌïòÎäî Îã§Î•∏ Ïä§ÌÉÄÏùºÏùÑ Ï∂îÏ≤úÌï† Ïàò ÏûàÎã§.

   ##### Ïû•Ï†ê
   - ÏÇ¨Ïö©ÏûêÏùò Ï∑®Ìñ•ÏùÑ Î∞òÏòÅÌïú Ï∂îÏ≤úÏù¥ Í∞ÄÎä•ÌïòÏó¨, Í∞úÏù∏ÌôîÎêú Í≤ΩÌóòÏùÑ Ï†úÍ≥µÌï† Ïàò ÏûàÎã§. ‚Üí Ï∂îÏ≤úÏùò Ïù¥Ïú†Î•º Î™ÖÌôïÌïòÍ≤å ÏÑ§Î™ÖÌï† Ïàò ÏûàÎã§.

   - ÎπÑÏä∑Ìïú Ï∑®Ìñ•ÏùÑ Í∞ÄÏßÑ ÏÇ¨Ïö©ÏûêÎì§ Í∞ÑÏùò Ï∂îÏ≤úÏùÑ ÌÜµÌï¥ Îã§ÏñëÌïú Ïä§ÌÉÄÏùºÏùÑÏ∂îÏ≤úÌï† Ïàò ÏûàÎã§.

   ##### Îã®Ï†ê
   - ÎπÑÏÑ†Ìò∏(1) Ïä§ÌÉÄÏùºÏóê ÎåÄÌïú Ï†ïÎ≥¥Í∞Ä ÎßéÏßÄ ÏïäÏúºÎ©¥, Ïú†ÏÇ¨Ìïú ÏÇ¨Ïö©ÏûêÎ•º Ï∞æÍ∏∞ Ïñ¥Î†§ÏõåÏßà Ïàò ÏûàÏúºÎ©∞, Ïù¥Îäî Ï∂îÏ≤úÏùò Ïßà Ï†ÄÌïòÎ°ú Ïù¥Ïñ¥Ïßà Ïàò ÏûàÎã§.

   - ÏÇ¨Ïö©Ïûê ÏàòÍ∞Ä Ï†ÅÍ±∞ÎÇò ÎπÑÏÑ†Ìò∏ Îç∞Ïù¥ÌÑ∞Í∞Ä Î∂ÄÏ°±Ìï† Í≤ΩÏö∞, Ïú†ÏÇ¨Ìïú ÏÇ¨Ïö©ÏûêÎ•º Ï∞æÍ∏∞Í∞Ä ÌûòÎì§Ïñ¥Ïßà Ïàò ÏûàÎã§. Ïù¥Îäî Ï∂îÏ≤úÏùò Ïã†Î¢∞ÏÑ±ÏùÑ Îñ®Ïñ¥Îú®Î¶¥ Ïàò ÏûàÎã§.

   - Îã§Î•∏ ÏÇ¨Ïö©ÏûêÏùò ÌèâÍ∞ÄÎ•º Î∞îÌÉïÏúºÎ°ú Ï∂îÏ≤úÏù¥ Ïù¥Î£®Ïñ¥ÏßÄÎØÄÎ°ú Ï†ïÌôïÎèÑÍ∞Ä Îñ®Ïñ¥Ïßà Ïàò ÏûàÎã§.



---



##[3-2]

##torchvision Ï∂©ÎèåÏãú sympy Ï∂©Îèå Ïò§Î•ò Î∞©ÏßÄ


```python
!pip install -U sympy
```


```python
import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from PIL import Image
from torchvision import models, transforms
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from tqdm import tqdm

# Í≤ΩÎ°ú ÏÑ§Ï†ï
train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'
val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'
model_path = '/content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ Ï∫†ÌîÑ ÏµúÏ¢Ö Ï†ïÎ¶¨/ÍπÄÏßÑ/model_final5.pth'
fixed_excel_file_path = '/content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ Ï∫†ÌîÑ ÏµúÏ¢Ö Ï†ïÎ¶¨/ÍπÄÏßÑ/top_100_respondents_preferences_fixed.xlsx'

# ResNet ÌäπÏßï Ï∂îÏ∂úÍ∏∞ ÌÅ¥ÎûòÏä§ Ï†ïÏùò (fc Î†àÏù¥Ïñ¥ Ï†úÏô∏)
class ResNetFeatureExtractor(nn.Module):
    def __init__(self, model_path):
        super(ResNetFeatureExtractor, self).__init__()
        resnet = models.resnet18(pretrained=False)
        state_dict = torch.load(model_path)
        state_dict = {k: v for k, v in state_dict.items() if not k.startswith("fc.")}
        resnet.load_state_dict(state_dict, strict=False)
        self.features = nn.Sequential(*list(resnet.children())[:-2])

    def forward(self, x):
        return self.features(x)

# Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ Ï†ïÏùò
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò
def load_and_preprocess_image(image_path, device):
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    return image

# Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑú Ïù¥ÎØ∏ÏßÄÎì§Ïùò ÌäπÏßï Î≤°ÌÑ∞Î•º Ï∂îÏ∂úÌïòÎäî Ìï®Ïàò
def extract_features_for_dataset(image_paths, feature_extractor, device, log_missing_files=False):
    features = []
    feature_extractor.eval()
    missing_files = []

    with torch.no_grad():
        for image_path in tqdm(image_paths, desc="Extracting Features"):
            if os.path.exists(image_path):
                image_tensor = load_and_preprocess_image(image_path, device)
                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()
                features.append(feature_vector)
            else:
                missing_files.append(image_path)
                print(f"File not found: {image_path}")

    if log_missing_files:
        with open("missing_files_log.txt", "w") as file:
            for item in missing_files:
                file.write(f"{item}\n")
        print(f"Missing files logged in 'missing_files_log.txt'")

    return np.array(features)

# ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Î∞è Ïú†ÌÅ¥Î¶¨ÎîîÏïà Í±∞Î¶¨ Í≥ÑÏÇ∞ Ìï®Ïàò (Î∞∞Ïπò Ï≤òÎ¶¨ Ï†ÅÏö©)
def calculate_similarity_scores(val_features, train_features, batch_size=100):
    cosine_similarity_list = []
    euclidean_distance_list = []

    val_features = torch.tensor(val_features).to(device)
    train_features = torch.tensor(train_features).to(device)
    val_features = val_features.view(val_features.size(0), -1)
    train_features = train_features.view(train_features.size(0), -1)

    with torch.no_grad():
        for i in range(0, len(val_features), batch_size):
            val_batch = val_features[i:i + batch_size]

            # ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
            val_norm = val_batch / val_batch.norm(dim=1, keepdim=True)
            train_norm = train_features / train_features.norm(dim=1, keepdim=True)
            cosine_sim_batch = torch.mm(val_norm, train_norm.T).cpu().numpy()
            cosine_similarity_list.append(cosine_sim_batch)

            # Ïú†ÌÅ¥Î¶¨ÎîîÏïà Í±∞Î¶¨ Í≥ÑÏÇ∞
            val_batch_cpu = val_batch.cpu().numpy()
            train_features_cpu = train_features.cpu().numpy()
            euclidean_dist_batch = -np.linalg.norm(val_batch_cpu[:, None, :] - train_features_cpu[None, :, :], axis=2)
            euclidean_distance_list.append(euclidean_dist_batch)

    cosine_similarity = np.vstack(cosine_similarity_list)
    euclidean_distance = np.vstack(euclidean_distance_list)

    return cosine_similarity, euclidean_distance

# Îëê Ïú†ÏÇ¨ÎèÑÎ•º Í≤∞Ìï©ÌïòÎäî Ìï®Ïàò
def combine_similarity_scores(cosine_similarity, euclidean_distance, alpha):
    return alpha * cosine_similarity + (1 - alpha) * euclidean_distance

# ÏµúÏ†Å alpha Ï∞æÍ∏∞
def find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels):
    best_alpha, best_f1 = 0.5, 0
    for alpha in np.arange(0.1, 1.0, 0.1):
        combined_score = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha)
        predicted_preferences = predict_style_preference(combined_score, train_preferences)
        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)
        if f1 > best_f1:
            best_f1, best_alpha = f1, alpha
    return best_alpha

# ÏµúÏ†Å threshold Ï∞æÍ∏∞
def find_optimal_threshold(similarity_scores, train_preferences, val_labels):
    best_threshold, best_f1 = 0.5, 0
    for threshold in np.arange(0.1, 0.9, 0.01):
        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)
        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)
        if f1 > best_f1:
            best_f1, best_threshold = f1, threshold
    return best_threshold

# Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑ ÏòàÏ∏°
def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):
    predicted_preferences = []
    train_len = len(train_preferences)

    for score_row in similarity_scores:
        max_similarity = np.max(score_row)
        most_similar_index = np.argmax(score_row) if np.argmax(score_row) < train_len else train_len - 1
        predicted_label = train_preferences[most_similar_index] if max_similarity > threshold else 0
        predicted_preferences.append(predicted_label)

    return predicted_preferences

# ÏÑ±Îä• ÌèâÍ∞Ä Ìï®Ïàò
def calculate_metrics(predicted, actual):
    accuracy = accuracy_score(actual, predicted) * 100
    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted', zero_division=0)
    return accuracy, precision * 100, recall * 100, f1 * 100

# ResNet ÌäπÏßï Ï∂îÏ∂úÍ∏∞ Ï¥àÍ∏∞Ìôî Î∞è Í∞ÄÏ§ëÏπò Î°úÎìú
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
feature_extractor = ResNetFeatureExtractor(model_path).to(device)

# ÏóëÏÖÄ ÌååÏùºÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú Ìï®Ïàò
def extract_preferences_from_excel(file_path):
    preferences_dict = {}
    preferences_df = pd.read_excel(file_path, engine='openpyxl')

    for idx, row in preferences_df.iterrows():
        respondent_id = row['Respondent ID']
        training_preferred = row['Training Style Preferred']
        training_not_preferred = row['Training Style Not Preferred']
        validation_preferred = row['Validation Style Preferred']
        validation_not_preferred = row['Validation Style Not Preferred']

        training_preferred_list = training_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(training_preferred) else []
        training_not_preferred_list = training_not_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(training_not_preferred) else []
        validation_preferred_list = validation_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(validation_preferred) else []
        validation_not_preferred_list = validation_not_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(validation_not_preferred) else []

        preferences_dict[respondent_id] = {
            'training_preferred': training_preferred_list,
            'training_not_preferred': training_not_preferred_list,
            'validation_preferred': validation_preferred_list,
            'validation_not_preferred': validation_not_preferred_list
        }

    return preferences_dict

# ÏóëÏÖÄ ÌååÏùºÏóêÏÑú ÏÑ†Ìò∏ Î∞è ÎπÑÏÑ†Ìò∏ Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ Ï∂îÏ∂ú
preferences_dict = extract_preferences_from_excel(fixed_excel_file_path)

# Training Style Preferred Î¶¨Ïä§Ìä∏ Ï∂îÏ∂ú
train_style = []
for respondent_id, prefs in preferences_dict.items():
    train_style.extend(prefs['training_preferred'])

# Validation Style Preferred Î∞è Not Preferred Î¶¨Ïä§Ìä∏ Ï∂îÏ∂ú Î∞è Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑ Ìï†Îãπ
val_style = []
val_labels = []
for respondent_id, prefs in preferences_dict.items():
    val_style.extend(prefs['validation_preferred'])
    val_style.extend(prefs['validation_not_preferred'])
    val_labels.extend([1] * len(prefs['validation_preferred']))
    val_labels.extend([0] * len(prefs['validation_not_preferred']))

# Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎ°ú Î≥ÄÌôò
train_image_paths = [os.path.join(train_image_dir, f"segmented_{img.strip()}") for img in train_style]
val_image_paths = [os.path.join(val_image_dir, f"segmented_{img.strip()}") for img in val_style]

# ÌïôÏäµ Î∞è Í≤ÄÏ¶ù Ïù¥ÎØ∏ÏßÄÏùò ÌäπÏßï Î≤°ÌÑ∞ Ï∂îÏ∂ú
train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device, log_missing_files=True)
val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device, log_missing_files=True)

# Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features)

# ÏµúÏ†ÅÏùò alphaÎ•º Ï∞æÍ≥† Ïú†ÏÇ¨ÎèÑÎ•º Í≤∞Ìï©ÌïòÏó¨ ÏµúÏ¢Ö Ï†êÏàò ÏÇ∞Ï∂ú
optimal_alpha = find_optimal_alpha(cosine_similarity, euclidean_distance, [1] * len(train_features), val_labels)
combined_similarity_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, optimal_alpha)

# ÏµúÏ†Å thresholdÎ•º Ï∞æÍ≥† ÏµúÏ¢Ö ÏòàÏ∏°
optimal_threshold = find_optimal_threshold(combined_similarity_scores, [1] * len(train_features), val_labels)
predicted_preferences = predict_style_preference(combined_similarity_scores, [1] * len(train_features), optimal_threshold)

# ÏÑ±Îä• ÌèâÍ∞Ä
accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)

# ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•
print(f"Optimal Alpha: {optimal_alpha:.2f}")
print(f"Optimal Threshold: {optimal_threshold:.2f}")
print(f"Final Prediction Accuracy: {accuracy:.2f}%")
print(f"Final Precision: {precision:.2f}%")
print(f"Final Recall: {recall:.2f}%")
print(f"Final F1-Score: {f1:.2f}%")


```

    /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
      warnings.warn(
    /usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.
      warnings.warn(msg)
    <ipython-input-21-03a4d8eb5ce4>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
      state_dict = torch.load(model_path)
    Extracting Features:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 232/331 [00:01<00:00, 151.22it/s]

    File not found: /content/drive/MyDrive/dataset/processed_segmentation_cleaned/segmented_T_15458_10_sportivecasual_M.jpg
    File not found: /content/drive/MyDrive/dataset/processed_segmentation_cleaned/segmented_T_15453_10_sportivecasual_M.jpg
    File not found: /content/drive/MyDrive/dataset/processed_segmentation_cleaned/segmented_T_15468_10_sportivecasual_M.jpg
    File not found: /content/drive/MyDrive/dataset/processed_segmentation_cleaned/segmented_T_15477_10_sportivecasual_M.jpg
    File not found: /content/drive/MyDrive/dataset/processed_segmentation_cleaned/segmented_T_15488_10_sportivecasual_M.jpg
    File not found: /content/drive/MyDrive/dataset/processed_segmentation_cleaned/segmented_T_15467_10_sportivecasual_M.jpg


    Extracting Features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 331/331 [00:02<00:00, 139.29it/s]


    Missing files logged in 'missing_files_log.txt'


    Extracting Features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 244/244 [00:01<00:00, 134.12it/s]


    Missing files logged in 'missing_files_log.txt'
    Optimal Alpha: 0.60
    Optimal Threshold: 0.10
    Final Prediction Accuracy: 78.69%
    Final Precision: 82.84%
    Final Recall: 78.69%
    Final F1-Score: 76.56%


##ÏµúÏ¢Ö ÎßàÍ∞êÎÇ† Ï†ïÎ¶¨Ìï†Îïå 2-2 Ìëú ÎÇ¥Ïö©Ïù¥ Î∞îÎÄåÎ©¥ÏÑú ÌååÏùº ÎàÑÎùΩÏù¥ ÏÉùÍ≤®ÏÑú Í≤∞Í≥ºÍ∞Ä Î∞îÎÄåÏñ¥ÏÑú Î∞ëÏóê Î∂ÄÎ°ùÏúºÎ°ú Ï∂îÍ∞ÄÎ°ú ÎãµÎãàÎã§.
## ÎîîÎ≤ÑÍπÖÌï† ÏãúÍ∞ÑÏù¥ ÏóÜÏñ¥ÏÑú Ïù¥Î†áÍ≤å Ïò¨Î†§ÎìúÎ¶¨ÎäîÏ†ê ÏñëÌï¥ Î∂ÄÌÉÅÎìúÎ¶ΩÎãàÎã§.
## '/content/drive/MyDrive/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö≥·ÑÖ·Öµ·Ñã·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö¢·Ü∑·Ñë·Ö≥ ·Ñé·Ö¨·Ñå·Ö©·Üº ·Ñå·Ö•·Üº·ÑÖ·Öµ/·ÑÄ·Öµ·Ü∑·Ñå·Öµ·Ü´/preferences0.xlsx'

## ÏõêÎûò ÏÇ¨Ïö©ÌñàÎçò preferences0.xlsxÏùÑ Ïù¥Ïö©Ìï¥ÏÑú Îã§Ïãú ÎèåÎ¶∞ ÏΩîÎìú Í≤∞Í≥ºÎ¨ºÏûÖÎãàÎã§.


```python
import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from PIL import Image
from torchvision import models, transforms
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
from tqdm import tqdm

# Í≤ΩÎ°ú ÏÑ§Ï†ï
train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'
val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'
model_path = '/content/drive/MyDrive/Îç∞Ïù¥ÌÑ∞ ÌÅ¨Î¶¨ÏóêÏù¥ÌÑ∞ Ï∫†ÌîÑ ÏµúÏ¢Ö Ï†ïÎ¶¨/ÍπÄÏßÑ/model_final5.pth'
excel_file_path = '/content/drive/MyDrive/·ÑÉ·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö≥·ÑÖ·Öµ·Ñã·Ö¶·Ñã·Öµ·Ñê·Ö• ·Ñè·Ö¢·Ü∑·Ñë·Ö≥ ·Ñé·Ö¨·Ñå·Ö©·Üº ·Ñå·Ö•·Üº·ÑÖ·Öµ/·ÑÄ·Öµ·Ü∑·Ñå·Öµ·Ü´/preferences0.xlsx'

# ResNet ÌäπÏßï Ï∂îÏ∂úÍ∏∞ ÌÅ¥ÎûòÏä§ Ï†ïÏùò (fc Î†àÏù¥Ïñ¥ Ï†úÏô∏)
class ResNetFeatureExtractor(nn.Module):
    def __init__(self, model_path):
        super(ResNetFeatureExtractor, self).__init__()
        resnet = models.resnet18(pretrained=False)
        state_dict = torch.load(model_path)
        state_dict = {k: v for k, v in state_dict.items() if not k.startswith("fc.")}
        resnet.load_state_dict(state_dict, strict=False)
        self.features = nn.Sequential(*list(resnet.children())[:-2])

    def forward(self, x):
        return self.features(x)

# Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ ÌååÏù¥ÌîÑÎùºÏù∏ Ï†ïÏùò
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Ïù¥ÎØ∏ÏßÄ Î°úÎìú Î∞è Ï†ÑÏ≤òÎ¶¨ Ìï®Ïàò
def load_and_preprocess_image(image_path, device):
    image = Image.open(image_path).convert('RGB')
    image = transform(image).unsqueeze(0).to(device)
    return image

# Îç∞Ïù¥ÌÑ∞ÏÖãÏóêÏÑú Ïù¥ÎØ∏ÏßÄÎì§Ïùò ÌäπÏßï Î≤°ÌÑ∞Î•º Ï∂îÏ∂úÌïòÎäî Ìï®Ïàò
def extract_features_for_dataset(image_paths, feature_extractor, device):
    features = []
    feature_extractor.eval()
    with torch.no_grad():
        for image_path in tqdm(image_paths, desc="Extracting Features"):
            if os.path.exists(image_path):
                image_tensor = load_and_preprocess_image(image_path, device)
                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()
                features.append(feature_vector)
            else:
                print(f"File not found: {image_path}")
    return np.array(features)

# ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Î∞è Ïú†ÌÅ¥Î¶¨ÎîîÏïà Í±∞Î¶¨ Í≥ÑÏÇ∞ Ìï®Ïàò (Î∞∞Ïπò Ï≤òÎ¶¨ Ï†ÅÏö©)
def calculate_similarity_scores(val_features, train_features, batch_size=100):
    cosine_similarity_list = []
    euclidean_distance_list = []

    val_features = torch.tensor(val_features).to(device)
    train_features = torch.tensor(train_features).to(device)
    val_features = val_features.view(val_features.size(0), -1)
    train_features = train_features.view(train_features.size(0), -1)

    with torch.no_grad():
        for i in range(0, len(val_features), batch_size):
            val_batch = val_features[i:i + batch_size]

            # ÏΩîÏÇ¨Ïù∏ Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
            val_norm = val_batch / val_batch.norm(dim=1, keepdim=True)
            train_norm = train_features / train_features.norm(dim=1, keepdim=True)
            cosine_sim_batch = torch.mm(val_norm, train_norm.T).cpu().numpy()
            cosine_similarity_list.append(cosine_sim_batch)

            # Ïú†ÌÅ¥Î¶¨ÎîîÏïà Í±∞Î¶¨ Í≥ÑÏÇ∞
            val_batch_cpu = val_batch.cpu().numpy()
            train_features_cpu = train_features.cpu().numpy()
            euclidean_dist_batch = -np.linalg.norm(val_batch_cpu[:, None, :] - train_features_cpu[None, :, :], axis=2)
            euclidean_distance_list.append(euclidean_dist_batch)

    cosine_similarity = np.vstack(cosine_similarity_list)
    euclidean_distance = np.vstack(euclidean_distance_list)

    return cosine_similarity, euclidean_distance

# Îëê Ïú†ÏÇ¨ÎèÑÎ•º Í≤∞Ìï©ÌïòÎäî Ìï®Ïàò
def combine_similarity_scores(cosine_similarity, euclidean_distance, alpha):
    return alpha * cosine_similarity + (1 - alpha) * euclidean_distance

# ÏµúÏ†Å alpha Ï∞æÍ∏∞
def find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels):
    best_alpha, best_f1 = 0.5, 0
    for alpha in np.arange(0.1, 1.0, 0.1):
        combined_score = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha)
        predicted_preferences = predict_style_preference(combined_score, train_preferences)
        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)
        if f1 > best_f1:
            best_f1, best_alpha = f1, alpha
    return best_alpha

# ÏµúÏ†Å threshold Ï∞æÍ∏∞
def find_optimal_threshold(similarity_scores, train_preferences, val_labels):
    best_threshold, best_f1 = 0.5, 0
    for threshold in np.arange(0.1, 0.9, 0.01):
        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)
        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)
        if f1 > best_f1:
            best_f1, best_threshold = f1, threshold
    return best_threshold

# Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑ ÏòàÏ∏°
def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):
    predicted_preferences = []
    train_len = len(train_preferences)  # train_preferencesÏùò Í∏∏Ïù¥ ÌôïÏù∏

    for score_row in similarity_scores:
        max_similarity = np.max(score_row)
        # np.argmax(score_row)Ïùò Í≤∞Í≥ºÍ∞Ä train_preferences Î≤îÏúÑ ÎÇ¥Ïóê ÏûàÎäîÏßÄ ÌôïÏù∏
        most_similar_index = np.argmax(score_row) if np.argmax(score_row) < train_len else train_len - 1
        predicted_label = train_preferences[most_similar_index] if max_similarity > threshold else 0
        predicted_preferences.append(predicted_label)

    return predicted_preferences

# ÏÑ±Îä• ÌèâÍ∞Ä Ìï®Ïàò
def calculate_metrics(predicted, actual):
    accuracy = accuracy_score(actual, predicted) * 100
    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted', zero_division=0)
    return accuracy, precision * 100, recall * 100, f1 * 100

# ResNet ÌäπÏßï Ï∂îÏ∂úÍ∏∞ Ï¥àÍ∏∞Ìôî Î∞è Í∞ÄÏ§ëÏπò Î°úÎìú
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
feature_extractor = ResNetFeatureExtractor(model_path).to(device)

# ÏóëÏÖÄ ÌååÏùºÏóêÏÑú Îç∞Ïù¥ÌÑ∞ Ï∂îÏ∂ú Ìï®Ïàò
def extract_preferences_from_excel(file_path):
    preferences_dict = {}
    preferences_df = pd.read_excel(file_path)

    for idx, row in preferences_df.iterrows():
        respondent_id = row['Respondent ID']
        training_preferred = row['Training Style Preferred']
        training_not_preferred = row['Training Style Not Preferred']
        validation_preferred = row['Validation Style Preferred']
        validation_not_preferred = row['Validation Style Not Preferred']

        training_preferred_list = training_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(training_preferred) else []
        training_not_preferred_list = training_not_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(training_not_preferred) else []
        validation_preferred_list = validation_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(validation_preferred) else []
        validation_not_preferred_list = validation_not_preferred.strip("[]").replace("'", "").split(", ") if pd.notna(validation_not_preferred) else []

        preferences_dict[respondent_id] = {
            'training_preferred': training_preferred_list,
            'training_not_preferred': training_not_preferred_list,
            'validation_preferred': validation_preferred_list,
            'validation_not_preferred': validation_not_preferred_list
        }

    return preferences_dict

# ÏóëÏÖÄ ÌååÏùºÏóêÏÑú ÏÑ†Ìò∏ Î∞è ÎπÑÏÑ†Ìò∏ Ïù¥ÎØ∏ÏßÄ Î¶¨Ïä§Ìä∏ Ï∂îÏ∂ú
preferences_dict = extract_preferences_from_excel(excel_file_path)

# Training Style Preferred Î¶¨Ïä§Ìä∏ Ï∂îÏ∂ú
train_style = []
for respondent_id, prefs in preferences_dict.items():
    train_style.extend(prefs['training_preferred'])

# Validation Style Preferred Î∞è Not Preferred Î¶¨Ïä§Ìä∏ Ï∂îÏ∂ú Î∞è Ïä§ÌÉÄÏùº ÏÑ†Ìò∏ÎèÑ Ìï†Îãπ
val_style = []
val_labels = []  # Í≤ÄÏ¶ù Î†àÏù¥Î∏î Î¶¨Ïä§Ìä∏ Ï¥àÍ∏∞Ìôî
for respondent_id, prefs in preferences_dict.items():
    val_style.extend(prefs['validation_preferred'])
    val_style.extend(prefs['validation_not_preferred'])
    val_labels.extend([1] * len(prefs['validation_preferred']))
    val_labels.extend([0] * len(prefs['validation_not_preferred']))

# Ïù¥ÎØ∏ÏßÄ Í≤ΩÎ°úÎ°ú Î≥ÄÌôò
train_image_paths = [os.path.join(train_image_dir, f"segmented_{img.strip()}") for img in train_style]
val_image_paths = [os.path.join(val_image_dir, f"segmented_{img.strip()}") for img in val_style]

# ÌïôÏäµ Î∞è Í≤ÄÏ¶ù Ïù¥ÎØ∏ÏßÄÏùò ÌäπÏßï Î≤°ÌÑ∞ Ï∂îÏ∂ú
train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)
val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)

# Ïú†ÏÇ¨ÎèÑ Í≥ÑÏÇ∞
cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features)

# ÏµúÏ†ÅÏùò alphaÎ•º Ï∞æÍ≥† Ïú†ÏÇ¨ÎèÑÎ•º Í≤∞Ìï©ÌïòÏó¨ ÏµúÏ¢Ö Ï†êÏàò ÏÇ∞Ï∂ú
optimal_alpha = find_optimal_alpha(cosine_similarity, euclidean_distance, [1] * len(train_features), val_labels)
combined_similarity_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, optimal_alpha)

# ÏµúÏ†Å thresholdÎ•º Ï∞æÍ≥† ÏµúÏ¢Ö ÏòàÏ∏°
optimal_threshold = find_optimal_threshold(combined_similarity_scores, [1] * len(train_features), val_labels)
predicted_preferences = predict_style_preference(combined_similarity_scores, [1] * len(train_features), optimal_threshold)

# ÏÑ±Îä• ÌèâÍ∞Ä
accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)

# ÏµúÏ¢Ö Í≤∞Í≥º Ï∂úÎ†•
print(f"Optimal Alpha: {optimal_alpha:.2f}")
print(f"Optimal Threshold: {optimal_threshold:.2f}")
print(f"Final Prediction Accuracy: {accuracy:.2f}%")
print(f"Final Precision: {precision:.2f}%")
print(f"Final Recall: {recall:.2f}%")
print(f"Final F1-Score: {f1:.2f}%")

```

    <ipython-input-28-bc3974a14a4c>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
      state_dict = torch.load(model_path)
    Extracting Features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 674/674 [00:04<00:00, 138.09it/s]
    Extracting Features: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1102/1102 [00:07<00:00, 143.37it/s]


    Optimal Alpha: 0.60
    Optimal Threshold: 0.10
    Final Prediction Accuracy: 67.88%
    Final Precision: 74.04%
    Final Recall: 67.88%
    Final F1-Score: 61.82%

