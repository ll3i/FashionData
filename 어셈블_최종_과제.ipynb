{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ll3i/FashionData/blob/main/%EC%96%B4%EC%85%88%EB%B8%94_%EC%B5%9C%EC%A2%85_%EA%B3%BC%EC%A0%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiRj8SUS19Xd",
        "outputId": "11d00b93-4f21-4708-89d8-8fd7febef9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1-1]"
      ],
      "metadata": {
        "id": "1Kl7zw_l2h86"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 폴더 경로 설정\n",
        "directories = [\n",
        "    '/content/drive/MyDrive/dataset/training_image',\n",
        "    '/content/drive/MyDrive/dataset/validation_image'  # 추가한 경로\n",
        "]\n",
        "\n",
        "# 성별 및 스타일별 이미지 개수를 저장할 구조\n",
        "image_count = defaultdict(lambda: defaultdict(int)) # 중첩된 딕셔너리의 구조: {성별: {스타일: 이미지 수}} 형태\n",
        "total_images = 0  # 전체 이미지 수를 저장할 변수\n",
        "\n",
        "# 파일 이름에서 성별과 스타일 추출하여 통계 내기\n",
        "for directory in directories:  # 각 디렉토리에 대해 반복\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith('.jpg'):  # JPG 파일만 처리\n",
        "            parts = filename.split('_')  # 파일명을 '_'로 분할\n",
        "\n",
        "            # 성별과 스타일 정보를 추출\n",
        "            gender_identifier = parts[-1][0]  # 마지막 부분 첫 글자 (W or T)\n",
        "            style = parts[3]  # 네 번째 부분은 스타일 정보\n",
        "\n",
        "            # 성별을 '여성' / '남성'으로 변환\n",
        "            gender = '여성' if gender_identifier == 'W' else '남성'\n",
        "\n",
        "            # 성별과 스타일의 이미지 수를 집계\n",
        "            image_count[gender][style] += 1\n",
        "            total_images += 1  # 전체 이미지 수 증가\n",
        "\n",
        "# DataFrame으로 변환\n",
        "data = []\n",
        "for gender, styles in image_count.items():\n",
        "    for style, count in styles.items():\n",
        "        data.append([gender, style, count])\n",
        "\n",
        "df = pd.DataFrame(data, columns=['성별', '스타일', '이미지 수'])\n",
        "\n",
        "# 예쁘게 출력\n",
        "df_sorted = df.sort_values(by=['성별', '스타일']).reset_index(drop=True)\n",
        "\n",
        "# 총 이미지 수 출력 및 DataFrame 표시\n",
        "print(f\"총 이미지 수: {total_images}\")\n",
        "display(df_sorted)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "psBdewIY2kBp",
        "outputId": "8366ca39-3a56-457c-b3df-a82950836596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 이미지 수: 5021\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    성별             스타일  이미지 수\n",
              "0   남성            bold    325\n",
              "1   남성          hiphop    340\n",
              "2   남성          hippie    342\n",
              "3   남성             ivy    316\n",
              "4   남성     metrosexual    336\n",
              "5   남성            mods    349\n",
              "6   남성        normcore    415\n",
              "7   남성  sportivecasual    350\n",
              "8   여성      athleisure     81\n",
              "9   여성   bodyconscious    118\n",
              "10  여성        cityglam     85\n",
              "11  여성         classic     99\n",
              "12  여성           disco     47\n",
              "13  여성         ecology     81\n",
              "14  여성        feminine    198\n",
              "15  여성      genderless     89\n",
              "16  여성          grunge     41\n",
              "17  여성          hiphop     56\n",
              "18  여성          hippie    105\n",
              "19  여성          kitsch    113\n",
              "20  여성        lingerie     60\n",
              "21  여성          lounge     53\n",
              "22  여성        military     42\n",
              "23  여성         minimal    174\n",
              "24  여성        normcore    173\n",
              "25  여성        oriental     96\n",
              "26  여성          popart     49\n",
              "27  여성       powersuit    154\n",
              "28  여성            punk     77\n",
              "29  여성           space     52\n",
              "30  여성  sportivecasual    205"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-108b1fdf-9c20-451f-ab08-62b33d58b714\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>성별</th>\n",
              "      <th>스타일</th>\n",
              "      <th>이미지 수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>남성</td>\n",
              "      <td>bold</td>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>남성</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>남성</td>\n",
              "      <td>hippie</td>\n",
              "      <td>342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>남성</td>\n",
              "      <td>ivy</td>\n",
              "      <td>316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>남성</td>\n",
              "      <td>metrosexual</td>\n",
              "      <td>336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>남성</td>\n",
              "      <td>mods</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>남성</td>\n",
              "      <td>normcore</td>\n",
              "      <td>415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>남성</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>350</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>여성</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>여성</td>\n",
              "      <td>bodyconscious</td>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>여성</td>\n",
              "      <td>cityglam</td>\n",
              "      <td>85</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>여성</td>\n",
              "      <td>classic</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>여성</td>\n",
              "      <td>disco</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>여성</td>\n",
              "      <td>ecology</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>여성</td>\n",
              "      <td>feminine</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>여성</td>\n",
              "      <td>genderless</td>\n",
              "      <td>89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>여성</td>\n",
              "      <td>grunge</td>\n",
              "      <td>41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>여성</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>여성</td>\n",
              "      <td>hippie</td>\n",
              "      <td>105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>여성</td>\n",
              "      <td>kitsch</td>\n",
              "      <td>113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>여성</td>\n",
              "      <td>lingerie</td>\n",
              "      <td>60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>여성</td>\n",
              "      <td>lounge</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>여성</td>\n",
              "      <td>military</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>여성</td>\n",
              "      <td>minimal</td>\n",
              "      <td>174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>여성</td>\n",
              "      <td>normcore</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>여성</td>\n",
              "      <td>oriental</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>여성</td>\n",
              "      <td>popart</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>여성</td>\n",
              "      <td>powersuit</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>여성</td>\n",
              "      <td>punk</td>\n",
              "      <td>77</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>여성</td>\n",
              "      <td>space</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>여성</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-108b1fdf-9c20-451f-ab08-62b33d58b714')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-108b1fdf-9c20-451f-ab08-62b33d58b714 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-108b1fdf-9c20-451f-ab08-62b33d58b714');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ff2bc150-871c-44a9-bed1-481eca7daffa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ff2bc150-871c-44a9-bed1-481eca7daffa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ff2bc150-871c-44a9-bed1-481eca7daffa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_f748c88d-31a7-45b1-9dfb-1932c724fd45\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_sorted')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f748c88d-31a7-45b1-9dfb-1932c724fd45 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_sorted');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_sorted",
              "summary": "{\n  \"name\": \"df_sorted\",\n  \"rows\": 31,\n  \"fields\": [\n    {\n      \"column\": \"\\uc131\\ubcc4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc5ec\\uc131\",\n          \"\\ub0a8\\uc131\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2a4\\ud0c0\\uc77c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"athleisure\",\n          \"ecology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc774\\ubbf8\\uc9c0 \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 119,\n        \"min\": 41,\n        \"max\": 415,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          77,\n          41\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1-2]"
      ],
      "metadata": {
        "id": "P4y-a7IM4GOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA 사용 가능 여부 확인\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 클래스 목록 (성별 + 스타일 조합으로 구성)\n",
        "fashion_classes = [\n",
        "    \"남성_bold\", \"남성_hiphop\", \"남성_hippie\", \"남성_ivy\", \"남성_metrosexual\",\n",
        "    \"남성_mods\", \"남성_normcore\", \"남성_sportivecasual\", \"여성_athleisure\",\n",
        "    \"여성_bodyconscious\", \"여성_cityglam\", \"여성_classic\", \"여성_disco\",\n",
        "    \"여성_ecology\", \"여성_feminine\", \"여성_genderless\", \"여성_grunge\",\n",
        "    \"여성_hiphop\", \"여성_hippie\", \"여성_kitsch\", \"여성_lingerie\",\n",
        "    \"여성_lounge\", \"여성_military\", \"여성_minimal\", \"여성_normcore\",\n",
        "    \"여성_oriental\", \"여성_popart\", \"여성_powersuit\", \"여성_punk\",\n",
        "    \"여성_space\", \"여성_sportivecasual\"\n",
        "]\n",
        "\n",
        "# 스타일 매핑 (각 클래스 조합을 숫자로 매핑)\n",
        "style_mapping = {style: idx for idx, style in enumerate(fashion_classes)}\n",
        "\n",
        "# 데이터셋 클래스 정의\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_folder, transform=None):\n",
        "        self.image_folder = image_folder\n",
        "        self.image_paths = [os.path.join(image_folder, fname) for fname in os.listdir(image_folder)]\n",
        "        self.transform = transform\n",
        "        self.labels = []\n",
        "\n",
        "        # 파일명에서 성별 및 스타일 레이블 추출\n",
        "        for img in self.image_paths:\n",
        "            fname = os.path.basename(img)\n",
        "            parts = fname.split('_')\n",
        "            gender = parts[-1].split('.')[0]  # 성별 추출 ('M' 또는 'W')\n",
        "            style = parts[-2]  # 스타일 추출\n",
        "\n",
        "            gender_label = \"남성\" if gender == 'M' else \"여성\"\n",
        "            label = f\"{gender_label}_{style}\"  # 성별 + 스타일 조합\n",
        "            style_label = style_mapping.get(label, -1)  # 스타일 매핑\n",
        "\n",
        "            if style_label != -1:\n",
        "                self.labels.append(style_label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "# 트레이닝 데이터 증강 강화\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # 좌우 뒤집기\n",
        "    transforms.RandomRotation(degrees=30),  # 회전 범위 증가\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # 색상 조정\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # 무작위 자르기 및 리사이즈\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 검증 데이터에 약한 데이터 증강 적용 (좌우 반전, 미세 회전 등)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),  # 좌우 뒤집기\n",
        "    transforms.RandomRotation(degrees=10),  # 미세한 회전 적용\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 트레이닝 데이터셋 로드\n",
        "train_dataset = CustomImageDataset('/content/drive/MyDrive/dataset/processed_segmentation_cleaned', transform=train_transform)\n",
        "\n",
        "# 검증 데이터셋 로드 (별도의 검증 이미지 폴더 사용)\n",
        "val_dataset = CustomImageDataset('/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val', transform=val_transform)\n",
        "\n",
        "# 데이터 로더 설정\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "# ResNet-18 기반 패션 스타일 및 성별 예측 모델\n",
        "class FashionGenderModel(nn.Module):\n",
        "    def __init__(self, num_classes=31):  # 총 31개의 클래스\n",
        "        super(FashionGenderModel, self).__init__()\n",
        "        self.resnet = models.resnet18(weights=None)  # Pretrained weights 사용 안 함\n",
        "        self.resnet.fc = nn.Identity()  # ResNet의 기본 fully connected 레이어를 제거\n",
        "\n",
        "        # 31개 클래스(성별 + 스타일 조합)를 위한 출력 레이어 추가\n",
        "        self.fc = nn.Linear(512, num_classes)\n",
        "        self.dropout = nn.Dropout(p=0.4)  # Dropout 비율 조정 (0.4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet(x)\n",
        "        x = self.dropout(x)\n",
        "        out = self.fc(x)  # 31개 클래스 예측\n",
        "        return out\n",
        "\n",
        "# 모델, 손실 함수, 옵티마이저, 스케줄러 설정\n",
        "model = FashionGenderModel(num_classes=31).to(device)  # 모델을 CUDA로 이동\n",
        "criterion = nn.CrossEntropyLoss()  # 하나의 CrossEntropyLoss 사용\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.005, weight_decay=0.02)  # 학습률 조정\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=10, T_mult=1)\n",
        "\n",
        "# 모델 학습 함수\n",
        "def train_model(train_loader, val_loader, model, optimizer, criterion, scheduler, epochs=200, save_path='/content/drive/MyDrive/dataset/model_final2.pth', start_epoch=0):\n",
        "    best_val_accuracy = 0.0  # 최상의 검증 정확도를 저장하기 위한 변수\n",
        "\n",
        "    for epoch in range(start_epoch, epochs):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        correct_train = 0\n",
        "        total_train = 0\n",
        "\n",
        "        # 학습 단계\n",
        "        for images, labels in train_loader:\n",
        "            images = images.to(device)  # 데이터를 CUDA로 이동\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # 모델 예측\n",
        "            outputs = model(images)\n",
        "\n",
        "            # 손실 계산\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "\n",
        "            # 정확도 계산\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "            total_train += labels.size(0)\n",
        "\n",
        "        train_accuracy = correct_train / total_train\n",
        "\n",
        "        # 검증 단계\n",
        "        model.eval()\n",
        "        total_val_loss = 0\n",
        "        correct_val = 0\n",
        "        total_val = 0\n",
        "        with torch.no_grad():\n",
        "            for val_images, val_labels in val_loader:\n",
        "                val_images = val_images.to(device)  # 검증 데이터도 CUDA로 이동\n",
        "                val_labels = val_labels.to(device)\n",
        "\n",
        "                val_outputs = model(val_images)\n",
        "\n",
        "                val_loss = criterion(val_outputs, val_labels)\n",
        "                total_val_loss += val_loss.item()\n",
        "\n",
        "                _, val_predicted = torch.max(val_outputs, 1)\n",
        "                correct_val += (val_predicted == val_labels).sum().item()\n",
        "                total_val += val_labels.size(0)\n",
        "\n",
        "        val_accuracy = correct_val / total_val\n",
        "\n",
        "        # 학습률을 퍼센트로 표시\n",
        "        lr_percent = optimizer.param_groups[0]['lr'] * 100\n",
        "        scheduler.step()\n",
        "\n",
        "        # 에포크 마다 출력\n",
        "        print(f'Epoch {epoch+1}, Train Loss: {total_train_loss / len(train_loader):.4f}, '\n",
        "              f'Train Accuracy: {train_accuracy * 100:.2f}%, '\n",
        "              f'Validation Loss: {total_val_loss / len(val_loader):.4f}, '\n",
        "              f'Validation Accuracy: {val_accuracy * 100:.2f}%, '\n",
        "              f'Learning Rate: {lr_percent:.2f}%')\n",
        "\n",
        "        # 최상의 검증 정확도를 가진 모델 저장\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "            torch.save(model.state_dict(), save_path)\n",
        "            print(f'Model saved with Validation Accuracy: {val_accuracy * 100:.2f}%')\n",
        "\n",
        " # 모델 가중치 파일 경로\n",
        "save_path = '/content/drive/MyDrive/dataset/model_final2.pth'\n",
        "\n",
        "# 모델을 생성하고 가중치가 저장된 파일이 존재하면 로드\n",
        "model = FashionGenderModel(num_classes=31).to(device)\n",
        "if os.path.exists(save_path):\n",
        "    model.load_state_dict(torch.load(save_path, map_location=device))\n",
        "    print(f\"Saved model weights loaded from {save_path}\")\n",
        "else:\n",
        "    print(\"No saved weights found. Starting with a new model.\")\n",
        "\n",
        "\n",
        "# 모델 학습 시작\n",
        "train_model(train_loader, val_loader, model, optimizer, criterion, scheduler, epochs=3, save_path='/content/drive/MyDrive/dataset/model_final2.pth')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pgGqPYd4F3T",
        "outputId": "ef1a7ad6-7b1d-4b48-b227-c3c411049b92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-9719e1e803df>:183: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(save_path, map_location=device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model weights loaded from /content/drive/MyDrive/dataset/model_final2.pth\n",
            "Epoch 1, Train Loss: 0.3092, Train Accuracy: 91.45%, Validation Loss: 1.9767, Validation Accuracy: 63.83%, Learning Rate: 0.50%\n",
            "Model saved with Validation Accuracy: 63.83%\n",
            "Epoch 2, Train Loss: 0.2939, Train Accuracy: 92.29%, Validation Loss: 2.0089, Validation Accuracy: 62.99%, Learning Rate: 0.49%\n",
            "Epoch 3, Train Loss: 0.2988, Train Accuracy: 91.74%, Validation Loss: 2.0055, Validation Accuracy: 62.88%, Learning Rate: 0.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2-1]"
      ],
      "metadata": {
        "id": "JGzCJcGQ1viX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvVNEN1az4uc",
        "outputId": "3a10ccf6-ed60-4d26-9ad5-1eff0a8621fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ujson\n",
            "  Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
            "Downloading ujson-5.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ujson\n",
            "Successfully installed ujson-5.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ujson"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 행과 열을 출력하도록 설정\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# 이미지와 JSON 파일의 경로\n",
        "image_dir = '/content/drive/MyDrive/dataset/'\n",
        "training_image_dir = os.path.join(image_dir, 'training_image')\n",
        "validation_image_dir = os.path.join(image_dir, 'validation_image')\n",
        "training_label_dir = os.path.join(image_dir, 'training_label')\n",
        "validation_label_dir = os.path.join(image_dir, 'validation_label')\n",
        "\n",
        "# 이미지 파일과 JSON 파일의 패턴 정의\n",
        "image_pattern = re.compile(r\"^(W|T)_(\\d+)_(\\d+)_(\\w+)_(\\w)\\.jpg$\")\n",
        "label_pattern = re.compile(r\"^(W|T)_(\\d+)_(\\d+)_(\\w+)_(\\w)_(\\d+)\\.json$\")\n",
        "\n",
        "# 유효한 이미지 ID를 저장할 집합\n",
        "def get_valid_image_ids(image_dir):\n",
        "    valid_image_ids = set()\n",
        "    for filename in os.listdir(image_dir):\n",
        "        if image_pattern.match(filename):\n",
        "            img_id = image_pattern.match(filename).group(2)\n",
        "            valid_image_ids.add(img_id)\n",
        "    return valid_image_ids\n",
        "\n",
        "# 통계 계산 함수 (Q5 포함)\n",
        "def calculate_statistics_with_q5(label_dir, valid_image_ids):\n",
        "    stats = []\n",
        "    valid_labels = []\n",
        "\n",
        "    for filename in os.listdir(label_dir):\n",
        "        match = label_pattern.match(filename)\n",
        "        if match:\n",
        "            img_id = match.group(2)\n",
        "            style = match.group(4)\n",
        "            gender = \"여성\" if match.group(1) == \"W\" else \"남성\"\n",
        "            if img_id in valid_image_ids:\n",
        "                with open(os.path.join(label_dir, filename), 'r') as f:\n",
        "                    data = json.load(f)\n",
        "                    # 통계에 사용할 정보 추가\n",
        "                    stats.append({\"성별\": gender, \"스타일\": style, \"이미지 수\": 1})\n",
        "                    # Q5 포함하여 유효한 라벨 저장\n",
        "                    valid_labels.append({\n",
        "                        \"respondent_id\": data[\"user\"][\"R_id\"],\n",
        "                        \"gender\": gender,\n",
        "                        \"style\": style,\n",
        "                        \"image_id\": img_id,\n",
        "                        \"Q5\": data[\"item\"][\"survey\"][\"Q5\"],\n",
        "                        \"img_name\": data[\"item\"][\"imgName\"]\n",
        "                    })\n",
        "\n",
        "    # 통계 데이터프레임 생성 및 집계\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "    stats_df = stats_df.groupby([\"성별\", \"스타일\"]).sum().reset_index()\n",
        "    return stats_df, valid_labels\n",
        "\n",
        "# 유효한 이미지 ID 확인\n",
        "valid_training_ids = get_valid_image_ids(training_image_dir)\n",
        "valid_validation_ids = get_valid_image_ids(validation_image_dir)\n",
        "\n",
        "# 통계 테이블 및 유효 라벨 데이터 생성\n",
        "training_stats, valid_training_labels = calculate_statistics_with_q5(training_label_dir, valid_training_ids)\n",
        "validation_stats, valid_validation_labels = calculate_statistics_with_q5(validation_label_dir, valid_validation_ids)\n",
        "\n",
        "# 출력\n",
        "print(\"Training 통계표:\")\n",
        "display(training_stats)\n",
        "print(\"\\nValidation 통계표:\")\n",
        "display(validation_stats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "Bfh1W5rDWv_w",
        "outputId": "afb47ed1-62b7-4f62-db1e-d5acd9ab51aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-56bf5ca9b86b>\u001b[0m in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m# 통계 테이블 및 유효 라벨 데이터 생성\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m \u001b[0mtraining_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_training_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_statistics_with_q5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_label_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_training_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0mvalidation_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_validation_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_statistics_with_q5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_label_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_validation_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-56bf5ca9b86b>\u001b[0m in \u001b[0;36mcalculate_statistics_with_q5\u001b[0;34m(label_dir, valid_image_ids)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mimg_id\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_image_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0;31m# 통계에 사용할 정보 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"성별\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgender\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"스타일\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"이미지 수\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    291\u001b[0m     \u001b[0mkwarg\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0motherwise\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mJSONDecoder\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m     \"\"\"\n\u001b[0;32m--> 293\u001b[0;31m     return loads(fp.read(),\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_hook\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject_hook\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0mparse_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_int\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_int\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/codecs.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;31m# decode input (taking the buffer into account)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-1 수정"
      ],
      "metadata": {
        "id": "IgjEY4NXrgDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# 모든 행과 열을 출력하도록 설정\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# 경로 설정\n",
        "image_dir = '/content/drive/MyDrive/dataset/'\n",
        "training_image_dir = os.path.join(image_dir, 'training_image')\n",
        "validation_image_dir = os.path.join(image_dir, 'validation_image')\n",
        "training_label_dir = os.path.join(image_dir, 'training_label')\n",
        "validation_label_dir = os.path.join(image_dir, 'validation_label')\n",
        "\n",
        "# 이미지와 JSON 파일의 패턴 정의\n",
        "image_pattern = re.compile(r\"^(W|T)_(\\d+)_(\\d+)_(\\w+)_(\\w)\\.jpg$\")\n",
        "label_pattern = re.compile(r\"^(W|T)_(\\d+)_(\\d+)_(\\w+)_(\\w)_(\\d+)\\.json$\")\n",
        "\n",
        "# 유효한 이미지 ID를 저장할 집합\n",
        "def get_valid_image_ids(image_dir):\n",
        "    valid_image_ids = set()\n",
        "    print(f\"Scanning directory {image_dir} for valid images...\")\n",
        "    for filename in os.listdir(image_dir):\n",
        "        match = image_pattern.match(filename)\n",
        "        if match:\n",
        "            img_id = match.group(2)\n",
        "            valid_image_ids.add(img_id)\n",
        "    print(f\"Found {len(valid_image_ids)} valid image IDs in {image_dir}\")\n",
        "    return valid_image_ids\n",
        "\n",
        "# JSON 파일을 비동기적으로 처리하는 함수\n",
        "def process_json_file(filename, label_dir, valid_image_ids):\n",
        "    try:\n",
        "        match = label_pattern.match(filename)\n",
        "        if match:\n",
        "            img_id = match.group(2)\n",
        "            style = match.group(4)\n",
        "            gender = \"여성\" if match.group(1) == \"W\" else \"남성\"\n",
        "            survey_id = match.group(6)  # 설문 ID 추출\n",
        "\n",
        "            # 유효한 이미지 ID에 해당하는 JSON 파일만 처리\n",
        "            if img_id in valid_image_ids:\n",
        "                with open(os.path.join(label_dir, filename), 'r', encoding='utf-8') as f:\n",
        "                    data = json.load(f)\n",
        "                    return {\n",
        "                        \"성별\": gender,\n",
        "                        \"스타일\": style,\n",
        "                        \"설문 ID 수\": 1,\n",
        "                        \"respondent_id\": data[\"user\"][\"R_id\"],\n",
        "                        \"gender\": gender,\n",
        "                        \"style\": style,\n",
        "                        \"image_id\": img_id,\n",
        "                        \"survey_id\": survey_id,\n",
        "                        \"Q5\": data[\"item\"][\"survey\"][\"Q5\"],\n",
        "                        \"img_name\": data[\"item\"][\"imgName\"]\n",
        "                    }\n",
        "    except OSError as e:\n",
        "        print(f\"Could not process file {filename}: {e}\")\n",
        "    return None\n",
        "\n",
        "# 통계 계산 함수 (멀티 스레드 방식)\n",
        "def calculate_statistics_with_q5(label_dir, valid_image_ids):\n",
        "    stats = []\n",
        "    valid_labels = []\n",
        "    print(f\"Processing JSON files in directory {label_dir} with multithreading...\")\n",
        "\n",
        "    # ThreadPoolExecutor를 사용하여 JSON 파일을 병렬로 처리\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        future_to_file = {executor.submit(process_json_file, filename, label_dir, valid_image_ids): filename for filename in os.listdir(label_dir)}\n",
        "\n",
        "        for future in as_completed(future_to_file):\n",
        "            result = future.result()\n",
        "            if result is not None:\n",
        "                # 통계에 사용할 정보 추가 (설문 ID 수를 기준으로)\n",
        "                stats.append({\"성별\": result[\"성별\"], \"스타일\": result[\"스타일\"], \"설문 ID 수\": 1})\n",
        "\n",
        "                # Q5 포함하여 유효한 라벨 저장\n",
        "                valid_labels.append({\n",
        "                    \"respondent_id\": result[\"respondent_id\"],\n",
        "                    \"gender\": result[\"gender\"],\n",
        "                    \"style\": result[\"style\"],\n",
        "                    \"image_id\": result[\"image_id\"],\n",
        "                    \"survey_id\": result[\"survey_id\"],\n",
        "                    \"Q5\": result[\"Q5\"],\n",
        "                    \"img_name\": result[\"img_name\"]\n",
        "                })\n",
        "\n",
        "    # 통계 데이터프레임 생성 및 집계\n",
        "    print(f\"Aggregating statistics for {label_dir}...\")\n",
        "    stats_df = pd.DataFrame(stats)\n",
        "    if not stats_df.empty:\n",
        "        stats_df = stats_df.groupby([\"성별\", \"스타일\"]).sum().reset_index()\n",
        "    else:\n",
        "        print(\"No valid data found for aggregation.\")\n",
        "\n",
        "    print(f\"Finished processing {label_dir}. Number of entries in stats: {len(stats_df)}\")\n",
        "    return stats_df, valid_labels\n",
        "\n",
        "# 유효한 이미지 ID 확인\n",
        "valid_training_ids = get_valid_image_ids(training_image_dir)\n",
        "valid_validation_ids = get_valid_image_ids(validation_image_dir)\n",
        "\n",
        "# 통계 테이블 및 유효 라벨 데이터 생성\n",
        "training_stats, valid_training_labels = calculate_statistics_with_q5(training_label_dir, valid_training_ids)\n",
        "validation_stats, valid_validation_labels = calculate_statistics_with_q5(validation_label_dir, valid_validation_ids)\n",
        "\n",
        "# 출력\n",
        "print(\"Training 통계표:\")\n",
        "display(training_stats)\n",
        "print(\"\\nValidation 통계표:\")\n",
        "display(validation_stats)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WSNqf5SErf2V",
        "outputId": "77e0f3a0-91b9-42a6-a30e-c7f03b245e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scanning directory /content/drive/MyDrive/dataset/training_image for valid images...\n",
            "Found 4066 valid image IDs in /content/drive/MyDrive/dataset/training_image\n",
            "Scanning directory /content/drive/MyDrive/dataset/validation_image for valid images...\n",
            "Found 951 valid image IDs in /content/drive/MyDrive/dataset/validation_image\n",
            "Processing JSON files in directory /content/drive/MyDrive/dataset/training_label with multithreading...\n",
            "Aggregating statistics for /content/drive/MyDrive/dataset/training_label...\n",
            "Finished processing /content/drive/MyDrive/dataset/training_label. Number of entries in stats: 53\n",
            "Processing JSON files in directory /content/drive/MyDrive/dataset/validation_label with multithreading...\n",
            "Aggregating statistics for /content/drive/MyDrive/dataset/validation_label...\n",
            "Finished processing /content/drive/MyDrive/dataset/validation_label. Number of entries in stats: 40\n",
            "Training 통계표:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    성별             스타일  설문 ID 수\n",
              "0   남성      athleisure        2\n",
              "1   남성   bodyconscious       10\n",
              "2   남성            bold       18\n",
              "3   남성        cityglam       11\n",
              "4   남성         classic       21\n",
              "5   남성           disco        1\n",
              "6   남성         ecology        9\n",
              "7   남성      genderless       18\n",
              "8   남성          grunge        3\n",
              "9   남성          hiphop       64\n",
              "10  남성          hippie       21\n",
              "11  남성             ivy       27\n",
              "12  남성          kitsch       17\n",
              "13  남성        lingerie        7\n",
              "14  남성          lounge       20\n",
              "15  남성     metrosexual       32\n",
              "16  남성        military        1\n",
              "17  남성         minimal       17\n",
              "18  남성            mods       36\n",
              "19  남성        normcore      154\n",
              "20  남성        oriental       17\n",
              "21  남성          popart        1\n",
              "22  남성       powersuit        9\n",
              "23  남성            punk        3\n",
              "24  남성           space        3\n",
              "25  남성  sportivecasual      215\n",
              "26  여성      athleisure       65\n",
              "27  여성   bodyconscious       71\n",
              "28  여성            bold      180\n",
              "29  여성        cityglam       40\n",
              "30  여성         classic       54\n",
              "31  여성           disco       31\n",
              "32  여성         ecology       36\n",
              "33  여성        feminine      144\n",
              "34  여성      genderless       33\n",
              "35  여성          grunge       16\n",
              "36  여성          hiphop      216\n",
              "37  여성          hippie      314\n",
              "38  여성             ivy      308\n",
              "39  여성          kitsch       44\n",
              "40  여성        lingerie       26\n",
              "41  여성          lounge       12\n",
              "42  여성     metrosexual      186\n",
              "43  여성        military       20\n",
              "44  여성         minimal      114\n",
              "45  여성            mods      266\n",
              "46  여성        normcore      165\n",
              "47  여성        oriental       54\n",
              "48  여성          popart       32\n",
              "49  여성       powersuit       96\n",
              "50  여성            punk       32\n",
              "51  여성           space       28\n",
              "52  여성  sportivecasual      288"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-01750b6f-eabd-46e5-b1ba-3e83c3357929\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>성별</th>\n",
              "      <th>스타일</th>\n",
              "      <th>설문 ID 수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>남성</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>남성</td>\n",
              "      <td>bodyconscious</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>남성</td>\n",
              "      <td>bold</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>남성</td>\n",
              "      <td>cityglam</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>남성</td>\n",
              "      <td>classic</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>남성</td>\n",
              "      <td>disco</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>남성</td>\n",
              "      <td>ecology</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>남성</td>\n",
              "      <td>genderless</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>남성</td>\n",
              "      <td>grunge</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>남성</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>남성</td>\n",
              "      <td>hippie</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>남성</td>\n",
              "      <td>ivy</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>남성</td>\n",
              "      <td>kitsch</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>남성</td>\n",
              "      <td>lingerie</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>남성</td>\n",
              "      <td>lounge</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>남성</td>\n",
              "      <td>metrosexual</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>남성</td>\n",
              "      <td>military</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>남성</td>\n",
              "      <td>minimal</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>남성</td>\n",
              "      <td>mods</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>남성</td>\n",
              "      <td>normcore</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>남성</td>\n",
              "      <td>oriental</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>남성</td>\n",
              "      <td>popart</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>남성</td>\n",
              "      <td>powersuit</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>남성</td>\n",
              "      <td>punk</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>남성</td>\n",
              "      <td>space</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>남성</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>여성</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>여성</td>\n",
              "      <td>bodyconscious</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>여성</td>\n",
              "      <td>bold</td>\n",
              "      <td>180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>여성</td>\n",
              "      <td>cityglam</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>여성</td>\n",
              "      <td>classic</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>여성</td>\n",
              "      <td>disco</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>여성</td>\n",
              "      <td>ecology</td>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>여성</td>\n",
              "      <td>feminine</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>여성</td>\n",
              "      <td>genderless</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>여성</td>\n",
              "      <td>grunge</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>여성</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>여성</td>\n",
              "      <td>hippie</td>\n",
              "      <td>314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>여성</td>\n",
              "      <td>ivy</td>\n",
              "      <td>308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>여성</td>\n",
              "      <td>kitsch</td>\n",
              "      <td>44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>여성</td>\n",
              "      <td>lingerie</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>여성</td>\n",
              "      <td>lounge</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>여성</td>\n",
              "      <td>metrosexual</td>\n",
              "      <td>186</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>여성</td>\n",
              "      <td>military</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>여성</td>\n",
              "      <td>minimal</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>여성</td>\n",
              "      <td>mods</td>\n",
              "      <td>266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>여성</td>\n",
              "      <td>normcore</td>\n",
              "      <td>165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>여성</td>\n",
              "      <td>oriental</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>여성</td>\n",
              "      <td>popart</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>여성</td>\n",
              "      <td>powersuit</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>여성</td>\n",
              "      <td>punk</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>여성</td>\n",
              "      <td>space</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>여성</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>288</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01750b6f-eabd-46e5-b1ba-3e83c3357929')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-01750b6f-eabd-46e5-b1ba-3e83c3357929 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-01750b6f-eabd-46e5-b1ba-3e83c3357929');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-116b89fc-8220-44fb-95ac-c56d4426ecf8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-116b89fc-8220-44fb-95ac-c56d4426ecf8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-116b89fc-8220-44fb-95ac-c56d4426ecf8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6e344234-5738-464d-bb2e-57a9710a12bb\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6e344234-5738-464d-bb2e-57a9710a12bb button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_stats",
              "summary": "{\n  \"name\": \"training_stats\",\n  \"rows\": 53,\n  \"fields\": [\n    {\n      \"column\": \"\\uc131\\ubcc4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc5ec\\uc131\",\n          \"\\ub0a8\\uc131\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2a4\\ud0c0\\uc77c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"grunge\",\n          \"lingerie\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc124\\ubb38 ID \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 86,\n        \"min\": 1,\n        \"max\": 314,\n        \"num_unique_values\": 39,\n        \"samples\": [\n          114,\n          96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation 통계표:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    성별             스타일  설문 ID 수\n",
              "0   남성   bodyconscious        1\n",
              "1   남성            bold        3\n",
              "2   남성        cityglam        2\n",
              "3   남성         classic        5\n",
              "4   남성         ecology        1\n",
              "5   남성          hiphop        3\n",
              "6   남성          hippie        1\n",
              "7   남성             ivy        3\n",
              "8   남성            mods        1\n",
              "9   남성        normcore        4\n",
              "10  남성        oriental        2\n",
              "11  남성          popart        1\n",
              "12  남성  sportivecasual       17\n",
              "13  여성      athleisure       16\n",
              "14  여성   bodyconscious       23\n",
              "15  여성            bold       47\n",
              "16  여성        cityglam       13\n",
              "17  여성         classic       22\n",
              "18  여성           disco        7\n",
              "19  여성         ecology       18\n",
              "20  여성        feminine       46\n",
              "21  여성      genderless        7\n",
              "22  여성          grunge        3\n",
              "23  여성          hiphop       66\n",
              "24  여성          hippie      114\n",
              "25  여성             ivy      127\n",
              "26  여성          kitsch       11\n",
              "27  여성        lingerie        5\n",
              "28  여성          lounge        5\n",
              "29  여성     metrosexual       54\n",
              "30  여성        military        8\n",
              "31  여성         minimal       40\n",
              "32  여성            mods       99\n",
              "33  여성        normcore       35\n",
              "34  여성        oriental       11\n",
              "35  여성          popart       10\n",
              "36  여성       powersuit       22\n",
              "37  여성            punk        3\n",
              "38  여성           space       18\n",
              "39  여성  sportivecasual       92"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d11292dc-3b61-44ad-8ab1-6773b674d468\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>성별</th>\n",
              "      <th>스타일</th>\n",
              "      <th>설문 ID 수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>남성</td>\n",
              "      <td>bodyconscious</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>남성</td>\n",
              "      <td>bold</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>남성</td>\n",
              "      <td>cityglam</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>남성</td>\n",
              "      <td>classic</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>남성</td>\n",
              "      <td>ecology</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>남성</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>남성</td>\n",
              "      <td>hippie</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>남성</td>\n",
              "      <td>ivy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>남성</td>\n",
              "      <td>mods</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>남성</td>\n",
              "      <td>normcore</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>남성</td>\n",
              "      <td>oriental</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>남성</td>\n",
              "      <td>popart</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>남성</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>여성</td>\n",
              "      <td>athleisure</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>여성</td>\n",
              "      <td>bodyconscious</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>여성</td>\n",
              "      <td>bold</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>여성</td>\n",
              "      <td>cityglam</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>여성</td>\n",
              "      <td>classic</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>여성</td>\n",
              "      <td>disco</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>여성</td>\n",
              "      <td>ecology</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>여성</td>\n",
              "      <td>feminine</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>여성</td>\n",
              "      <td>genderless</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>여성</td>\n",
              "      <td>grunge</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>여성</td>\n",
              "      <td>hiphop</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>여성</td>\n",
              "      <td>hippie</td>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>여성</td>\n",
              "      <td>ivy</td>\n",
              "      <td>127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>여성</td>\n",
              "      <td>kitsch</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>여성</td>\n",
              "      <td>lingerie</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>여성</td>\n",
              "      <td>lounge</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>여성</td>\n",
              "      <td>metrosexual</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>여성</td>\n",
              "      <td>military</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>여성</td>\n",
              "      <td>minimal</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>여성</td>\n",
              "      <td>mods</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>여성</td>\n",
              "      <td>normcore</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>여성</td>\n",
              "      <td>oriental</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>여성</td>\n",
              "      <td>popart</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>여성</td>\n",
              "      <td>powersuit</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>여성</td>\n",
              "      <td>punk</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>여성</td>\n",
              "      <td>space</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>여성</td>\n",
              "      <td>sportivecasual</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d11292dc-3b61-44ad-8ab1-6773b674d468')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d11292dc-3b61-44ad-8ab1-6773b674d468 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d11292dc-3b61-44ad-8ab1-6773b674d468');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18648667-3dfa-48af-b3b1-5e402b450d68\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18648667-3dfa-48af-b3b1-5e402b450d68')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18648667-3dfa-48af-b3b1-5e402b450d68 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_2df58803-677a-4cf9-9a84-03055db831d2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('validation_stats')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_2df58803-677a-4cf9-9a84-03055db831d2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('validation_stats');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "validation_stats",
              "summary": "{\n  \"name\": \"validation_stats\",\n  \"rows\": 40,\n  \"fields\": [\n    {\n      \"column\": \"\\uc131\\ubcc4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"\\uc5ec\\uc131\",\n          \"\\ub0a8\\uc131\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc2a4\\ud0c0\\uc77c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 27,\n        \"samples\": [\n          \"mods\",\n          \"athleisure\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc124\\ubb38 ID \\uc218\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32,\n        \"min\": 1,\n        \"max\": 127,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          47,\n          127\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2-2 수정"
      ],
      "metadata": {
        "id": "xHPKbjKJyYaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# 모든 행과 열을 출력하도록 설정\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# 상위 100명 응답자를 추출하는 함수\n",
        "def get_top_respondents(valid_labels, top_n=100):\n",
        "    # 응답자 ID별로 라벨링 데이터 개수를 집계하여 상위 N명을 추출\n",
        "    respondent_counts = pd.DataFrame(valid_labels).groupby(\"respondent_id\").size()\n",
        "    top_respondents = respondent_counts.nlargest(top_n).index.tolist()\n",
        "    print(f\"상위 {top_n}명 응답자 ID 추출 완료.\")\n",
        "    return top_respondents\n",
        "\n",
        "# 응답자별 스타일 선호/비선호 정보를 생성하는 함수\n",
        "def create_preference_df(valid_labels, top_respondents, dataset_name):\n",
        "    rows = []\n",
        "\n",
        "    for respondent in top_respondents:\n",
        "        # 해당 응답자의 모든 데이터 추출\n",
        "        respondent_data = [entry for entry in valid_labels if entry['respondent_id'] == respondent]\n",
        "        preferred = [entry['img_name'] for entry in respondent_data if entry['Q5'] == 2]\n",
        "        non_preferred = [entry['img_name'] for entry in respondent_data if entry['Q5'] == 1]\n",
        "\n",
        "        rows.append({\n",
        "            '응답자 ID': respondent,\n",
        "            f'{dataset_name} 스타일 선호': preferred,\n",
        "            f'{dataset_name} 스타일 비선호': non_preferred\n",
        "        })\n",
        "\n",
        "    print(f\"{dataset_name} 스타일 선호 정보 데이터프레임 생성 완료.\")\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# 유효한 라벨 데이터에서 상위 100명의 응답자를 추출\n",
        "top_training_respondents = get_top_respondents(valid_training_labels, top_n=100)\n",
        "top_validation_respondents = get_top_respondents(valid_validation_labels, top_n=100)\n",
        "\n",
        "# 각 응답자의 선호/비선호 스타일 정리\n",
        "training_df = create_preference_df(valid_training_labels, top_training_respondents, 'Training')\n",
        "validation_df = create_preference_df(valid_validation_labels, top_validation_respondents, 'Validation')\n",
        "\n",
        "# 데이터프레임 출력\n",
        "print(\"Training 응답자 스타일 선호 정보:\")\n",
        "display(training_df)\n",
        "print(\"\\nValidation 응답자 스타일 선호 정보:\")\n",
        "display(validation_df)\n",
        "\n",
        "# 두 데이터를 하나의 CSV 파일로 합쳐서 저장\n",
        "top_preference_df = pd.merge(training_df, validation_df, on=\"응답자 ID\", how=\"outer\")\n",
        "output_csv_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "top_preference_df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
        "print(f\"\\n상위 100명의 응답자 스타일 선호도가 {output_csv_path}에 저장되었습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rnt7st_FyZi1",
        "outputId": "52e9e0b7-2912-417d-e336-5bbbd567f09e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "상위 100명 응답자 ID 추출 완료.\n",
            "상위 100명 응답자 ID 추출 완료.\n",
            "Training 스타일 선호 정보 데이터프레임 생성 완료.\n",
            "Validation 스타일 선호 정보 데이터프레임 생성 완료.\n",
            "Training 응답자 스타일 선호 정보:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    응답자 ID  \\\n",
              "0    21432   \n",
              "1    60234   \n",
              "2    62264   \n",
              "3    64345   \n",
              "4    63740   \n",
              "5    64221   \n",
              "6    64460   \n",
              "7    28912   \n",
              "8    60184   \n",
              "9    62525   \n",
              "10   63545   \n",
              "11   63583   \n",
              "12   63934   \n",
              "13   66592   \n",
              "14   60173   \n",
              "15   63207   \n",
              "16   63359   \n",
              "17   63508   \n",
              "18   63571   \n",
              "19   63769   \n",
              "20   63913   \n",
              "21   63927   \n",
              "22   64216   \n",
              "23   64571   \n",
              "24   64598   \n",
              "25   68891   \n",
              "26     837   \n",
              "27   30790   \n",
              "28   35514   \n",
              "29   61104   \n",
              "30   62155   \n",
              "31   62349   \n",
              "32   63156   \n",
              "33   63369   \n",
              "34   63424   \n",
              "35   63435   \n",
              "36   63748   \n",
              "37   64310   \n",
              "38   64397   \n",
              "39   64503   \n",
              "40   65139   \n",
              "41   66513   \n",
              "42    9096   \n",
              "43   22324   \n",
              "44   59083   \n",
              "45   59523   \n",
              "46   59637   \n",
              "47   59704   \n",
              "48   59812   \n",
              "49   63316   \n",
              "50   63479   \n",
              "51   63644   \n",
              "52   63759   \n",
              "53   64561   \n",
              "54   64662   \n",
              "55   64747   \n",
              "56   66469   \n",
              "57    7658   \n",
              "58   20768   \n",
              "59   28371   \n",
              "60   61250   \n",
              "61   61493   \n",
              "62   61859   \n",
              "63   63405   \n",
              "64   63505   \n",
              "65   63742   \n",
              "66   63910   \n",
              "67   64223   \n",
              "68   64364   \n",
              "69     368   \n",
              "70   18730   \n",
              "71   28358   \n",
              "72   28571   \n",
              "73   50277   \n",
              "74   59506   \n",
              "75   62113   \n",
              "76   62625   \n",
              "77   62868   \n",
              "78   63430   \n",
              "79   63481   \n",
              "80   63526   \n",
              "81   63717   \n",
              "82   63930   \n",
              "83   64252   \n",
              "84   64327   \n",
              "85   64336   \n",
              "86   64346   \n",
              "87   66731   \n",
              "88    4035   \n",
              "89    7905   \n",
              "90   18129   \n",
              "91   23108   \n",
              "92   58251   \n",
              "93   59642   \n",
              "94   59857   \n",
              "95   59901   \n",
              "96   62653   \n",
              "97   62952   \n",
              "98   63255   \n",
              "99   63391   \n",
              "\n",
              "                                                                                                                                                                                                                        Training 스타일 선호  \\\n",
              "0                                                                                                          [W_28523_90_hiphop_M.jpg, W_09891_90_hiphop_M.jpg, W_29023_00_metrosexual_M.jpg, W_15294_50_ivy_M.jpg, W_32448_50_ivy_M.jpg]   \n",
              "1                                                                                                                   [W_01693_19_normcore_M.jpg, W_17337_50_ivy_M.jpg, W_16539_50_ivy_M.jpg, W_07102_50_ivy_M.jpg, W_12748_50_ivy_M.jpg]   \n",
              "2                                                      [W_07260_10_sportivecasual_M.jpg, W_16449_10_sportivecasual_M.jpg, W_16403_10_sportivecasual_M.jpg, W_07098_19_normcore_M.jpg, W_07307_19_normcore_M.jpg, W_05869_60_mods_M.jpg]   \n",
              "3   [W_28449_10_sportivecasual_M.jpg, W_17467_19_normcore_M.jpg, W_00843_10_sportivecasual_M.jpg, W_29596_10_sportivecasual_M.jpg, W_27156_90_hiphop_M.jpg, W_32150_00_metrosexual_M.jpg, W_15856_60_mods_M.jpg, W_24155_60_mods_M.jpg]   \n",
              "4                                                                                            [W_04201_19_lounge_W.jpg, W_01179_10_sportivecasual_W.jpg, W_11824_70_military_W.jpg, W_14975_60_minimal_W.jpg, W_18894_50_feminine_W.jpg]   \n",
              "5                                                                                                 [W_28698_10_sportivecasual_M.jpg, W_25039_90_hiphop_M.jpg, W_32524_00_metrosexual_M.jpg, W_28728_50_ivy_M.jpg, W_24013_60_mods_M.jpg]   \n",
              "6                                                              [W_24294_80_bold_M.jpg, W_24934_90_hiphop_M.jpg, W_26530_00_metrosexual_M.jpg, W_06514_80_bold_M.jpg, W_10792_50_ivy_M.jpg, W_12817_50_ivy_M.jpg, W_15653_60_mods_M.jpg]   \n",
              "7                                                                                                                                              [W_01754_10_sportivecasual_M.jpg, W_04680_10_sportivecasual_M.jpg, W_02669_50_ivy_M.jpg]   \n",
              "8                                                                                                                                                       [W_01687_19_normcore_M.jpg, W_17427_00_metrosexual_M.jpg, W_17348_50_ivy_M.jpg]   \n",
              "9           [W_00760_19_normcore_W.jpg, W_05751_10_sportivecasual_W.jpg, W_19165_00_cityglam_W.jpg, W_03477_80_powersuit_W.jpg, W_01207_60_minimal_W.jpg, W_11223_60_popart_W.jpg, W_13104_50_classic_W.jpg, W_18495_50_feminine_W.jpg]   \n",
              "10                                                                                                                     [W_08322_19_normcore_W.jpg, W_14897_10_sportivecasual_W.jpg, W_04993_70_hippie_W.jpg, W_03842_50_feminine_W.jpg]   \n",
              "11                                                                                                                                                                               [W_02100_00_oriental_W.jpg, W_00385_50_feminine_W.jpg]   \n",
              "12                                                                                                                                                                                   [W_16255_19_normcore_M.jpg, W_12327_80_bold_M.jpg]   \n",
              "13                                                                            [W_46907_80_powersuit_W.jpg, W_53583_90_hiphop_W.jpg, W_53861_90_kitsch_W.jpg, W_53133_90_hiphop_W.jpg, W_44918_60_minimal_W.jpg, W_02343_60_space_W.jpg]   \n",
              "14                                                        [W_14216_10_sportivecasual_W.jpg, W_08869_10_sportivecasual_W.jpg, W_05458_10_athleisure_W.jpg, W_07964_70_military_W.jpg, W_14099_50_classic_W.jpg, W_09079_60_popart_W.jpg]   \n",
              "15                                                                                                                                                                                                    [W_02771_10_sportivecasual_M.jpg]   \n",
              "16                                                                                                                                                  [W_00410_19_genderless_W.jpg, W_01958_00_cityglam_W.jpg, W_08140_50_feminine_W.jpg]   \n",
              "17                                                                                              [W_15768_19_normcore_M.jpg, W_15156_00_metrosexual_M.jpg, W_12698_80_bold_M.jpg, W_16295_70_hippie_M.jpg, W_15488_00_metrosexual_M.jpg]   \n",
              "18                                                                                                                                                                                                    [W_04649_10_sportivecasual_M.jpg]   \n",
              "19                                                                                                                                                                                                    [W_09795_10_sportivecasual_M.jpg]   \n",
              "20                                                                      [W_00553_10_sportivecasual_M.jpg, W_07066_10_sportivecasual_M.jpg, W_07255_50_ivy_M.jpg, W_07150_70_hippie_M.jpg, W_06573_60_mods_M.jpg, W_06883_60_mods_M.jpg]   \n",
              "21                                                                                                                                                                                   [W_06824_19_normcore_M.jpg, W_06531_60_mods_M.jpg]   \n",
              "22                                                                                                                                                    [W_27674_10_sportivecasual_M.jpg, W_17855_90_hiphop_M.jpg, W_02816_60_mods_M.jpg]   \n",
              "23                                                                                                                                                                                                          [W_00794_19_normcore_M.jpg]   \n",
              "24                                                         [W_48074_10_sportivecasual_W.jpg, W_21732_10_sportivecasual_W.jpg, W_27930_80_powersuit_W.jpg, W_00638_90_hiphop_W.jpg, W_04895_50_classic_W.jpg, W_09961_50_feminine_W.jpg]   \n",
              "25                               [T_15458_10_sportivecasual_M.jpg, T_15453_10_sportivecasual_M.jpg, T_15468_10_sportivecasual_M.jpg, T_15477_10_sportivecasual_M.jpg, T_15488_10_sportivecasual_M.jpg, T_15467_10_sportivecasual_M.jpg]   \n",
              "26                                                     [W_00829_10_sportivecasual_M.jpg, W_28209_10_sportivecasual_M.jpg, W_28211_19_normcore_M.jpg, W_28722_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg, W_25073_90_hiphop_M.jpg]   \n",
              "27                                                                                                                              [W_33023_10_sportivecasual_M.jpg, W_26425_90_hiphop_M.jpg, W_06511_50_ivy_M.jpg, W_06863_60_mods_M.jpg]   \n",
              "28                                                                                                  [W_01716_19_normcore_M.jpg, W_04539_10_sportivecasual_M.jpg, W_01645_90_hiphop_M.jpg, W_01664_60_mods_M.jpg, W_09152_60_mods_M.jpg]   \n",
              "29                                                                                                                  [W_07906_00_ecology_W.jpg, W_08810_10_sportivecasual_W.jpg, W_04919_00_oriental_W.jpg, W_02487_10_athleisure_W.jpg]   \n",
              "30                                                                                                                                                                                    [W_31063_19_normcore_M.jpg, W_27854_50_ivy_M.jpg]   \n",
              "31                                                                                                                                                      [W_04689_10_sportivecasual_M.jpg, W_17802_80_bold_M.jpg, W_07101_60_mods_M.jpg]   \n",
              "32                                                                                                                                                                                                        [W_01318_10_athleisure_W.jpg]   \n",
              "33                                                                                              [W_03000_19_normcore_M.jpg, W_09785_19_normcore_M.jpg, W_01428_10_sportivecasual_M.jpg, W_04733_90_hiphop_M.jpg, W_09760_60_mods_M.jpg]   \n",
              "34                                                                                                                                                 [W_19801_19_genderless_W.jpg, W_09698_19_genderless_W.jpg, W_01962_60_minimal_W.jpg]   \n",
              "35                                                              [W_08285_19_normcore_W.jpg, W_19407_19_normcore_W.jpg, W_01041_10_sportivecasual_W.jpg, W_19010_00_oriental_W.jpg, W_18401_90_lingerie_W.jpg, W_04192_60_minimal_W.jpg]   \n",
              "36                                                                                                      [W_02890_19_normcore_M.jpg, W_00829_10_sportivecasual_M.jpg, W_15268_50_ivy_M.jpg, W_10092_60_mods_M.jpg, W_17867_50_ivy_M.jpg]   \n",
              "37                                                                                                                                 [W_26375_70_hippie_M.jpg, W_16007_70_hippie_M.jpg, W_25934_90_hiphop_M.jpg, W_04692_90_hiphop_M.jpg]   \n",
              "38                                                                                                                                                                                    [W_17793_19_normcore_M.jpg, W_24889_50_ivy_M.jpg]   \n",
              "39                                                                     [W_43214_19_genderless_W.jpg, W_45353_80_powersuit_W.jpg, W_40718_90_hiphop_W.jpg, W_43570_90_hiphop_W.jpg, W_36275_60_minimal_W.jpg, W_07755_50_feminine_W.jpg]   \n",
              "40                                                                                                                                                                               [W_64254_19_normcore_M.jpg, W_16523_19_normcore_M.jpg]   \n",
              "41                                                                                                                             [W_60789_90_lingerie_W.jpg, W_44554_90_grunge_W.jpg, W_35544_60_minimal_W.jpg, W_19031_50_classic_W.jpg]   \n",
              "42                                                                        [W_03582_19_normcore_W.jpg, W_03784_00_cityglam_W.jpg, W_08797_70_disco_W.jpg, W_14507_60_minimal_W.jpg, W_03160_60_minimal_W.jpg, W_19987_50_feminine_W.jpg]   \n",
              "43                                                                                                                      [W_04372_10_sportivecasual_M.jpg, W_07347_90_hiphop_M.jpg, W_17700_00_metrosexual_M.jpg, W_02696_60_mods_M.jpg]   \n",
              "44                                                                                                [W_09799_19_normcore_M.jpg, W_06836_00_metrosexual_M.jpg, W_06547_00_metrosexual_M.jpg, W_10803_80_bold_M.jpg, W_15367_60_mods_M.jpg]   \n",
              "45                                                                                               [W_09060_19_normcore_W.jpg, W_05673_10_sportivecasual_W.jpg, W_09533_90_grunge_W.jpg, W_05690_70_punk_W.jpg, W_18661_60_minimal_W.jpg]   \n",
              "46                                                                                                                      [W_00784_19_normcore_W.jpg, W_08042_10_athleisure_W.jpg, W_09626_10_athleisure_W.jpg, W_03580_60_minimal_W.jpg]   \n",
              "47                                                                                                                                                          [W_07211_00_metrosexual_M.jpg, W_04636_50_ivy_M.jpg, W_06558_60_mods_M.jpg]   \n",
              "48                                                                                                                                                                                                    [W_06672_10_sportivecasual_M.jpg]   \n",
              "49                                                                                                                    [W_06484_19_lounge_W.jpg, W_05594_19_genderless_W.jpg, W_05580_10_sportivecasual_W.jpg, W_07586_60_minimal_W.jpg]   \n",
              "50                                                                                                  [W_09086_19_normcore_W.jpg, W_19413_00_oriental_W.jpg, W_14584_50_classic_W.jpg, W_18202_60_minimal_W.jpg, W_04994_60_popart_W.jpg]   \n",
              "51                                                                                                                                 [W_05127_90_kitsch_W.jpg, W_03934_70_hippie_W.jpg, W_07688_70_disco_W.jpg, W_14787_60_minimal_W.jpg]   \n",
              "52                                                                                                                                                [W_05821_90_kitsch_W.jpg, W_09611_10_sportivecasual_W.jpg, W_05715_70_military_W.jpg]   \n",
              "53                                                                                                                                                   [W_36907_19_genderless_W.jpg, W_18759_50_feminine_W.jpg, W_18066_50_classic_W.jpg]   \n",
              "54                                                                                                                                                                                                                                   []   \n",
              "55                                                                                         [W_39725_19_normcore_W.jpg, W_29783_10_sportivecasual_W.jpg, W_34636_00_oriental_W.jpg, W_04972_90_kitsch_W.jpg, W_21223_80_powersuit_W.jpg]   \n",
              "56                                                                                [T_00456_10_sportivecasual_M.jpg, T_03772_90_hiphop_M.jpg, W_06657_60_mods_M.jpg, W_00486_60_mods_M.jpg, W_10810_60_mods_M.jpg, W_51362_50_ivy_M.jpg]   \n",
              "57                                                                                                                                                                   [W_01234_10_sportivecasual_W.jpg, W_08708_10_sportivecasual_W.jpg]   \n",
              "58                                                                                                                                                                          [W_09011_10_sportivecasual_W.jpg, W_18900_50_classic_W.jpg]   \n",
              "59                                                                                                                                                        [W_17461_19_normcore_M.jpg, W_57031_90_hiphop_M.jpg, W_25020_90_hiphop_M.jpg]   \n",
              "60                                                                                                                             [W_62598_19_normcore_W.jpg, W_47873_70_punk_W.jpg, W_01933_50_feminine_W.jpg, W_13173_50_feminine_W.jpg]   \n",
              "61                                                                                                                      [W_04661_10_sportivecasual_M.jpg, W_02881_10_sportivecasual_M.jpg, W_02818_60_mods_M.jpg, W_04232_50_ivy_M.jpg]   \n",
              "62                                                                                                                                                                                                                                   []   \n",
              "63                                                                                                                                                                                     [W_04684_90_hiphop_M.jpg, W_15400_60_mods_M.jpg]   \n",
              "64                                      [W_11117_19_normcore_M.jpg, W_09186_10_sportivecasual_M.jpg, W_07078_10_sportivecasual_M.jpg, W_12328_80_bold_M.jpg, W_17803_80_bold_M.jpg, W_17907_00_metrosexual_M.jpg, W_12393_50_ivy_M.jpg]   \n",
              "65                                                                                                                                                                                                                                   []   \n",
              "66                                                                                                                                                               [W_17529_70_hippie_M.jpg, W_17962_50_ivy_M.jpg, W_00495_60_mods_M.jpg]   \n",
              "67                                                                                                                                                                                                          [W_04537_19_normcore_M.jpg]   \n",
              "68                                                                                                                        [W_01472_19_normcore_M.jpg, W_32885_10_sportivecasual_M.jpg, W_16850_19_normcore_M.jpg, W_24141_50_ivy_M.jpg]   \n",
              "69                                                                                                                                                                                   [W_02804_19_normcore_M.jpg, W_06843_60_mods_M.jpg]   \n",
              "70                                                                                                                                                                [W_16362_80_bold_M.jpg, W_12196_80_bold_M.jpg, W_06847_60_mods_M.jpg]   \n",
              "71                                                                                                                                                                                                                                   []   \n",
              "72                                                                                                                                                                                                               [W_12826_50_ivy_M.jpg]   \n",
              "73                                                                                                                                                                              [W_09792_10_sportivecasual_M.jpg, W_06909_50_ivy_M.jpg]   \n",
              "74                                                                                                                                                     [W_02265_70_military_W.jpg, W_11218_50_feminine_W.jpg, W_13247_60_minimal_W.jpg]   \n",
              "75                                                                             [W_02567_10_sportivecasual_W.jpg, W_04068_10_athleisure_W.jpg, W_10554_80_bodyconscious_W.jpg, W_08595_80_bodyconscious_W.jpg, W_09639_50_classic_W.jpg]   \n",
              "76                                                                                                                                                    [W_09363_19_genderless_W.jpg, W_05247_90_hiphop_W.jpg, W_07950_70_military_W.jpg]   \n",
              "77                                                                                                                                                                                                                                   []   \n",
              "78                                                                                                                                                                                 [W_08809_19_lounge_W.jpg, W_00570_90_lingerie_W.jpg]   \n",
              "79                                                                                                                                          [W_01480_10_sportivecasual_M.jpg, W_16975_10_sportivecasual_M.jpg, W_05894_90_hiphop_M.jpg]   \n",
              "80                                                                                                                                                                               [W_03388_00_cityglam_W.jpg, W_01993_00_oriental_W.jpg]   \n",
              "81                                                                                                                                                                                                          [W_09352_70_military_W.jpg]   \n",
              "82                                                                                                                                            [W_01558_10_sportivecasual_M.jpg, W_09792_10_sportivecasual_M.jpg, W_12196_80_bold_M.jpg]   \n",
              "83                                                                                                                                                                                   [W_07138_19_normcore_M.jpg, W_24152_60_mods_M.jpg]   \n",
              "84                                                                                                                                                                                 [W_24403_00_metrosexual_M.jpg, W_15095_50_ivy_M.jpg]   \n",
              "85                                                                                                                                                                                     [W_06603_90_hiphop_M.jpg, W_00479_60_mods_M.jpg]   \n",
              "86                                                                                                       [W_00856_10_sportivecasual_M.jpg, W_16233_80_bold_M.jpg, W_24977_70_hippie_M.jpg, W_30040_60_mods_M.jpg, W_24103_50_ivy_M.jpg]   \n",
              "87                                                                                                                                                                               [W_01088_70_military_W.jpg, W_04781_50_feminine_W.jpg]   \n",
              "88                                                                                                                                                                                                               [W_15186_50_ivy_M.jpg]   \n",
              "89                                                                                                                                                                                                                                   []   \n",
              "90                                                                                                                                                                                      [W_01424_70_hippie_M.jpg, W_02710_50_ivy_M.jpg]   \n",
              "91                                                                                                                                                                                        [W_30483_80_bold_M.jpg, W_04601_50_ivy_M.jpg]   \n",
              "92                                                                                                                                                                                                          [W_01259_90_lingerie_W.jpg]   \n",
              "93                                                                                                                                [W_16917_10_athleisure_W.jpg, W_18366_70_disco_W.jpg, W_02444_70_punk_W.jpg, W_02095_60_popart_W.jpg]   \n",
              "94                                                                                                                                                         [W_14888_19_normcore_W.jpg, W_03599_70_punk_W.jpg, W_18546_50_classic_W.jpg]   \n",
              "95                                                                                                                                                       [W_04649_10_sportivecasual_M.jpg, W_00017_60_mods_M.jpg, W_12821_50_ivy_M.jpg]   \n",
              "96                                                                                                                                                                                [W_26093_00_metrosexual_M.jpg, W_02958_60_mods_M.jpg]   \n",
              "97                                                                                                                                                                               [W_38394_19_normcore_W.jpg, W_04928_50_feminine_W.jpg]   \n",
              "98                                                                                                                                          [W_02846_70_hippie_M.jpg, W_16541_50_ivy_M.jpg, W_10804_50_ivy_M.jpg, W_00036_50_ivy_M.jpg]   \n",
              "99                                                                                                                                                                                   [W_07215_19_normcore_M.jpg, W_09140_60_mods_M.jpg]   \n",
              "\n",
              "                                                                                                                                                                                                                                      Training 스타일 비선호  \n",
              "0                            [W_29224_10_sportivecasual_M.jpg, W_26017_10_sportivecasual_M.jpg, W_26151_80_bold_M.jpg, W_26296_70_hippie_M.jpg, W_12383_80_bold_M.jpg, W_24439_00_metrosexual_M.jpg, W_26397_70_hippie_M.jpg, W_25107_70_hippie_M.jpg]  \n",
              "1                                                  [W_17508_80_bold_M.jpg, W_02844_90_hiphop_M.jpg, W_16755_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_16673_70_hippie_M.jpg, W_15423_80_bold_M.jpg, W_06546_60_mods_M.jpg, W_15259_60_mods_M.jpg]  \n",
              "2                                                                             [W_16136_80_bold_M.jpg, W_15477_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_16428_90_hiphop_M.jpg, W_16189_50_ivy_M.jpg, W_16189_50_ivy_M.jpg, W_04233_60_mods_M.jpg]  \n",
              "3                                                                                                                       [W_24825_80_bold_M.jpg, W_25884_90_hiphop_M.jpg, W_11105_00_metrosexual_M.jpg, W_24352_70_hippie_M.jpg, W_24325_60_mods_M.jpg]  \n",
              "4                                                [W_05226_10_sportivecasual_W.jpg, W_08607_90_kitsch_W.jpg, W_19264_90_kitsch_W.jpg, W_03656_90_hiphop_W.jpg, W_05353_80_bodyconscious_W.jpg, W_06083_80_bodyconscious_W.jpg, W_07532_70_hippie_W.jpg]  \n",
              "5                                                                             [W_26397_70_hippie_M.jpg, W_25471_70_hippie_M.jpg, W_12130_80_bold_M.jpg, W_28207_90_hiphop_M.jpg, W_17747_80_bold_M.jpg, W_15129_50_ivy_M.jpg, W_07333_70_hippie_M.jpg]  \n",
              "6                                                                                                                       [W_25069_90_hiphop_M.jpg, W_31356_80_bold_M.jpg, W_25082_70_hippie_M.jpg, W_30522_00_metrosexual_M.jpg, W_25526_60_mods_M.jpg]  \n",
              "7                                                    [W_17260_19_normcore_M.jpg, W_16725_70_hippie_M.jpg, W_15745_80_bold_M.jpg, W_04723_90_hiphop_M.jpg, W_15923_80_bold_M.jpg, W_04242_60_mods_M.jpg, W_15246_50_ivy_M.jpg, W_03007_70_hippie_M.jpg]  \n",
              "8                                    [W_12453_10_sportivecasual_M.jpg, W_12095_80_bold_M.jpg, W_28377_80_bold_M.jpg, W_27913_00_metrosexual_M.jpg, W_25030_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_16016_70_hippie_M.jpg, W_04245_70_hippie_M.jpg]  \n",
              "9                                                                                                                                                                     [W_13667_00_oriental_W.jpg, W_08167_60_minimal_W.jpg, W_07447_50_feminine_W.jpg]  \n",
              "10                                                             [W_04035_19_normcore_W.jpg, W_08610_90_grunge_W.jpg, W_19342_70_hippie_W.jpg, W_10655_50_feminine_W.jpg, W_12003_60_minimal_W.jpg, W_13846_60_minimal_W.jpg, W_10981_50_feminine_W.jpg]  \n",
              "11        [W_10223_00_oriental_W.jpg, W_18920_00_oriental_W.jpg, W_03693_10_athleisure_W.jpg, W_01248_90_hiphop_W.jpg, W_18030_90_kitsch_W.jpg, W_19311_70_punk_W.jpg, W_19964_80_powersuit_W.jpg, W_18543_60_popart_W.jpg, W_04901_50_feminine_W.jpg]  \n",
              "12  [W_01630_10_sportivecasual_M.jpg, W_10791_19_normcore_M.jpg, W_16236_80_bold_M.jpg, W_11063_00_metrosexual_M.jpg, W_02755_90_hiphop_M.jpg, W_01794_00_metrosexual_M.jpg, W_15669_00_metrosexual_M.jpg, W_17603_50_ivy_M.jpg, W_06259_50_ivy_M.jpg]  \n",
              "13                                                                                                                     [W_52969_00_ecology_W.jpg, W_51690_80_powersuit_W.jpg, W_52731_90_kitsch_W.jpg, W_41924_70_punk_W.jpg, W_47960_60_popart_W.jpg]  \n",
              "14                                                                                                                                        [W_19273_00_ecology_W.jpg, W_07408_90_lingerie_W.jpg, W_06402_80_powersuit_W.jpg, W_09497_50_feminine_W.jpg]  \n",
              "15      [W_00505_10_sportivecasual_M.jpg, W_16390_10_sportivecasual_M.jpg, W_11033_90_hiphop_M.jpg, W_15634_80_bold_M.jpg, W_16684_00_metrosexual_M.jpg, W_16361_80_bold_M.jpg, W_09796_60_mods_M.jpg, W_10087_70_hippie_M.jpg, W_09132_60_mods_M.jpg]  \n",
              "16                                                     [W_10207_00_oriental_W.jpg, W_10289_00_oriental_W.jpg, W_13858_80_bodyconscious_W.jpg, W_13941_60_minimal_W.jpg, W_12019_50_feminine_W.jpg, W_19530_60_popart_W.jpg, W_07682_50_feminine_W.jpg]  \n",
              "17                                                                                                                 [W_07043_10_sportivecasual_M.jpg, W_13458_80_bold_M.jpg, W_11071_00_metrosexual_M.jpg, W_16180_50_ivy_M.jpg, W_10817_60_mods_M.jpg]  \n",
              "18             [W_00815_19_normcore_M.jpg, W_07001_19_normcore_M.jpg, W_02855_10_sportivecasual_M.jpg, W_17207_00_metrosexual_M.jpg, W_15623_70_hippie_M.jpg, W_15270_60_mods_M.jpg, W_00492_50_ivy_M.jpg, W_02740_50_ivy_M.jpg, W_15093_50_ivy_M.jpg]  \n",
              "19            [W_07373_19_normcore_M.jpg, W_17262_19_normcore_M.jpg, W_17688_19_normcore_M.jpg, W_11011_80_bold_M.jpg, W_12408_90_hiphop_M.jpg, W_16806_00_metrosexual_M.jpg, W_04632_90_hiphop_M.jpg, W_07123_70_hippie_M.jpg, W_10122_60_mods_M.jpg]  \n",
              "20                                                                                                                                    [W_17009_19_normcore_M.jpg, W_16444_10_sportivecasual_M.jpg, W_15843_00_metrosexual_M.jpg, W_10066_50_ivy_M.jpg]  \n",
              "21                               [W_16412_10_sportivecasual_M.jpg, W_12650_90_hiphop_M.jpg, W_11143_00_metrosexual_M.jpg, W_15276_00_metrosexual_M.jpg, W_17443_90_hiphop_M.jpg, W_15651_70_hippie_M.jpg, W_17779_80_bold_M.jpg, W_15080_50_ivy_M.jpg]  \n",
              "22                                                                    [W_31918_19_normcore_M.jpg, W_25452_19_normcore_M.jpg, W_32426_70_hippie_M.jpg, W_15666_90_hiphop_M.jpg, W_26288_70_hippie_M.jpg, W_24486_70_hippie_M.jpg, W_24931_50_ivy_M.jpg]  \n",
              "23        [W_29383_10_sportivecasual_M.jpg, W_31502_19_normcore_M.jpg, W_32860_80_bold_M.jpg, W_16985_70_hippie_M.jpg, W_11145_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_24059_50_ivy_M.jpg, W_25406_00_metrosexual_M.jpg, W_24180_60_mods_M.jpg]  \n",
              "24                                                                                                                                      [W_11262_00_oriental_W.jpg, W_31881_80_powersuit_W.jpg, W_27619_80_powersuit_W.jpg, W_02442_50_feminine_W.jpg]  \n",
              "25                                                                                                                [T_15462_10_sportivecasual_M.jpg, T_15443_10_sportivecasual_M.jpg, T_15441_10_sportivecasual_M.jpg, T_09788_10_sportivecasual_M.jpg]  \n",
              "26                                                                                                                                                                    [W_07130_19_normcore_M.jpg, W_24845_80_bold_M.jpg, W_16659_00_metrosexual_M.jpg]  \n",
              "27                                                                                                       [W_26359_19_normcore_M.jpg, W_25835_10_sportivecasual_M.jpg, W_29485_10_sportivecasual_M.jpg, W_24886_70_hippie_M.jpg, W_24769_60_mods_M.jpg]  \n",
              "28                                                                                                                                        [W_12634_10_sportivecasual_M.jpg, W_04406_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_10814_50_ivy_M.jpg]  \n",
              "29                                                                                                              [W_19430_00_oriental_W.jpg, W_07717_90_kitsch_W.jpg, W_14147_70_disco_W.jpg, W_08511_80_bodyconscious_W.jpg, W_08670_50_classic_W.jpg]  \n",
              "30                                                                [W_32383_00_metrosexual_M.jpg, W_15666_90_hiphop_M.jpg, W_24569_70_hippie_M.jpg, W_12265_00_metrosexual_M.jpg, W_24492_70_hippie_M.jpg, W_17353_50_ivy_M.jpg, W_01726_60_mods_M.jpg]  \n",
              "31                                                                                                 [W_06253_90_hiphop_M.jpg, W_16681_70_hippie_M.jpg, W_07095_00_metrosexual_M.jpg, W_12552_80_bold_M.jpg, W_15125_50_ivy_M.jpg, W_17353_50_ivy_M.jpg]  \n",
              "32                        [W_09007_19_normcore_W.jpg, W_11504_19_lounge_W.jpg, W_01166_10_sportivecasual_W.jpg, W_19061_90_kitsch_W.jpg, W_08180_80_bodyconscious_W.jpg, W_19838_60_popart_W.jpg, W_14259_50_feminine_W.jpg, W_18729_50_classic_W.jpg]  \n",
              "33                                                                                                                                             [W_12487_90_hiphop_M.jpg, W_01509_00_metrosexual_M.jpg, W_15884_80_bold_M.jpg, W_06563_70_hippie_M.jpg]  \n",
              "34                                                                          [W_07715_19_normcore_W.jpg, W_05652_10_athleisure_W.jpg, W_03717_10_athleisure_W.jpg, W_07675_80_bodyconscious_W.jpg, W_19301_50_feminine_W.jpg, W_14997_60_minimal_W.jpg]  \n",
              "35                                                                                                                                                               [W_08838_10_athleisure_W.jpg, W_03787_80_bodyconscious_W.jpg, W_14345_60_space_W.jpg]  \n",
              "36                                                                                                                                        [W_15116_00_metrosexual_M.jpg, W_04484_90_hiphop_M.jpg, W_11144_00_metrosexual_M.jpg, W_10079_60_mods_M.jpg]  \n",
              "37                                                                                                                   [W_28801_19_normcore_M.jpg, W_28741_19_normcore_M.jpg, W_01799_00_metrosexual_M.jpg, W_16259_80_bold_M.jpg, W_32131_50_ivy_M.jpg]  \n",
              "38                                                    [W_31360_19_normcore_M.jpg, W_30015_00_metrosexual_M.jpg, W_29830_90_hiphop_M.jpg, W_28319_90_hiphop_M.jpg, W_11080_00_metrosexual_M.jpg, W_06665_00_metrosexual_M.jpg, W_24348_70_hippie_M.jpg]  \n",
              "39                                                                                                                                                                  [W_34027_10_sportivecasual_W.jpg, W_42376_90_grunge_W.jpg, W_30932_70_disco_W.jpg]  \n",
              "40                                                                 [W_26315_19_normcore_M.jpg, W_01898_19_normcore_M.jpg, W_57822_90_hiphop_M.jpg, W_52693_00_metrosexual_M.jpg, W_16063_80_bold_M.jpg, W_62525_90_hiphop_M.jpg, W_66114_50_ivy_M.jpg]  \n",
              "41                                                                                                     [W_56334_10_sportivecasual_W.jpg, W_68199_10_sportivecasual_W.jpg, W_34173_19_normcore_W.jpg, W_38863_60_minimal_W.jpg, W_37404_60_space_W.jpg]  \n",
              "42                                                                                                                                                                                              [W_03461_19_normcore_W.jpg, W_12033_00_cityglam_W.jpg]  \n",
              "43                                                                                                                                               [W_15443_70_hippie_M.jpg, W_15091_80_bold_M.jpg, W_15511_00_metrosexual_M.jpg, W_17893_80_bold_M.jpg]  \n",
              "44                                                                                                                                                          [W_16435_10_sportivecasual_M.jpg, W_18545_19_normcore_M.jpg, W_12593_00_metrosexual_M.jpg]  \n",
              "45                                                                                                                                                                  [W_08092_90_hiphop_W.jpg, W_05246_80_bodyconscious_W.jpg, W_19742_60_popart_W.jpg]  \n",
              "46                                                                                                                                      [W_18644_19_genderless_W.jpg, W_14410_19_genderless_W.jpg, W_03430_90_lingerie_W.jpg, W_18462_90_kitsch_W.jpg]  \n",
              "47                                                                                                               [W_11141_19_normcore_M.jpg, W_04573_10_sportivecasual_M.jpg, W_12476_90_hiphop_M.jpg, W_16676_90_hiphop_M.jpg, W_15120_60_mods_M.jpg]  \n",
              "48                                                      [W_17916_10_sportivecasual_M.jpg, W_11085_19_normcore_M.jpg, W_03044_19_normcore_M.jpg, W_12564_00_metrosexual_M.jpg, W_06759_90_hiphop_M.jpg, W_12120_80_bold_M.jpg, W_05879_70_hippie_M.jpg]  \n",
              "49                                                                                                                                      [W_11796_19_genderless_W.jpg, W_19165_00_cityglam_W.jpg, W_11950_00_oriental_W.jpg, W_19177_50_feminine_W.jpg]  \n",
              "50                                                                                                                                                                        [W_18878_19_genderless_W.jpg, W_00631_70_disco_W.jpg, W_19921_70_punk_W.jpg]  \n",
              "51                                                                                                                 [W_05472_10_sportivecasual_W.jpg, W_01326_10_sportivecasual_W.jpg, W_01390_10_sportivecasual_W.jpg, W_14273_80_bodyconscious_W.jpg]  \n",
              "52                                                                                                          [W_18199_19_normcore_W.jpg, W_01334_19_normcore_W.jpg, W_03258_00_ecology_W.jpg, W_04031_80_bodyconscious_W.jpg, W_18549_60_minimal_W.jpg]  \n",
              "53                                                                                                               [W_26946_19_lounge_W.jpg, W_41279_19_genderless_W.jpg, W_32248_80_powersuit_W.jpg, W_02232_70_hippie_W.jpg, W_33622_60_minimal_W.jpg]  \n",
              "54                       [W_22067_19_normcore_W.jpg, W_41537_10_sportivecasual_W.jpg, W_46905_80_powersuit_W.jpg, W_46562_80_powersuit_W.jpg, W_20551_70_hippie_W.jpg, W_40817_70_military_W.jpg, W_34872_70_military_W.jpg, W_22856_60_minimal_W.jpg]  \n",
              "55                                                                                                                                                                     [W_47169_70_hippie_W.jpg, W_14102_50_feminine_W.jpg, W_02498_50_feminine_W.jpg]  \n",
              "56                                                                                                                                                                                                       [T_06076_60_mods_M.jpg, W_51757_50_ivy_M.jpg]  \n",
              "57                                                                                                                   [W_14380_90_hiphop_W.jpg, W_00344_90_grunge_W.jpg, W_08112_90_hiphop_W.jpg, W_18658_80_powersuit_W.jpg, W_13271_60_minimal_W.jpg]  \n",
              "58                                                                                                                 [W_11868_90_grunge_W.jpg, W_13238_80_powersuit_W.jpg, W_00148_60_popart_W.jpg, W_18730_50_feminine_W.jpg, W_06318_50_classic_W.jpg]  \n",
              "59                                                                                                                             [W_09860_10_sportivecasual_M.jpg, W_22928_10_sportivecasual_M.jpg, W_24917_80_bold_M.jpg, W_55201_00_metrosexual_M.jpg]  \n",
              "60                                                                                                                                                                         [W_50293_19_normcore_W.jpg, W_43573_90_hiphop_W.jpg, W_42046_70_punk_W.jpg]  \n",
              "61                                                                                                                                                                         [W_16695_19_normcore_M.jpg, W_12345_80_bold_M.jpg, W_16014_70_hippie_M.jpg]  \n",
              "62                                   [W_02966_10_sportivecasual_M.jpg, W_24995_10_sportivecasual_M.jpg, W_04363_10_sportivecasual_M.jpg, W_07364_00_metrosexual_M.jpg, W_24403_00_metrosexual_M.jpg, W_32257_90_hiphop_M.jpg, W_12504_90_hiphop_M.jpg]  \n",
              "63                                                                                                                  [W_17108_19_normcore_M.jpg, W_06691_10_sportivecasual_M.jpg, W_15517_70_hippie_M.jpg, W_15140_80_bold_M.jpg, W_12904_50_ivy_M.jpg]  \n",
              "64                                                                                                                                                                                                                                                  []  \n",
              "65                                                       [W_00191_10_sportivecasual_W.jpg, W_08047_90_hiphop_W.jpg, W_13399_90_kitsch_W.jpg, W_05957_70_disco_W.jpg, W_14310_80_powersuit_W.jpg, W_01956_50_feminine_W.jpg, W_01187_50_feminine_W.jpg]  \n",
              "66                                                                                                                                                  [W_15974_80_bold_M.jpg, W_16380_80_bold_M.jpg, W_04273_00_metrosexual_M.jpg, W_10779_50_ivy_M.jpg]  \n",
              "67                                                                                                 [W_01687_19_normcore_M.jpg, W_15815_70_hippie_M.jpg, W_24958_90_hiphop_M.jpg, W_07324_50_ivy_M.jpg, W_02736_60_mods_M.jpg, W_02715_70_hippie_M.jpg]  \n",
              "68                                                                                                                                                                        [W_24903_80_bold_M.jpg, W_26093_00_metrosexual_M.jpg, W_26631_80_bold_M.jpg]  \n",
              "69                                                                                                                                                     [W_02777_90_hiphop_M.jpg, W_15568_70_hippie_M.jpg, W_12459_50_ivy_M.jpg, W_15157_60_mods_M.jpg]  \n",
              "70                                                                                                                                                                       [W_12593_00_metrosexual_M.jpg, W_15795_70_hippie_M.jpg, W_06537_50_ivy_M.jpg]  \n",
              "71                                                                                    [W_17728_10_sportivecasual_M.jpg, W_12658_00_metrosexual_M.jpg, W_17252_50_ivy_M.jpg, W_15119_00_metrosexual_M.jpg, W_16962_60_mods_M.jpg, W_10075_50_ivy_M.jpg]  \n",
              "72                                                                                                                   [W_10791_19_normcore_M.jpg, W_16203_90_hiphop_M.jpg, W_15596_70_hippie_M.jpg, W_15388_00_metrosexual_M.jpg, W_06735_50_ivy_M.jpg]  \n",
              "73                                                                                                                                                   [W_16367_90_hiphop_M.jpg, W_00803_50_ivy_M.jpg, W_06686_70_hippie_M.jpg, W_11024_70_hippie_M.jpg]  \n",
              "74                                                                                                                                                                    [W_13958_00_cityglam_W.jpg, W_03529_90_grunge_W.jpg, W_06147_80_powersuit_W.jpg]  \n",
              "75                                                                                                                                                                                                                   [W_00754_10_sportivecasual_W.jpg]  \n",
              "76                                                                                                                                                               [W_18943_80_powersuit_W.jpg, W_11938_70_hippie_W.jpg, W_01955_80_bodyconscious_W.jpg]  \n",
              "77                                                                                        [W_17812_10_sportivecasual_M.jpg, W_10851_19_normcore_M.jpg, W_16930_19_normcore_M.jpg, W_15987_70_hippie_M.jpg, W_12807_50_ivy_M.jpg, W_16189_50_ivy_M.jpg]  \n",
              "78                                                                                                                                           [W_18618_80_powersuit_W.jpg, W_02282_70_hippie_W.jpg, W_08501_70_hippie_W.jpg, W_14852_50_feminine_W.jpg]  \n",
              "79                                                                                                                                                                         [W_16460_19_normcore_M.jpg, W_16039_70_hippie_M.jpg, W_12336_80_bold_M.jpg]  \n",
              "80                                                                                                                                              [W_19492_00_ecology_W.jpg, W_18797_70_disco_W.jpg, W_19750_70_hippie_W.jpg, W_18508_50_feminine_W.jpg]  \n",
              "81                                                                                                   [W_18335_00_oriental_W.jpg, W_14378_10_sportivecasual_W.jpg, W_11421_00_ecology_W.jpg, W_14221_80_bodyconscious_W.jpg, W_02047_50_feminine_W.jpg]  \n",
              "82                                                                                                                                                                   [W_27174_10_sportivecasual_M.jpg, W_16291_80_bold_M.jpg, W_15762_70_hippie_M.jpg]  \n",
              "83                                                                                                                                                 [W_32608_70_hippie_M.jpg, W_04510_00_metrosexual_M.jpg, W_30290_50_ivy_M.jpg, W_24101_50_ivy_M.jpg]  \n",
              "84                                                                                                                                                [W_21401_00_metrosexual_M.jpg, W_24357_70_hippie_M.jpg, W_33002_60_mods_M.jpg, W_32459_50_ivy_M.jpg]  \n",
              "85                                                                                                                                         [W_15920_00_metrosexual_M.jpg, W_24347_00_metrosexual_M.jpg, W_25202_90_hiphop_M.jpg, W_27903_50_ivy_M.jpg]  \n",
              "86                                                                                                                                                                                                                           [W_25721_90_hiphop_M.jpg]  \n",
              "87                                                                                                                                       [T_11421_00_cityglam_W.jpg, W_55996_90_lingerie_W.jpg, T_07471_80_bodyconscious_W.jpg, W_33100_70_punk_W.jpg]  \n",
              "88                                                                                                                                                        [W_15438_70_hippie_M.jpg, W_04677_50_ivy_M.jpg, W_12866_60_mods_M.jpg, W_10082_50_ivy_M.jpg]  \n",
              "89                                                                                                       [W_07025_10_sportivecasual_M.jpg, W_28443_10_sportivecasual_M.jpg, W_24557_19_normcore_M.jpg, W_06805_90_hiphop_M.jpg, W_24142_60_mods_M.jpg]  \n",
              "90                                                                                                                                                                                 [W_12309_80_bold_M.jpg, W_09835_50_ivy_M.jpg, W_15479_50_ivy_M.jpg]  \n",
              "91                                                                                                                                                                  [W_25106_00_metrosexual_M.jpg, W_26001_00_metrosexual_M.jpg, W_04302_50_ivy_M.jpg]  \n",
              "92                                                                                                                                   [W_63956_80_powersuit_W.jpg, W_13086_80_powersuit_W.jpg, W_13952_80_bodyconscious_W.jpg, W_34247_70_hippie_W.jpg]  \n",
              "93                                                                                                                                                                                                                    [W_08246_80_bodyconscious_W.jpg]  \n",
              "94                                                                                                                                                                                            [W_05586_80_bodyconscious_W.jpg, W_14299_70_disco_W.jpg]  \n",
              "95                                                                                                                                                                                                        [W_10796_50_ivy_M.jpg, W_15404_50_ivy_M.jpg]  \n",
              "96                                                                                                                                                                    [W_25941_10_sportivecasual_M.jpg, W_15586_70_hippie_M.jpg, W_26584_50_ivy_M.jpg]  \n",
              "97                                                                                                                                                                        [W_05818_90_lingerie_W.jpg, W_44650_90_kitsch_W.jpg, W_42705_70_disco_W.jpg]  \n",
              "98                                                                                                                                                                                                                           [W_15503_70_hippie_M.jpg]  \n",
              "99                                                                                                                                                                              [W_06617_90_hiphop_M.jpg, W_15124_80_bold_M.jpg, W_06511_50_ivy_M.jpg]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dbb2f5b9-9800-4d0c-aaf2-b150dd13505d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>응답자 ID</th>\n",
              "      <th>Training 스타일 선호</th>\n",
              "      <th>Training 스타일 비선호</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21432</td>\n",
              "      <td>[W_28523_90_hiphop_M.jpg, W_09891_90_hiphop_M.jpg, W_29023_00_metrosexual_M.jpg, W_15294_50_ivy_M.jpg, W_32448_50_ivy_M.jpg]</td>\n",
              "      <td>[W_29224_10_sportivecasual_M.jpg, W_26017_10_sportivecasual_M.jpg, W_26151_80_bold_M.jpg, W_26296_70_hippie_M.jpg, W_12383_80_bold_M.jpg, W_24439_00_metrosexual_M.jpg, W_26397_70_hippie_M.jpg, W_25107_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60234</td>\n",
              "      <td>[W_01693_19_normcore_M.jpg, W_17337_50_ivy_M.jpg, W_16539_50_ivy_M.jpg, W_07102_50_ivy_M.jpg, W_12748_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17508_80_bold_M.jpg, W_02844_90_hiphop_M.jpg, W_16755_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_16673_70_hippie_M.jpg, W_15423_80_bold_M.jpg, W_06546_60_mods_M.jpg, W_15259_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62264</td>\n",
              "      <td>[W_07260_10_sportivecasual_M.jpg, W_16449_10_sportivecasual_M.jpg, W_16403_10_sportivecasual_M.jpg, W_07098_19_normcore_M.jpg, W_07307_19_normcore_M.jpg, W_05869_60_mods_M.jpg]</td>\n",
              "      <td>[W_16136_80_bold_M.jpg, W_15477_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_16428_90_hiphop_M.jpg, W_16189_50_ivy_M.jpg, W_16189_50_ivy_M.jpg, W_04233_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64345</td>\n",
              "      <td>[W_28449_10_sportivecasual_M.jpg, W_17467_19_normcore_M.jpg, W_00843_10_sportivecasual_M.jpg, W_29596_10_sportivecasual_M.jpg, W_27156_90_hiphop_M.jpg, W_32150_00_metrosexual_M.jpg, W_15856_60_mods_M.jpg, W_24155_60_mods_M.jpg]</td>\n",
              "      <td>[W_24825_80_bold_M.jpg, W_25884_90_hiphop_M.jpg, W_11105_00_metrosexual_M.jpg, W_24352_70_hippie_M.jpg, W_24325_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63740</td>\n",
              "      <td>[W_04201_19_lounge_W.jpg, W_01179_10_sportivecasual_W.jpg, W_11824_70_military_W.jpg, W_14975_60_minimal_W.jpg, W_18894_50_feminine_W.jpg]</td>\n",
              "      <td>[W_05226_10_sportivecasual_W.jpg, W_08607_90_kitsch_W.jpg, W_19264_90_kitsch_W.jpg, W_03656_90_hiphop_W.jpg, W_05353_80_bodyconscious_W.jpg, W_06083_80_bodyconscious_W.jpg, W_07532_70_hippie_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>64221</td>\n",
              "      <td>[W_28698_10_sportivecasual_M.jpg, W_25039_90_hiphop_M.jpg, W_32524_00_metrosexual_M.jpg, W_28728_50_ivy_M.jpg, W_24013_60_mods_M.jpg]</td>\n",
              "      <td>[W_26397_70_hippie_M.jpg, W_25471_70_hippie_M.jpg, W_12130_80_bold_M.jpg, W_28207_90_hiphop_M.jpg, W_17747_80_bold_M.jpg, W_15129_50_ivy_M.jpg, W_07333_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>64460</td>\n",
              "      <td>[W_24294_80_bold_M.jpg, W_24934_90_hiphop_M.jpg, W_26530_00_metrosexual_M.jpg, W_06514_80_bold_M.jpg, W_10792_50_ivy_M.jpg, W_12817_50_ivy_M.jpg, W_15653_60_mods_M.jpg]</td>\n",
              "      <td>[W_25069_90_hiphop_M.jpg, W_31356_80_bold_M.jpg, W_25082_70_hippie_M.jpg, W_30522_00_metrosexual_M.jpg, W_25526_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>28912</td>\n",
              "      <td>[W_01754_10_sportivecasual_M.jpg, W_04680_10_sportivecasual_M.jpg, W_02669_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17260_19_normcore_M.jpg, W_16725_70_hippie_M.jpg, W_15745_80_bold_M.jpg, W_04723_90_hiphop_M.jpg, W_15923_80_bold_M.jpg, W_04242_60_mods_M.jpg, W_15246_50_ivy_M.jpg, W_03007_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>60184</td>\n",
              "      <td>[W_01687_19_normcore_M.jpg, W_17427_00_metrosexual_M.jpg, W_17348_50_ivy_M.jpg]</td>\n",
              "      <td>[W_12453_10_sportivecasual_M.jpg, W_12095_80_bold_M.jpg, W_28377_80_bold_M.jpg, W_27913_00_metrosexual_M.jpg, W_25030_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_16016_70_hippie_M.jpg, W_04245_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>62525</td>\n",
              "      <td>[W_00760_19_normcore_W.jpg, W_05751_10_sportivecasual_W.jpg, W_19165_00_cityglam_W.jpg, W_03477_80_powersuit_W.jpg, W_01207_60_minimal_W.jpg, W_11223_60_popart_W.jpg, W_13104_50_classic_W.jpg, W_18495_50_feminine_W.jpg]</td>\n",
              "      <td>[W_13667_00_oriental_W.jpg, W_08167_60_minimal_W.jpg, W_07447_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>63545</td>\n",
              "      <td>[W_08322_19_normcore_W.jpg, W_14897_10_sportivecasual_W.jpg, W_04993_70_hippie_W.jpg, W_03842_50_feminine_W.jpg]</td>\n",
              "      <td>[W_04035_19_normcore_W.jpg, W_08610_90_grunge_W.jpg, W_19342_70_hippie_W.jpg, W_10655_50_feminine_W.jpg, W_12003_60_minimal_W.jpg, W_13846_60_minimal_W.jpg, W_10981_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>63583</td>\n",
              "      <td>[W_02100_00_oriental_W.jpg, W_00385_50_feminine_W.jpg]</td>\n",
              "      <td>[W_10223_00_oriental_W.jpg, W_18920_00_oriental_W.jpg, W_03693_10_athleisure_W.jpg, W_01248_90_hiphop_W.jpg, W_18030_90_kitsch_W.jpg, W_19311_70_punk_W.jpg, W_19964_80_powersuit_W.jpg, W_18543_60_popart_W.jpg, W_04901_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>63934</td>\n",
              "      <td>[W_16255_19_normcore_M.jpg, W_12327_80_bold_M.jpg]</td>\n",
              "      <td>[W_01630_10_sportivecasual_M.jpg, W_10791_19_normcore_M.jpg, W_16236_80_bold_M.jpg, W_11063_00_metrosexual_M.jpg, W_02755_90_hiphop_M.jpg, W_01794_00_metrosexual_M.jpg, W_15669_00_metrosexual_M.jpg, W_17603_50_ivy_M.jpg, W_06259_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>66592</td>\n",
              "      <td>[W_46907_80_powersuit_W.jpg, W_53583_90_hiphop_W.jpg, W_53861_90_kitsch_W.jpg, W_53133_90_hiphop_W.jpg, W_44918_60_minimal_W.jpg, W_02343_60_space_W.jpg]</td>\n",
              "      <td>[W_52969_00_ecology_W.jpg, W_51690_80_powersuit_W.jpg, W_52731_90_kitsch_W.jpg, W_41924_70_punk_W.jpg, W_47960_60_popart_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>60173</td>\n",
              "      <td>[W_14216_10_sportivecasual_W.jpg, W_08869_10_sportivecasual_W.jpg, W_05458_10_athleisure_W.jpg, W_07964_70_military_W.jpg, W_14099_50_classic_W.jpg, W_09079_60_popart_W.jpg]</td>\n",
              "      <td>[W_19273_00_ecology_W.jpg, W_07408_90_lingerie_W.jpg, W_06402_80_powersuit_W.jpg, W_09497_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>63207</td>\n",
              "      <td>[W_02771_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_00505_10_sportivecasual_M.jpg, W_16390_10_sportivecasual_M.jpg, W_11033_90_hiphop_M.jpg, W_15634_80_bold_M.jpg, W_16684_00_metrosexual_M.jpg, W_16361_80_bold_M.jpg, W_09796_60_mods_M.jpg, W_10087_70_hippie_M.jpg, W_09132_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>63359</td>\n",
              "      <td>[W_00410_19_genderless_W.jpg, W_01958_00_cityglam_W.jpg, W_08140_50_feminine_W.jpg]</td>\n",
              "      <td>[W_10207_00_oriental_W.jpg, W_10289_00_oriental_W.jpg, W_13858_80_bodyconscious_W.jpg, W_13941_60_minimal_W.jpg, W_12019_50_feminine_W.jpg, W_19530_60_popart_W.jpg, W_07682_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>63508</td>\n",
              "      <td>[W_15768_19_normcore_M.jpg, W_15156_00_metrosexual_M.jpg, W_12698_80_bold_M.jpg, W_16295_70_hippie_M.jpg, W_15488_00_metrosexual_M.jpg]</td>\n",
              "      <td>[W_07043_10_sportivecasual_M.jpg, W_13458_80_bold_M.jpg, W_11071_00_metrosexual_M.jpg, W_16180_50_ivy_M.jpg, W_10817_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>63571</td>\n",
              "      <td>[W_04649_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_00815_19_normcore_M.jpg, W_07001_19_normcore_M.jpg, W_02855_10_sportivecasual_M.jpg, W_17207_00_metrosexual_M.jpg, W_15623_70_hippie_M.jpg, W_15270_60_mods_M.jpg, W_00492_50_ivy_M.jpg, W_02740_50_ivy_M.jpg, W_15093_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>63769</td>\n",
              "      <td>[W_09795_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_07373_19_normcore_M.jpg, W_17262_19_normcore_M.jpg, W_17688_19_normcore_M.jpg, W_11011_80_bold_M.jpg, W_12408_90_hiphop_M.jpg, W_16806_00_metrosexual_M.jpg, W_04632_90_hiphop_M.jpg, W_07123_70_hippie_M.jpg, W_10122_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>63913</td>\n",
              "      <td>[W_00553_10_sportivecasual_M.jpg, W_07066_10_sportivecasual_M.jpg, W_07255_50_ivy_M.jpg, W_07150_70_hippie_M.jpg, W_06573_60_mods_M.jpg, W_06883_60_mods_M.jpg]</td>\n",
              "      <td>[W_17009_19_normcore_M.jpg, W_16444_10_sportivecasual_M.jpg, W_15843_00_metrosexual_M.jpg, W_10066_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>63927</td>\n",
              "      <td>[W_06824_19_normcore_M.jpg, W_06531_60_mods_M.jpg]</td>\n",
              "      <td>[W_16412_10_sportivecasual_M.jpg, W_12650_90_hiphop_M.jpg, W_11143_00_metrosexual_M.jpg, W_15276_00_metrosexual_M.jpg, W_17443_90_hiphop_M.jpg, W_15651_70_hippie_M.jpg, W_17779_80_bold_M.jpg, W_15080_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>64216</td>\n",
              "      <td>[W_27674_10_sportivecasual_M.jpg, W_17855_90_hiphop_M.jpg, W_02816_60_mods_M.jpg]</td>\n",
              "      <td>[W_31918_19_normcore_M.jpg, W_25452_19_normcore_M.jpg, W_32426_70_hippie_M.jpg, W_15666_90_hiphop_M.jpg, W_26288_70_hippie_M.jpg, W_24486_70_hippie_M.jpg, W_24931_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>64571</td>\n",
              "      <td>[W_00794_19_normcore_M.jpg]</td>\n",
              "      <td>[W_29383_10_sportivecasual_M.jpg, W_31502_19_normcore_M.jpg, W_32860_80_bold_M.jpg, W_16985_70_hippie_M.jpg, W_11145_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_24059_50_ivy_M.jpg, W_25406_00_metrosexual_M.jpg, W_24180_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>64598</td>\n",
              "      <td>[W_48074_10_sportivecasual_W.jpg, W_21732_10_sportivecasual_W.jpg, W_27930_80_powersuit_W.jpg, W_00638_90_hiphop_W.jpg, W_04895_50_classic_W.jpg, W_09961_50_feminine_W.jpg]</td>\n",
              "      <td>[W_11262_00_oriental_W.jpg, W_31881_80_powersuit_W.jpg, W_27619_80_powersuit_W.jpg, W_02442_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>68891</td>\n",
              "      <td>[T_15458_10_sportivecasual_M.jpg, T_15453_10_sportivecasual_M.jpg, T_15468_10_sportivecasual_M.jpg, T_15477_10_sportivecasual_M.jpg, T_15488_10_sportivecasual_M.jpg, T_15467_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[T_15462_10_sportivecasual_M.jpg, T_15443_10_sportivecasual_M.jpg, T_15441_10_sportivecasual_M.jpg, T_09788_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>837</td>\n",
              "      <td>[W_00829_10_sportivecasual_M.jpg, W_28209_10_sportivecasual_M.jpg, W_28211_19_normcore_M.jpg, W_28722_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg, W_25073_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_07130_19_normcore_M.jpg, W_24845_80_bold_M.jpg, W_16659_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>30790</td>\n",
              "      <td>[W_33023_10_sportivecasual_M.jpg, W_26425_90_hiphop_M.jpg, W_06511_50_ivy_M.jpg, W_06863_60_mods_M.jpg]</td>\n",
              "      <td>[W_26359_19_normcore_M.jpg, W_25835_10_sportivecasual_M.jpg, W_29485_10_sportivecasual_M.jpg, W_24886_70_hippie_M.jpg, W_24769_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>35514</td>\n",
              "      <td>[W_01716_19_normcore_M.jpg, W_04539_10_sportivecasual_M.jpg, W_01645_90_hiphop_M.jpg, W_01664_60_mods_M.jpg, W_09152_60_mods_M.jpg]</td>\n",
              "      <td>[W_12634_10_sportivecasual_M.jpg, W_04406_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_10814_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>61104</td>\n",
              "      <td>[W_07906_00_ecology_W.jpg, W_08810_10_sportivecasual_W.jpg, W_04919_00_oriental_W.jpg, W_02487_10_athleisure_W.jpg]</td>\n",
              "      <td>[W_19430_00_oriental_W.jpg, W_07717_90_kitsch_W.jpg, W_14147_70_disco_W.jpg, W_08511_80_bodyconscious_W.jpg, W_08670_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>62155</td>\n",
              "      <td>[W_31063_19_normcore_M.jpg, W_27854_50_ivy_M.jpg]</td>\n",
              "      <td>[W_32383_00_metrosexual_M.jpg, W_15666_90_hiphop_M.jpg, W_24569_70_hippie_M.jpg, W_12265_00_metrosexual_M.jpg, W_24492_70_hippie_M.jpg, W_17353_50_ivy_M.jpg, W_01726_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>62349</td>\n",
              "      <td>[W_04689_10_sportivecasual_M.jpg, W_17802_80_bold_M.jpg, W_07101_60_mods_M.jpg]</td>\n",
              "      <td>[W_06253_90_hiphop_M.jpg, W_16681_70_hippie_M.jpg, W_07095_00_metrosexual_M.jpg, W_12552_80_bold_M.jpg, W_15125_50_ivy_M.jpg, W_17353_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>63156</td>\n",
              "      <td>[W_01318_10_athleisure_W.jpg]</td>\n",
              "      <td>[W_09007_19_normcore_W.jpg, W_11504_19_lounge_W.jpg, W_01166_10_sportivecasual_W.jpg, W_19061_90_kitsch_W.jpg, W_08180_80_bodyconscious_W.jpg, W_19838_60_popart_W.jpg, W_14259_50_feminine_W.jpg, W_18729_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>63369</td>\n",
              "      <td>[W_03000_19_normcore_M.jpg, W_09785_19_normcore_M.jpg, W_01428_10_sportivecasual_M.jpg, W_04733_90_hiphop_M.jpg, W_09760_60_mods_M.jpg]</td>\n",
              "      <td>[W_12487_90_hiphop_M.jpg, W_01509_00_metrosexual_M.jpg, W_15884_80_bold_M.jpg, W_06563_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>63424</td>\n",
              "      <td>[W_19801_19_genderless_W.jpg, W_09698_19_genderless_W.jpg, W_01962_60_minimal_W.jpg]</td>\n",
              "      <td>[W_07715_19_normcore_W.jpg, W_05652_10_athleisure_W.jpg, W_03717_10_athleisure_W.jpg, W_07675_80_bodyconscious_W.jpg, W_19301_50_feminine_W.jpg, W_14997_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>63435</td>\n",
              "      <td>[W_08285_19_normcore_W.jpg, W_19407_19_normcore_W.jpg, W_01041_10_sportivecasual_W.jpg, W_19010_00_oriental_W.jpg, W_18401_90_lingerie_W.jpg, W_04192_60_minimal_W.jpg]</td>\n",
              "      <td>[W_08838_10_athleisure_W.jpg, W_03787_80_bodyconscious_W.jpg, W_14345_60_space_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>63748</td>\n",
              "      <td>[W_02890_19_normcore_M.jpg, W_00829_10_sportivecasual_M.jpg, W_15268_50_ivy_M.jpg, W_10092_60_mods_M.jpg, W_17867_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15116_00_metrosexual_M.jpg, W_04484_90_hiphop_M.jpg, W_11144_00_metrosexual_M.jpg, W_10079_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>64310</td>\n",
              "      <td>[W_26375_70_hippie_M.jpg, W_16007_70_hippie_M.jpg, W_25934_90_hiphop_M.jpg, W_04692_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_28801_19_normcore_M.jpg, W_28741_19_normcore_M.jpg, W_01799_00_metrosexual_M.jpg, W_16259_80_bold_M.jpg, W_32131_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>64397</td>\n",
              "      <td>[W_17793_19_normcore_M.jpg, W_24889_50_ivy_M.jpg]</td>\n",
              "      <td>[W_31360_19_normcore_M.jpg, W_30015_00_metrosexual_M.jpg, W_29830_90_hiphop_M.jpg, W_28319_90_hiphop_M.jpg, W_11080_00_metrosexual_M.jpg, W_06665_00_metrosexual_M.jpg, W_24348_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>64503</td>\n",
              "      <td>[W_43214_19_genderless_W.jpg, W_45353_80_powersuit_W.jpg, W_40718_90_hiphop_W.jpg, W_43570_90_hiphop_W.jpg, W_36275_60_minimal_W.jpg, W_07755_50_feminine_W.jpg]</td>\n",
              "      <td>[W_34027_10_sportivecasual_W.jpg, W_42376_90_grunge_W.jpg, W_30932_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>65139</td>\n",
              "      <td>[W_64254_19_normcore_M.jpg, W_16523_19_normcore_M.jpg]</td>\n",
              "      <td>[W_26315_19_normcore_M.jpg, W_01898_19_normcore_M.jpg, W_57822_90_hiphop_M.jpg, W_52693_00_metrosexual_M.jpg, W_16063_80_bold_M.jpg, W_62525_90_hiphop_M.jpg, W_66114_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>66513</td>\n",
              "      <td>[W_60789_90_lingerie_W.jpg, W_44554_90_grunge_W.jpg, W_35544_60_minimal_W.jpg, W_19031_50_classic_W.jpg]</td>\n",
              "      <td>[W_56334_10_sportivecasual_W.jpg, W_68199_10_sportivecasual_W.jpg, W_34173_19_normcore_W.jpg, W_38863_60_minimal_W.jpg, W_37404_60_space_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>9096</td>\n",
              "      <td>[W_03582_19_normcore_W.jpg, W_03784_00_cityglam_W.jpg, W_08797_70_disco_W.jpg, W_14507_60_minimal_W.jpg, W_03160_60_minimal_W.jpg, W_19987_50_feminine_W.jpg]</td>\n",
              "      <td>[W_03461_19_normcore_W.jpg, W_12033_00_cityglam_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>22324</td>\n",
              "      <td>[W_04372_10_sportivecasual_M.jpg, W_07347_90_hiphop_M.jpg, W_17700_00_metrosexual_M.jpg, W_02696_60_mods_M.jpg]</td>\n",
              "      <td>[W_15443_70_hippie_M.jpg, W_15091_80_bold_M.jpg, W_15511_00_metrosexual_M.jpg, W_17893_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>59083</td>\n",
              "      <td>[W_09799_19_normcore_M.jpg, W_06836_00_metrosexual_M.jpg, W_06547_00_metrosexual_M.jpg, W_10803_80_bold_M.jpg, W_15367_60_mods_M.jpg]</td>\n",
              "      <td>[W_16435_10_sportivecasual_M.jpg, W_18545_19_normcore_M.jpg, W_12593_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>59523</td>\n",
              "      <td>[W_09060_19_normcore_W.jpg, W_05673_10_sportivecasual_W.jpg, W_09533_90_grunge_W.jpg, W_05690_70_punk_W.jpg, W_18661_60_minimal_W.jpg]</td>\n",
              "      <td>[W_08092_90_hiphop_W.jpg, W_05246_80_bodyconscious_W.jpg, W_19742_60_popart_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>59637</td>\n",
              "      <td>[W_00784_19_normcore_W.jpg, W_08042_10_athleisure_W.jpg, W_09626_10_athleisure_W.jpg, W_03580_60_minimal_W.jpg]</td>\n",
              "      <td>[W_18644_19_genderless_W.jpg, W_14410_19_genderless_W.jpg, W_03430_90_lingerie_W.jpg, W_18462_90_kitsch_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>59704</td>\n",
              "      <td>[W_07211_00_metrosexual_M.jpg, W_04636_50_ivy_M.jpg, W_06558_60_mods_M.jpg]</td>\n",
              "      <td>[W_11141_19_normcore_M.jpg, W_04573_10_sportivecasual_M.jpg, W_12476_90_hiphop_M.jpg, W_16676_90_hiphop_M.jpg, W_15120_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>59812</td>\n",
              "      <td>[W_06672_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17916_10_sportivecasual_M.jpg, W_11085_19_normcore_M.jpg, W_03044_19_normcore_M.jpg, W_12564_00_metrosexual_M.jpg, W_06759_90_hiphop_M.jpg, W_12120_80_bold_M.jpg, W_05879_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>63316</td>\n",
              "      <td>[W_06484_19_lounge_W.jpg, W_05594_19_genderless_W.jpg, W_05580_10_sportivecasual_W.jpg, W_07586_60_minimal_W.jpg]</td>\n",
              "      <td>[W_11796_19_genderless_W.jpg, W_19165_00_cityglam_W.jpg, W_11950_00_oriental_W.jpg, W_19177_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>63479</td>\n",
              "      <td>[W_09086_19_normcore_W.jpg, W_19413_00_oriental_W.jpg, W_14584_50_classic_W.jpg, W_18202_60_minimal_W.jpg, W_04994_60_popart_W.jpg]</td>\n",
              "      <td>[W_18878_19_genderless_W.jpg, W_00631_70_disco_W.jpg, W_19921_70_punk_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>63644</td>\n",
              "      <td>[W_05127_90_kitsch_W.jpg, W_03934_70_hippie_W.jpg, W_07688_70_disco_W.jpg, W_14787_60_minimal_W.jpg]</td>\n",
              "      <td>[W_05472_10_sportivecasual_W.jpg, W_01326_10_sportivecasual_W.jpg, W_01390_10_sportivecasual_W.jpg, W_14273_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>63759</td>\n",
              "      <td>[W_05821_90_kitsch_W.jpg, W_09611_10_sportivecasual_W.jpg, W_05715_70_military_W.jpg]</td>\n",
              "      <td>[W_18199_19_normcore_W.jpg, W_01334_19_normcore_W.jpg, W_03258_00_ecology_W.jpg, W_04031_80_bodyconscious_W.jpg, W_18549_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>64561</td>\n",
              "      <td>[W_36907_19_genderless_W.jpg, W_18759_50_feminine_W.jpg, W_18066_50_classic_W.jpg]</td>\n",
              "      <td>[W_26946_19_lounge_W.jpg, W_41279_19_genderless_W.jpg, W_32248_80_powersuit_W.jpg, W_02232_70_hippie_W.jpg, W_33622_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>64662</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_22067_19_normcore_W.jpg, W_41537_10_sportivecasual_W.jpg, W_46905_80_powersuit_W.jpg, W_46562_80_powersuit_W.jpg, W_20551_70_hippie_W.jpg, W_40817_70_military_W.jpg, W_34872_70_military_W.jpg, W_22856_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>64747</td>\n",
              "      <td>[W_39725_19_normcore_W.jpg, W_29783_10_sportivecasual_W.jpg, W_34636_00_oriental_W.jpg, W_04972_90_kitsch_W.jpg, W_21223_80_powersuit_W.jpg]</td>\n",
              "      <td>[W_47169_70_hippie_W.jpg, W_14102_50_feminine_W.jpg, W_02498_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>66469</td>\n",
              "      <td>[T_00456_10_sportivecasual_M.jpg, T_03772_90_hiphop_M.jpg, W_06657_60_mods_M.jpg, W_00486_60_mods_M.jpg, W_10810_60_mods_M.jpg, W_51362_50_ivy_M.jpg]</td>\n",
              "      <td>[T_06076_60_mods_M.jpg, W_51757_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>7658</td>\n",
              "      <td>[W_01234_10_sportivecasual_W.jpg, W_08708_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_14380_90_hiphop_W.jpg, W_00344_90_grunge_W.jpg, W_08112_90_hiphop_W.jpg, W_18658_80_powersuit_W.jpg, W_13271_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>20768</td>\n",
              "      <td>[W_09011_10_sportivecasual_W.jpg, W_18900_50_classic_W.jpg]</td>\n",
              "      <td>[W_11868_90_grunge_W.jpg, W_13238_80_powersuit_W.jpg, W_00148_60_popart_W.jpg, W_18730_50_feminine_W.jpg, W_06318_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>28371</td>\n",
              "      <td>[W_17461_19_normcore_M.jpg, W_57031_90_hiphop_M.jpg, W_25020_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_09860_10_sportivecasual_M.jpg, W_22928_10_sportivecasual_M.jpg, W_24917_80_bold_M.jpg, W_55201_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>61250</td>\n",
              "      <td>[W_62598_19_normcore_W.jpg, W_47873_70_punk_W.jpg, W_01933_50_feminine_W.jpg, W_13173_50_feminine_W.jpg]</td>\n",
              "      <td>[W_50293_19_normcore_W.jpg, W_43573_90_hiphop_W.jpg, W_42046_70_punk_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61493</td>\n",
              "      <td>[W_04661_10_sportivecasual_M.jpg, W_02881_10_sportivecasual_M.jpg, W_02818_60_mods_M.jpg, W_04232_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16695_19_normcore_M.jpg, W_12345_80_bold_M.jpg, W_16014_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>61859</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_02966_10_sportivecasual_M.jpg, W_24995_10_sportivecasual_M.jpg, W_04363_10_sportivecasual_M.jpg, W_07364_00_metrosexual_M.jpg, W_24403_00_metrosexual_M.jpg, W_32257_90_hiphop_M.jpg, W_12504_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63405</td>\n",
              "      <td>[W_04684_90_hiphop_M.jpg, W_15400_60_mods_M.jpg]</td>\n",
              "      <td>[W_17108_19_normcore_M.jpg, W_06691_10_sportivecasual_M.jpg, W_15517_70_hippie_M.jpg, W_15140_80_bold_M.jpg, W_12904_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>63505</td>\n",
              "      <td>[W_11117_19_normcore_M.jpg, W_09186_10_sportivecasual_M.jpg, W_07078_10_sportivecasual_M.jpg, W_12328_80_bold_M.jpg, W_17803_80_bold_M.jpg, W_17907_00_metrosexual_M.jpg, W_12393_50_ivy_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>63742</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_00191_10_sportivecasual_W.jpg, W_08047_90_hiphop_W.jpg, W_13399_90_kitsch_W.jpg, W_05957_70_disco_W.jpg, W_14310_80_powersuit_W.jpg, W_01956_50_feminine_W.jpg, W_01187_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>63910</td>\n",
              "      <td>[W_17529_70_hippie_M.jpg, W_17962_50_ivy_M.jpg, W_00495_60_mods_M.jpg]</td>\n",
              "      <td>[W_15974_80_bold_M.jpg, W_16380_80_bold_M.jpg, W_04273_00_metrosexual_M.jpg, W_10779_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>64223</td>\n",
              "      <td>[W_04537_19_normcore_M.jpg]</td>\n",
              "      <td>[W_01687_19_normcore_M.jpg, W_15815_70_hippie_M.jpg, W_24958_90_hiphop_M.jpg, W_07324_50_ivy_M.jpg, W_02736_60_mods_M.jpg, W_02715_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>64364</td>\n",
              "      <td>[W_01472_19_normcore_M.jpg, W_32885_10_sportivecasual_M.jpg, W_16850_19_normcore_M.jpg, W_24141_50_ivy_M.jpg]</td>\n",
              "      <td>[W_24903_80_bold_M.jpg, W_26093_00_metrosexual_M.jpg, W_26631_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>368</td>\n",
              "      <td>[W_02804_19_normcore_M.jpg, W_06843_60_mods_M.jpg]</td>\n",
              "      <td>[W_02777_90_hiphop_M.jpg, W_15568_70_hippie_M.jpg, W_12459_50_ivy_M.jpg, W_15157_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>18730</td>\n",
              "      <td>[W_16362_80_bold_M.jpg, W_12196_80_bold_M.jpg, W_06847_60_mods_M.jpg]</td>\n",
              "      <td>[W_12593_00_metrosexual_M.jpg, W_15795_70_hippie_M.jpg, W_06537_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>28358</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17728_10_sportivecasual_M.jpg, W_12658_00_metrosexual_M.jpg, W_17252_50_ivy_M.jpg, W_15119_00_metrosexual_M.jpg, W_16962_60_mods_M.jpg, W_10075_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>28571</td>\n",
              "      <td>[W_12826_50_ivy_M.jpg]</td>\n",
              "      <td>[W_10791_19_normcore_M.jpg, W_16203_90_hiphop_M.jpg, W_15596_70_hippie_M.jpg, W_15388_00_metrosexual_M.jpg, W_06735_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>50277</td>\n",
              "      <td>[W_09792_10_sportivecasual_M.jpg, W_06909_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16367_90_hiphop_M.jpg, W_00803_50_ivy_M.jpg, W_06686_70_hippie_M.jpg, W_11024_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>59506</td>\n",
              "      <td>[W_02265_70_military_W.jpg, W_11218_50_feminine_W.jpg, W_13247_60_minimal_W.jpg]</td>\n",
              "      <td>[W_13958_00_cityglam_W.jpg, W_03529_90_grunge_W.jpg, W_06147_80_powersuit_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>62113</td>\n",
              "      <td>[W_02567_10_sportivecasual_W.jpg, W_04068_10_athleisure_W.jpg, W_10554_80_bodyconscious_W.jpg, W_08595_80_bodyconscious_W.jpg, W_09639_50_classic_W.jpg]</td>\n",
              "      <td>[W_00754_10_sportivecasual_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>62625</td>\n",
              "      <td>[W_09363_19_genderless_W.jpg, W_05247_90_hiphop_W.jpg, W_07950_70_military_W.jpg]</td>\n",
              "      <td>[W_18943_80_powersuit_W.jpg, W_11938_70_hippie_W.jpg, W_01955_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>62868</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17812_10_sportivecasual_M.jpg, W_10851_19_normcore_M.jpg, W_16930_19_normcore_M.jpg, W_15987_70_hippie_M.jpg, W_12807_50_ivy_M.jpg, W_16189_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>63430</td>\n",
              "      <td>[W_08809_19_lounge_W.jpg, W_00570_90_lingerie_W.jpg]</td>\n",
              "      <td>[W_18618_80_powersuit_W.jpg, W_02282_70_hippie_W.jpg, W_08501_70_hippie_W.jpg, W_14852_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>63481</td>\n",
              "      <td>[W_01480_10_sportivecasual_M.jpg, W_16975_10_sportivecasual_M.jpg, W_05894_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_16460_19_normcore_M.jpg, W_16039_70_hippie_M.jpg, W_12336_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>63526</td>\n",
              "      <td>[W_03388_00_cityglam_W.jpg, W_01993_00_oriental_W.jpg]</td>\n",
              "      <td>[W_19492_00_ecology_W.jpg, W_18797_70_disco_W.jpg, W_19750_70_hippie_W.jpg, W_18508_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>63717</td>\n",
              "      <td>[W_09352_70_military_W.jpg]</td>\n",
              "      <td>[W_18335_00_oriental_W.jpg, W_14378_10_sportivecasual_W.jpg, W_11421_00_ecology_W.jpg, W_14221_80_bodyconscious_W.jpg, W_02047_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>63930</td>\n",
              "      <td>[W_01558_10_sportivecasual_M.jpg, W_09792_10_sportivecasual_M.jpg, W_12196_80_bold_M.jpg]</td>\n",
              "      <td>[W_27174_10_sportivecasual_M.jpg, W_16291_80_bold_M.jpg, W_15762_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>64252</td>\n",
              "      <td>[W_07138_19_normcore_M.jpg, W_24152_60_mods_M.jpg]</td>\n",
              "      <td>[W_32608_70_hippie_M.jpg, W_04510_00_metrosexual_M.jpg, W_30290_50_ivy_M.jpg, W_24101_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>64327</td>\n",
              "      <td>[W_24403_00_metrosexual_M.jpg, W_15095_50_ivy_M.jpg]</td>\n",
              "      <td>[W_21401_00_metrosexual_M.jpg, W_24357_70_hippie_M.jpg, W_33002_60_mods_M.jpg, W_32459_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>64336</td>\n",
              "      <td>[W_06603_90_hiphop_M.jpg, W_00479_60_mods_M.jpg]</td>\n",
              "      <td>[W_15920_00_metrosexual_M.jpg, W_24347_00_metrosexual_M.jpg, W_25202_90_hiphop_M.jpg, W_27903_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>64346</td>\n",
              "      <td>[W_00856_10_sportivecasual_M.jpg, W_16233_80_bold_M.jpg, W_24977_70_hippie_M.jpg, W_30040_60_mods_M.jpg, W_24103_50_ivy_M.jpg]</td>\n",
              "      <td>[W_25721_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>66731</td>\n",
              "      <td>[W_01088_70_military_W.jpg, W_04781_50_feminine_W.jpg]</td>\n",
              "      <td>[T_11421_00_cityglam_W.jpg, W_55996_90_lingerie_W.jpg, T_07471_80_bodyconscious_W.jpg, W_33100_70_punk_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>4035</td>\n",
              "      <td>[W_15186_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15438_70_hippie_M.jpg, W_04677_50_ivy_M.jpg, W_12866_60_mods_M.jpg, W_10082_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>7905</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_07025_10_sportivecasual_M.jpg, W_28443_10_sportivecasual_M.jpg, W_24557_19_normcore_M.jpg, W_06805_90_hiphop_M.jpg, W_24142_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>18129</td>\n",
              "      <td>[W_01424_70_hippie_M.jpg, W_02710_50_ivy_M.jpg]</td>\n",
              "      <td>[W_12309_80_bold_M.jpg, W_09835_50_ivy_M.jpg, W_15479_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>23108</td>\n",
              "      <td>[W_30483_80_bold_M.jpg, W_04601_50_ivy_M.jpg]</td>\n",
              "      <td>[W_25106_00_metrosexual_M.jpg, W_26001_00_metrosexual_M.jpg, W_04302_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>58251</td>\n",
              "      <td>[W_01259_90_lingerie_W.jpg]</td>\n",
              "      <td>[W_63956_80_powersuit_W.jpg, W_13086_80_powersuit_W.jpg, W_13952_80_bodyconscious_W.jpg, W_34247_70_hippie_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>59642</td>\n",
              "      <td>[W_16917_10_athleisure_W.jpg, W_18366_70_disco_W.jpg, W_02444_70_punk_W.jpg, W_02095_60_popart_W.jpg]</td>\n",
              "      <td>[W_08246_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>59857</td>\n",
              "      <td>[W_14888_19_normcore_W.jpg, W_03599_70_punk_W.jpg, W_18546_50_classic_W.jpg]</td>\n",
              "      <td>[W_05586_80_bodyconscious_W.jpg, W_14299_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>59901</td>\n",
              "      <td>[W_04649_10_sportivecasual_M.jpg, W_00017_60_mods_M.jpg, W_12821_50_ivy_M.jpg]</td>\n",
              "      <td>[W_10796_50_ivy_M.jpg, W_15404_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>62653</td>\n",
              "      <td>[W_26093_00_metrosexual_M.jpg, W_02958_60_mods_M.jpg]</td>\n",
              "      <td>[W_25941_10_sportivecasual_M.jpg, W_15586_70_hippie_M.jpg, W_26584_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>62952</td>\n",
              "      <td>[W_38394_19_normcore_W.jpg, W_04928_50_feminine_W.jpg]</td>\n",
              "      <td>[W_05818_90_lingerie_W.jpg, W_44650_90_kitsch_W.jpg, W_42705_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>63255</td>\n",
              "      <td>[W_02846_70_hippie_M.jpg, W_16541_50_ivy_M.jpg, W_10804_50_ivy_M.jpg, W_00036_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15503_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>63391</td>\n",
              "      <td>[W_07215_19_normcore_M.jpg, W_09140_60_mods_M.jpg]</td>\n",
              "      <td>[W_06617_90_hiphop_M.jpg, W_15124_80_bold_M.jpg, W_06511_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dbb2f5b9-9800-4d0c-aaf2-b150dd13505d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dbb2f5b9-9800-4d0c-aaf2-b150dd13505d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dbb2f5b9-9800-4d0c-aaf2-b150dd13505d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0a4bfec1-30d0-430c-9c34-b0d166b7e3dc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a4bfec1-30d0-430c-9c34-b0d166b7e3dc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0a4bfec1-30d0-430c-9c34-b0d166b7e3dc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_a666f14b-61f6-4036-9df5-453add92ca89\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a666f14b-61f6-4036-9df5-453add92ca89 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_df",
              "summary": "{\n  \"name\": \"training_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"\\uc751\\ub2f5\\uc790 ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17863,\n        \"min\": 368,\n        \"max\": 68891,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          64252,\n          64561,\n          18730\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training \\uc2a4\\ud0c0\\uc77c \\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training \\uc2a4\\ud0c0\\uc77c \\ube44\\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation 응답자 스타일 선호 정보:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    응답자 ID  \\\n",
              "0    63405   \n",
              "1    59642   \n",
              "2    63748   \n",
              "3    63913   \n",
              "4    64221   \n",
              "5    62155   \n",
              "6    63479   \n",
              "7    64216   \n",
              "8     7905   \n",
              "9    21432   \n",
              "10   22324   \n",
              "11   60184   \n",
              "12   61104   \n",
              "13   62625   \n",
              "14   63481   \n",
              "15   64295   \n",
              "16    7658   \n",
              "17   12826   \n",
              "18   15251   \n",
              "19   28371   \n",
              "20   28912   \n",
              "21   59523   \n",
              "22   59704   \n",
              "23   59778   \n",
              "24   59812   \n",
              "25   59857   \n",
              "26   60270   \n",
              "27   60510   \n",
              "28   61250   \n",
              "29   62349   \n",
              "30   63156   \n",
              "31   63195   \n",
              "32   63316   \n",
              "33   63392   \n",
              "34   63401   \n",
              "35   63430   \n",
              "36   63435   \n",
              "37   63473   \n",
              "38   63505   \n",
              "39   63545   \n",
              "40   63571   \n",
              "41   63740   \n",
              "42   63910   \n",
              "43   63934   \n",
              "44   63952   \n",
              "45   64252   \n",
              "46   64280   \n",
              "47   64310   \n",
              "48   64460   \n",
              "49   64496   \n",
              "50   64575   \n",
              "51   64747   \n",
              "52   66513   \n",
              "53   66592   \n",
              "54   66842   \n",
              "55   67975   \n",
              "56     837   \n",
              "57    2609   \n",
              "58    4035   \n",
              "59    4817   \n",
              "60    5931   \n",
              "61   10590   \n",
              "62   14276   \n",
              "63   18129   \n",
              "64   18667   \n",
              "65   19125   \n",
              "66   19339   \n",
              "67   19552   \n",
              "68   20768   \n",
              "69   23021   \n",
              "70   23054   \n",
              "71   24912   \n",
              "72   28534   \n",
              "73   28700   \n",
              "74   28828   \n",
              "75   30790   \n",
              "76   35283   \n",
              "77   38363   \n",
              "78   44117   \n",
              "79   50038   \n",
              "80   51939   \n",
              "81   54939   \n",
              "82   58251   \n",
              "83   59083   \n",
              "84   59468   \n",
              "85   59637   \n",
              "86   59843   \n",
              "87   59901   \n",
              "88   60056   \n",
              "89   60071   \n",
              "90   60234   \n",
              "91   60465   \n",
              "92   61145   \n",
              "93   61192   \n",
              "94   61227   \n",
              "95   61460   \n",
              "96   61818   \n",
              "97   61892   \n",
              "98   62125   \n",
              "99   62154   \n",
              "\n",
              "                                                                                               Validation 스타일 선호  \\\n",
              "0                                        [W_02677_60_mods_M.jpg, W_01853_60_mods_M.jpg, W_04684_90_hiphop_M.jpg]   \n",
              "1                                [W_05716_19_normcore_W.jpg, W_14706_19_normcore_W.jpg, W_02095_60_popart_W.jpg]   \n",
              "2                                                        [W_17867_50_ivy_M.jpg, W_00829_10_sportivecasual_M.jpg]   \n",
              "3                                                                                        [W_06883_60_mods_M.jpg]   \n",
              "4                                                     [W_28925_90_hiphop_M.jpg, W_25086_10_sportivecasual_M.jpg]   \n",
              "5                                                                                         [W_27854_50_ivy_M.jpg]   \n",
              "6                                  [W_04994_60_popart_W.jpg, W_06438_00_ecology_W.jpg, W_18202_60_minimal_W.jpg]   \n",
              "7                                                             [W_02816_60_mods_M.jpg, W_15662_19_normcore_M.jpg]   \n",
              "8                                                                                                             []   \n",
              "9                                     [W_06522_50_ivy_M.jpg, W_15294_50_ivy_M.jpg, W_29023_00_metrosexual_M.jpg]   \n",
              "10                                                                             [W_00931_10_sportivecasual_M.jpg]   \n",
              "11                                                                                                            []   \n",
              "12                                                       [W_08839_10_athleisure_W.jpg, W_09085_60_minimal_W.jpg]   \n",
              "13  [W_14785_00_cityglam_W.jpg, W_09363_19_genderless_W.jpg, W_01998_90_lingerie_W.jpg, W_03334_90_kitsch_W.jpg]   \n",
              "14                                                                                                            []   \n",
              "15                                                                                                            []   \n",
              "16                     [W_09731_19_genderless_W.jpg, W_04927_50_feminine_W.jpg, W_01234_10_sportivecasual_W.jpg]   \n",
              "17                                [W_16541_50_ivy_M.jpg, W_15244_80_bold_M.jpg, W_04670_10_sportivecasual_M.jpg]   \n",
              "18                                                              [W_17841_80_bold_M.jpg, W_16732_70_hippie_M.jpg]   \n",
              "19                                                               [W_26393_50_ivy_M.jpg, W_25020_90_hiphop_M.jpg]   \n",
              "20                                                                                       [W_16375_80_bold_M.jpg]   \n",
              "21                                                                                   [W_13251_19_normcore_W.jpg]   \n",
              "22                                                                                        [W_04636_50_ivy_M.jpg]   \n",
              "23                                                               [W_04643_50_ivy_M.jpg, W_04396_90_hiphop_M.jpg]   \n",
              "24                                                                                                            []   \n",
              "25                                                         [W_14888_19_normcore_W.jpg, W_18546_50_classic_W.jpg]   \n",
              "26                                                                                       [W_10844_60_mods_M.jpg]   \n",
              "27                                                          [W_03447_70_military_W.jpg, W_05736_90_kitsch_W.jpg]   \n",
              "28                           [W_28373_80_powersuit_W.jpg, W_44789_80_powersuit_W.jpg, W_01933_50_feminine_W.jpg]   \n",
              "29                                                                                                            []   \n",
              "30                                                                                    [W_14796_60_minimal_W.jpg]   \n",
              "31                                                                                        [W_26200_50_ivy_M.jpg]   \n",
              "32                                                                             [W_05580_10_sportivecasual_W.jpg]   \n",
              "33                                                                  [W_15370_50_ivy_M.jpg, W_06576_50_ivy_M.jpg]   \n",
              "34                                                                                        [W_00492_50_ivy_M.jpg]   \n",
              "35                                                                                   [W_01056_00_cityglam_W.jpg]   \n",
              "36                                                         [W_08285_19_normcore_W.jpg, W_02557_00_ecology_W.jpg]   \n",
              "37                                                                                                            []   \n",
              "38                                                               [W_12393_50_ivy_M.jpg, W_12518_90_hiphop_M.jpg]   \n",
              "39                                                                                   [W_03842_50_feminine_W.jpg]   \n",
              "40                                                                                                            []   \n",
              "41                                                                             [W_01179_10_sportivecasual_W.jpg]   \n",
              "42                                                                             [W_16851_10_sportivecasual_M.jpg]   \n",
              "43                                                                             [W_12897_10_sportivecasual_M.jpg]   \n",
              "44                                                             [W_00073_50_ivy_M.jpg, W_15662_19_normcore_M.jpg]   \n",
              "45                                                                                       [W_24152_60_mods_M.jpg]   \n",
              "46                                       [W_12567_60_mods_M.jpg, W_24628_70_hippie_M.jpg, W_02688_60_mods_M.jpg]   \n",
              "47                                                                                     [W_25934_90_hiphop_M.jpg]   \n",
              "48                                    [W_12817_50_ivy_M.jpg, W_25649_19_normcore_M.jpg, W_16732_70_hippie_M.jpg]   \n",
              "49                                     [W_24647_70_hippie_M.jpg, W_34080_70_hippie_M.jpg, W_30403_60_mods_M.jpg]   \n",
              "50                                                                                       [W_32445_60_mods_M.jpg]   \n",
              "51                                                                                                            []   \n",
              "52                                                                                                            []   \n",
              "53                                                        [W_46907_80_powersuit_W.jpg, W_44918_60_minimal_W.jpg]   \n",
              "54                                                      [W_27765_60_mods_M.jpg, T_06502_10_sportivecasual_M.jpg]   \n",
              "55                                                                                [W_07074_00_metrosexual_M.jpg]   \n",
              "56                                                    [W_00829_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg]   \n",
              "57                                                                                                            []   \n",
              "58                                                                                                            []   \n",
              "59                                                                                   [W_00831_19_normcore_M.jpg]   \n",
              "60                                                                                   [W_13354_50_feminine_W.jpg]   \n",
              "61                                                                                        [W_09156_50_ivy_M.jpg]   \n",
              "62                                                                                       [W_15295_60_mods_M.jpg]   \n",
              "63                                                                                                            []   \n",
              "64                                                                                       [W_29258_80_bold_M.jpg]   \n",
              "65                                                  [W_17413_00_metrosexual_M.jpg, W_12656_00_metrosexual_M.jpg]   \n",
              "66                                                                                                            []   \n",
              "67                                                               [W_07290_50_ivy_M.jpg, W_04268_70_hippie_M.jpg]   \n",
              "68                                                                                                            []   \n",
              "69                                                                                                            []   \n",
              "70                                                                                                            []   \n",
              "71                                                                                                            []   \n",
              "72                                                                                        [W_15294_50_ivy_M.jpg]   \n",
              "73                                                                             [W_06955_10_sportivecasual_M.jpg]   \n",
              "74                                                                                     [W_04245_70_hippie_M.jpg]   \n",
              "75                                                                                                            []   \n",
              "76                                                                                                            []   \n",
              "77                                                                                       [W_27750_60_mods_M.jpg]   \n",
              "78                                                      [T_06739_10_sportivecasual_M.jpg, T_15662_80_bold_M.jpg]   \n",
              "79                                                                                                            []   \n",
              "80                                                                                                            []   \n",
              "81                                                                                       [W_24696_80_bold_M.jpg]   \n",
              "82                                                         [W_19520_50_feminine_W.jpg, W_00716_60_minimal_W.jpg]   \n",
              "83                                               [W_16466_10_sportivecasual_M.jpg, W_06547_00_metrosexual_M.jpg]   \n",
              "84                                                                                                            []   \n",
              "85                                                                                                            []   \n",
              "86                                                                                    [W_44918_60_minimal_W.jpg]   \n",
              "87                                                                                        [W_05868_50_ivy_M.jpg]   \n",
              "88                                                    [W_16624_90_hiphop_M.jpg, W_07271_10_sportivecasual_M.jpg]   \n",
              "89                                                          [W_29942_50_ivy_M.jpg, W_27791_00_metrosexual_M.jpg]   \n",
              "90                                                                                       [W_10107_60_mods_M.jpg]   \n",
              "91                                                                                                            []   \n",
              "92                                                                                                            []   \n",
              "93                                                                             [W_44330_10_sportivecasual_W.jpg]   \n",
              "94                                                                                                            []   \n",
              "95                                                                                     [W_19158_90_kitsch_W.jpg]   \n",
              "96                                                                                       [W_09763_80_bold_M.jpg]   \n",
              "97                                                                                        [W_15248_50_ivy_M.jpg]   \n",
              "98                                                                                                            []   \n",
              "99                                                                                                            []   \n",
              "\n",
              "                                                                                                                       Validation 스타일 비선호  \n",
              "0                                           [W_12904_50_ivy_M.jpg, W_15140_80_bold_M.jpg, W_12304_80_bold_M.jpg, W_07187_70_hippie_M.jpg]  \n",
              "1                                               [W_08246_80_bodyconscious_W.jpg, W_00359_90_grunge_W.jpg, W_11444_80_bodyconscious_W.jpg]  \n",
              "2                 [W_00539_10_sportivecasual_M.jpg, W_10079_60_mods_M.jpg, W_11144_00_metrosexual_M.jpg, W_06955_10_sportivecasual_M.jpg]  \n",
              "3   [W_10066_50_ivy_M.jpg, W_15843_00_metrosexual_M.jpg, W_15947_80_bold_M.jpg, W_16444_10_sportivecasual_M.jpg, W_05876_70_hippie_M.jpg]  \n",
              "4                                 [W_17747_80_bold_M.jpg, W_07333_70_hippie_M.jpg, W_26397_70_hippie_M.jpg, W_02936_00_metrosexual_M.jpg]  \n",
              "5                                  [W_17353_50_ivy_M.jpg, W_32383_00_metrosexual_M.jpg, W_06186_60_mods_M.jpg, W_26120_19_normcore_M.jpg]  \n",
              "6                                                                                [W_18878_19_genderless_W.jpg, W_11936_00_oriental_W.jpg]  \n",
              "7                                                                [W_24931_50_ivy_M.jpg, W_24486_70_hippie_M.jpg, W_26288_70_hippie_M.jpg]  \n",
              "8                               [W_17603_50_ivy_M.jpg, W_28909_19_normcore_M.jpg, W_26179_60_mods_M.jpg, W_07025_10_sportivecasual_M.jpg]  \n",
              "9                                                                                                               [W_26397_70_hippie_M.jpg]  \n",
              "10                                                        [W_04395_80_bold_M.jpg, W_17481_10_sportivecasual_M.jpg, W_16104_60_mods_M.jpg]  \n",
              "11                              [W_12744_50_ivy_M.jpg, W_04245_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_12453_10_sportivecasual_M.jpg]  \n",
              "12                                                                                    [W_14147_70_disco_W.jpg, W_19430_00_oriental_W.jpg]  \n",
              "13                                                                                                                                     []  \n",
              "14                           [W_15184_60_mods_M.jpg, W_17032_10_sportivecasual_M.jpg, W_16460_19_normcore_M.jpg, W_16347_70_hippie_M.jpg]  \n",
              "15                       [W_16374_10_sportivecasual_M.jpg, W_32314_19_normcore_M.jpg, W_31478_19_normcore_M.jpg, W_15729_90_hiphop_M.jpg]  \n",
              "16                                                                                                                                     []  \n",
              "17                                                                                                                                     []  \n",
              "18                                                                                                              [W_10125_70_hippie_M.jpg]  \n",
              "19                                                                                                              [W_27184_90_hiphop_M.jpg]  \n",
              "20                                                                                          [W_00012_50_ivy_M.jpg, W_15745_80_bold_M.jpg]  \n",
              "21                                                                                 [W_19207_19_lounge_W.jpg, W_05665_19_genderless_W.jpg]  \n",
              "22                                                                                       [W_15120_60_mods_M.jpg, W_12476_90_hiphop_M.jpg]  \n",
              "23                                                                                                                [W_15184_60_mods_M.jpg]  \n",
              "24                                                         [W_12564_00_metrosexual_M.jpg, W_15508_60_mods_M.jpg, W_09278_70_hippie_M.jpg]  \n",
              "25                                                                                                               [W_14299_70_disco_W.jpg]  \n",
              "26                                                                                   [W_00117_19_normcore_M.jpg, W_07187_70_hippie_M.jpg]  \n",
              "27                                                                                                            [W_14039_00_cityglam_W.jpg]  \n",
              "28                                                                                                                                     []  \n",
              "29                                                               [W_17353_50_ivy_M.jpg, W_15141_70_hippie_M.jpg, W_16538_90_hiphop_M.jpg]  \n",
              "30                                                                                   [W_19454_90_kitsch_W.jpg, W_19545_00_oriental_W.jpg]  \n",
              "31                                                                                           [W_30593_50_ivy_M.jpg, W_00804_50_ivy_M.jpg]  \n",
              "32                                                                                  [W_13359_80_powersuit_W.jpg, W_05736_90_kitsch_W.jpg]  \n",
              "33                                                                                                                 [W_17603_50_ivy_M.jpg]  \n",
              "34                                                                                       [W_16283_90_hiphop_M.jpg, W_09119_60_mods_M.jpg]  \n",
              "35                                                                                 [W_10191_00_oriental_W.jpg, W_14852_50_feminine_W.jpg]  \n",
              "36                                                                                                            [W_13251_19_normcore_W.jpg]  \n",
              "37                                                        [W_13398_80_powersuit_W.jpg, W_09307_60_popart_W.jpg, W_18622_60_minimal_W.jpg]  \n",
              "38                                                                                                         [W_16699_00_metrosexual_M.jpg]  \n",
              "39                                                                                   [W_04801_19_lounge_W.jpg, W_14039_00_cityglam_W.jpg]  \n",
              "40                                                                 [W_00492_50_ivy_M.jpg, W_02794_90_hiphop_M.jpg, W_15270_60_mods_M.jpg]  \n",
              "41                                                                                    [W_12002_60_minimal_W.jpg, W_07532_70_hippie_W.jpg]  \n",
              "42                                                                                   [W_10779_50_ivy_M.jpg, W_15766_00_metrosexual_M.jpg]  \n",
              "43                                                                                        [W_17603_50_ivy_M.jpg, W_15684_70_hippie_M.jpg]  \n",
              "44                                                                                                              [W_12635_70_hippie_M.jpg]  \n",
              "45                                                                                        [W_17304_70_hippie_M.jpg, W_30290_50_ivy_M.jpg]  \n",
              "46                                                                                                                                     []  \n",
              "47                                                                                       [W_15362_60_mods_M.jpg, W_15740_70_hippie_M.jpg]  \n",
              "48                                                                                                                                     []  \n",
              "49                                                                                                                                     []  \n",
              "50                                                                                        [W_27850_50_ivy_M.jpg, W_17304_70_hippie_M.jpg]  \n",
              "51                                                        [W_14102_50_feminine_W.jpg, W_47169_70_hippie_W.jpg, W_02498_50_feminine_W.jpg]  \n",
              "52                                                    [W_37404_60_space_W.jpg, W_56334_10_sportivecasual_W.jpg, T_06910_50_classic_W.jpg]  \n",
              "53                                                                                                               [W_34436_60_space_W.jpg]  \n",
              "54                                                                                                         [W_16485_00_metrosexual_M.jpg]  \n",
              "55                                                                             [W_26965_90_hiphop_M.jpg, W_60184_10_sportivecasual_M.jpg]  \n",
              "56                                                                                                                                     []  \n",
              "57                                                                                   [W_11266_60_popart_W.jpg, W_09376_00_cityglam_W.jpg]  \n",
              "58                                                                                          [W_17603_50_ivy_M.jpg, W_12866_60_mods_M.jpg]  \n",
              "59                                                                                                              [W_34080_70_hippie_M.jpg]  \n",
              "60                                                                                                       [W_14272_80_bodyconscious_W.jpg]  \n",
              "61                                                                                                              [W_26634_90_hiphop_M.jpg]  \n",
              "62                                                                                                              [W_15497_70_hippie_M.jpg]  \n",
              "63                                                                                         [W_16067_80_bold_M.jpg, W_12309_80_bold_M.jpg]  \n",
              "64                                                                                                                 [W_23900_50_ivy_M.jpg]  \n",
              "65                                                                                                                                     []  \n",
              "66                                                                             [W_07226_90_hiphop_M.jpg, W_00829_10_sportivecasual_M.jpg]  \n",
              "67                                                                                                                                     []  \n",
              "68                                                                                  [W_10768_00_ecology_W.jpg, W_18730_50_feminine_W.jpg]  \n",
              "69                                                                                     [W_34436_60_space_W.jpg, W_05760_60_minimal_W.jpg]  \n",
              "70                                                                                  [W_15120_60_mods_M.jpg, W_06715_00_metrosexual_M.jpg]  \n",
              "71                                                                                       [W_24947_90_hiphop_M.jpg, W_15998_80_bold_M.jpg]  \n",
              "72                                                                                                              [W_16503_70_hippie_M.jpg]  \n",
              "73                                                                                                            [W_17062_19_normcore_M.jpg]  \n",
              "74                                                                                                              [W_16501_70_hippie_M.jpg]  \n",
              "75                                                                                   [W_25411_70_hippie_M.jpg, W_17767_19_normcore_M.jpg]  \n",
              "76                                                                                     [W_12476_90_hiphop_M.jpg, W_25884_90_hiphop_M.jpg]  \n",
              "77                                                                                                                [T_15662_80_bold_M.jpg]  \n",
              "78                                                                                                                                     []  \n",
              "79                                                                                       [W_24109_60_mods_M.jpg, W_16452_70_hippie_M.jpg]  \n",
              "80                                                                                [W_15486_00_metrosexual_M.jpg, W_17616_70_hippie_M.jpg]  \n",
              "81                                                                                                         [W_15658_00_metrosexual_M.jpg]  \n",
              "82                                                                                                                                     []  \n",
              "83                                                                                                                                     []  \n",
              "84                                                                             [W_12413_90_hiphop_M.jpg, W_00842_10_sportivecasual_M.jpg]  \n",
              "85                                                                           [W_06000_80_powersuit_W.jpg, W_08467_80_bodyconscious_W.jpg]  \n",
              "86                                                                                                           [W_28373_80_powersuit_W.jpg]  \n",
              "87                                                                                                                 [W_15404_50_ivy_M.jpg]  \n",
              "88                                                                                                                                     []  \n",
              "89                                                                                                                                     []  \n",
              "90                                                                                                         [W_16755_00_metrosexual_M.jpg]  \n",
              "91                                                                               [W_16915_10_sportivecasual_M.jpg, W_06883_60_mods_M.jpg]  \n",
              "92                                                                                   [W_18160_50_classic_W.jpg, W_14828_50_classic_W.jpg]  \n",
              "93                                                                                                      [W_05562_10_sportivecasual_W.jpg]  \n",
              "94                                                                                [W_17539_00_metrosexual_M.jpg, W_16047_70_hippie_M.jpg]  \n",
              "95                                                                                                              [W_08641_90_hiphop_W.jpg]  \n",
              "96                                                                                                              [W_12214_70_hippie_M.jpg]  \n",
              "97                                                                                                                 [W_16541_50_ivy_M.jpg]  \n",
              "98                                                                     [W_08862_10_sportivecasual_W.jpg, W_02394_10_sportivecasual_W.jpg]  \n",
              "99                                                                                           [W_24103_50_ivy_M.jpg, W_09156_50_ivy_M.jpg]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c39b6679-5523-45e5-8223-0bd3ee927b0a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>응답자 ID</th>\n",
              "      <th>Validation 스타일 선호</th>\n",
              "      <th>Validation 스타일 비선호</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63405</td>\n",
              "      <td>[W_02677_60_mods_M.jpg, W_01853_60_mods_M.jpg, W_04684_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_12904_50_ivy_M.jpg, W_15140_80_bold_M.jpg, W_12304_80_bold_M.jpg, W_07187_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59642</td>\n",
              "      <td>[W_05716_19_normcore_W.jpg, W_14706_19_normcore_W.jpg, W_02095_60_popart_W.jpg]</td>\n",
              "      <td>[W_08246_80_bodyconscious_W.jpg, W_00359_90_grunge_W.jpg, W_11444_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63748</td>\n",
              "      <td>[W_17867_50_ivy_M.jpg, W_00829_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_00539_10_sportivecasual_M.jpg, W_10079_60_mods_M.jpg, W_11144_00_metrosexual_M.jpg, W_06955_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63913</td>\n",
              "      <td>[W_06883_60_mods_M.jpg]</td>\n",
              "      <td>[W_10066_50_ivy_M.jpg, W_15843_00_metrosexual_M.jpg, W_15947_80_bold_M.jpg, W_16444_10_sportivecasual_M.jpg, W_05876_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64221</td>\n",
              "      <td>[W_28925_90_hiphop_M.jpg, W_25086_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17747_80_bold_M.jpg, W_07333_70_hippie_M.jpg, W_26397_70_hippie_M.jpg, W_02936_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>62155</td>\n",
              "      <td>[W_27854_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17353_50_ivy_M.jpg, W_32383_00_metrosexual_M.jpg, W_06186_60_mods_M.jpg, W_26120_19_normcore_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>63479</td>\n",
              "      <td>[W_04994_60_popart_W.jpg, W_06438_00_ecology_W.jpg, W_18202_60_minimal_W.jpg]</td>\n",
              "      <td>[W_18878_19_genderless_W.jpg, W_11936_00_oriental_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>64216</td>\n",
              "      <td>[W_02816_60_mods_M.jpg, W_15662_19_normcore_M.jpg]</td>\n",
              "      <td>[W_24931_50_ivy_M.jpg, W_24486_70_hippie_M.jpg, W_26288_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7905</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg, W_28909_19_normcore_M.jpg, W_26179_60_mods_M.jpg, W_07025_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>21432</td>\n",
              "      <td>[W_06522_50_ivy_M.jpg, W_15294_50_ivy_M.jpg, W_29023_00_metrosexual_M.jpg]</td>\n",
              "      <td>[W_26397_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>22324</td>\n",
              "      <td>[W_00931_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_04395_80_bold_M.jpg, W_17481_10_sportivecasual_M.jpg, W_16104_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>60184</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12744_50_ivy_M.jpg, W_04245_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_12453_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>61104</td>\n",
              "      <td>[W_08839_10_athleisure_W.jpg, W_09085_60_minimal_W.jpg]</td>\n",
              "      <td>[W_14147_70_disco_W.jpg, W_19430_00_oriental_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>62625</td>\n",
              "      <td>[W_14785_00_cityglam_W.jpg, W_09363_19_genderless_W.jpg, W_01998_90_lingerie_W.jpg, W_03334_90_kitsch_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>63481</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_15184_60_mods_M.jpg, W_17032_10_sportivecasual_M.jpg, W_16460_19_normcore_M.jpg, W_16347_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>64295</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_16374_10_sportivecasual_M.jpg, W_32314_19_normcore_M.jpg, W_31478_19_normcore_M.jpg, W_15729_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7658</td>\n",
              "      <td>[W_09731_19_genderless_W.jpg, W_04927_50_feminine_W.jpg, W_01234_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>12826</td>\n",
              "      <td>[W_16541_50_ivy_M.jpg, W_15244_80_bold_M.jpg, W_04670_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>15251</td>\n",
              "      <td>[W_17841_80_bold_M.jpg, W_16732_70_hippie_M.jpg]</td>\n",
              "      <td>[W_10125_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>28371</td>\n",
              "      <td>[W_26393_50_ivy_M.jpg, W_25020_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_27184_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>28912</td>\n",
              "      <td>[W_16375_80_bold_M.jpg]</td>\n",
              "      <td>[W_00012_50_ivy_M.jpg, W_15745_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>59523</td>\n",
              "      <td>[W_13251_19_normcore_W.jpg]</td>\n",
              "      <td>[W_19207_19_lounge_W.jpg, W_05665_19_genderless_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>59704</td>\n",
              "      <td>[W_04636_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15120_60_mods_M.jpg, W_12476_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>59778</td>\n",
              "      <td>[W_04643_50_ivy_M.jpg, W_04396_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_15184_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>59812</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12564_00_metrosexual_M.jpg, W_15508_60_mods_M.jpg, W_09278_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>59857</td>\n",
              "      <td>[W_14888_19_normcore_W.jpg, W_18546_50_classic_W.jpg]</td>\n",
              "      <td>[W_14299_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>60270</td>\n",
              "      <td>[W_10844_60_mods_M.jpg]</td>\n",
              "      <td>[W_00117_19_normcore_M.jpg, W_07187_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>60510</td>\n",
              "      <td>[W_03447_70_military_W.jpg, W_05736_90_kitsch_W.jpg]</td>\n",
              "      <td>[W_14039_00_cityglam_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>61250</td>\n",
              "      <td>[W_28373_80_powersuit_W.jpg, W_44789_80_powersuit_W.jpg, W_01933_50_feminine_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>62349</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17353_50_ivy_M.jpg, W_15141_70_hippie_M.jpg, W_16538_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>63156</td>\n",
              "      <td>[W_14796_60_minimal_W.jpg]</td>\n",
              "      <td>[W_19454_90_kitsch_W.jpg, W_19545_00_oriental_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>63195</td>\n",
              "      <td>[W_26200_50_ivy_M.jpg]</td>\n",
              "      <td>[W_30593_50_ivy_M.jpg, W_00804_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>63316</td>\n",
              "      <td>[W_05580_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_13359_80_powersuit_W.jpg, W_05736_90_kitsch_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>63392</td>\n",
              "      <td>[W_15370_50_ivy_M.jpg, W_06576_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>63401</td>\n",
              "      <td>[W_00492_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16283_90_hiphop_M.jpg, W_09119_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>63430</td>\n",
              "      <td>[W_01056_00_cityglam_W.jpg]</td>\n",
              "      <td>[W_10191_00_oriental_W.jpg, W_14852_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>63435</td>\n",
              "      <td>[W_08285_19_normcore_W.jpg, W_02557_00_ecology_W.jpg]</td>\n",
              "      <td>[W_13251_19_normcore_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>63473</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_13398_80_powersuit_W.jpg, W_09307_60_popart_W.jpg, W_18622_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>63505</td>\n",
              "      <td>[W_12393_50_ivy_M.jpg, W_12518_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_16699_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>63545</td>\n",
              "      <td>[W_03842_50_feminine_W.jpg]</td>\n",
              "      <td>[W_04801_19_lounge_W.jpg, W_14039_00_cityglam_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>63571</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_00492_50_ivy_M.jpg, W_02794_90_hiphop_M.jpg, W_15270_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>63740</td>\n",
              "      <td>[W_01179_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_12002_60_minimal_W.jpg, W_07532_70_hippie_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>63910</td>\n",
              "      <td>[W_16851_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_10779_50_ivy_M.jpg, W_15766_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>63934</td>\n",
              "      <td>[W_12897_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg, W_15684_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>63952</td>\n",
              "      <td>[W_00073_50_ivy_M.jpg, W_15662_19_normcore_M.jpg]</td>\n",
              "      <td>[W_12635_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>64252</td>\n",
              "      <td>[W_24152_60_mods_M.jpg]</td>\n",
              "      <td>[W_17304_70_hippie_M.jpg, W_30290_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>64280</td>\n",
              "      <td>[W_12567_60_mods_M.jpg, W_24628_70_hippie_M.jpg, W_02688_60_mods_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>64310</td>\n",
              "      <td>[W_25934_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_15362_60_mods_M.jpg, W_15740_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>64460</td>\n",
              "      <td>[W_12817_50_ivy_M.jpg, W_25649_19_normcore_M.jpg, W_16732_70_hippie_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>64496</td>\n",
              "      <td>[W_24647_70_hippie_M.jpg, W_34080_70_hippie_M.jpg, W_30403_60_mods_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>64575</td>\n",
              "      <td>[W_32445_60_mods_M.jpg]</td>\n",
              "      <td>[W_27850_50_ivy_M.jpg, W_17304_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>64747</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_14102_50_feminine_W.jpg, W_47169_70_hippie_W.jpg, W_02498_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>66513</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_37404_60_space_W.jpg, W_56334_10_sportivecasual_W.jpg, T_06910_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>66592</td>\n",
              "      <td>[W_46907_80_powersuit_W.jpg, W_44918_60_minimal_W.jpg]</td>\n",
              "      <td>[W_34436_60_space_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>66842</td>\n",
              "      <td>[W_27765_60_mods_M.jpg, T_06502_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_16485_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>67975</td>\n",
              "      <td>[W_07074_00_metrosexual_M.jpg]</td>\n",
              "      <td>[W_26965_90_hiphop_M.jpg, W_60184_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>837</td>\n",
              "      <td>[W_00829_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>2609</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_11266_60_popart_W.jpg, W_09376_00_cityglam_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>4035</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg, W_12866_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>4817</td>\n",
              "      <td>[W_00831_19_normcore_M.jpg]</td>\n",
              "      <td>[W_34080_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>5931</td>\n",
              "      <td>[W_13354_50_feminine_W.jpg]</td>\n",
              "      <td>[W_14272_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>10590</td>\n",
              "      <td>[W_09156_50_ivy_M.jpg]</td>\n",
              "      <td>[W_26634_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>14276</td>\n",
              "      <td>[W_15295_60_mods_M.jpg]</td>\n",
              "      <td>[W_15497_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>18129</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_16067_80_bold_M.jpg, W_12309_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>18667</td>\n",
              "      <td>[W_29258_80_bold_M.jpg]</td>\n",
              "      <td>[W_23900_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>19125</td>\n",
              "      <td>[W_17413_00_metrosexual_M.jpg, W_12656_00_metrosexual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>19339</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_07226_90_hiphop_M.jpg, W_00829_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>19552</td>\n",
              "      <td>[W_07290_50_ivy_M.jpg, W_04268_70_hippie_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>20768</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_10768_00_ecology_W.jpg, W_18730_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>23021</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_34436_60_space_W.jpg, W_05760_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>23054</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_15120_60_mods_M.jpg, W_06715_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>24912</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_24947_90_hiphop_M.jpg, W_15998_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>28534</td>\n",
              "      <td>[W_15294_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16503_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>28700</td>\n",
              "      <td>[W_06955_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17062_19_normcore_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>28828</td>\n",
              "      <td>[W_04245_70_hippie_M.jpg]</td>\n",
              "      <td>[W_16501_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>30790</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_25411_70_hippie_M.jpg, W_17767_19_normcore_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>35283</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12476_90_hiphop_M.jpg, W_25884_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>38363</td>\n",
              "      <td>[W_27750_60_mods_M.jpg]</td>\n",
              "      <td>[T_15662_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>44117</td>\n",
              "      <td>[T_06739_10_sportivecasual_M.jpg, T_15662_80_bold_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>50038</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_24109_60_mods_M.jpg, W_16452_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>51939</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_15486_00_metrosexual_M.jpg, W_17616_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>54939</td>\n",
              "      <td>[W_24696_80_bold_M.jpg]</td>\n",
              "      <td>[W_15658_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>58251</td>\n",
              "      <td>[W_19520_50_feminine_W.jpg, W_00716_60_minimal_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>59083</td>\n",
              "      <td>[W_16466_10_sportivecasual_M.jpg, W_06547_00_metrosexual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>59468</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12413_90_hiphop_M.jpg, W_00842_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>59637</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_06000_80_powersuit_W.jpg, W_08467_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>59843</td>\n",
              "      <td>[W_44918_60_minimal_W.jpg]</td>\n",
              "      <td>[W_28373_80_powersuit_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>59901</td>\n",
              "      <td>[W_05868_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15404_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>60056</td>\n",
              "      <td>[W_16624_90_hiphop_M.jpg, W_07271_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>60071</td>\n",
              "      <td>[W_29942_50_ivy_M.jpg, W_27791_00_metrosexual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>60234</td>\n",
              "      <td>[W_10107_60_mods_M.jpg]</td>\n",
              "      <td>[W_16755_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>60465</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_16915_10_sportivecasual_M.jpg, W_06883_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>61145</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_18160_50_classic_W.jpg, W_14828_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>61192</td>\n",
              "      <td>[W_44330_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_05562_10_sportivecasual_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>61227</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17539_00_metrosexual_M.jpg, W_16047_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>61460</td>\n",
              "      <td>[W_19158_90_kitsch_W.jpg]</td>\n",
              "      <td>[W_08641_90_hiphop_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>61818</td>\n",
              "      <td>[W_09763_80_bold_M.jpg]</td>\n",
              "      <td>[W_12214_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>61892</td>\n",
              "      <td>[W_15248_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16541_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>62125</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_08862_10_sportivecasual_W.jpg, W_02394_10_sportivecasual_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>62154</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_24103_50_ivy_M.jpg, W_09156_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c39b6679-5523-45e5-8223-0bd3ee927b0a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c39b6679-5523-45e5-8223-0bd3ee927b0a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c39b6679-5523-45e5-8223-0bd3ee927b0a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e7e24c3e-bc61-4acd-b030-efe5247ebc97\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e7e24c3e-bc61-4acd-b030-efe5247ebc97')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e7e24c3e-bc61-4acd-b030-efe5247ebc97 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_ba79f982-f643-49e6-9298-8a777db1669f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('validation_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_ba79f982-f643-49e6-9298-8a777db1669f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('validation_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "validation_df",
              "summary": "{\n  \"name\": \"validation_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"\\uc751\\ub2f5\\uc790 ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20727,\n        \"min\": 837,\n        \"max\": 67975,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          59083,\n          66592,\n          23054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation \\uc2a4\\ud0c0\\uc77c \\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation \\uc2a4\\ud0c0\\uc77c \\ube44\\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "상위 100명의 응답자 스타일 선호도가 /content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv에 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[2-2]"
      ],
      "metadata": {
        "id": "o59lQxP32RSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 응답자별로 상위 100명을 추출하는 함수\n",
        "def get_top_respondents(valid_labels, top_n=100):\n",
        "    # 응답자 ID별로 라벨링 데이터 개수를 집계하여 상위 N명을 추출\n",
        "    respondent_counts = pd.DataFrame(valid_labels).groupby(\"respondent_id\").size()\n",
        "    top_respondents = respondent_counts.nlargest(top_n).index.tolist()\n",
        "    return top_respondents\n",
        "\n",
        "# 유효한 라벨 데이터에서 상위 100명의 응답자를 추출\n",
        "top_training_respondents = get_top_respondents(valid_training_labels, top_n=100)\n",
        "top_validation_respondents = get_top_respondents(valid_validation_labels, top_n=100)\n",
        "\n",
        "# 응답자 스타일 선호도 데이터프레임 생성\n",
        "def create_preference_df(valid_labels, top_respondents, dataset_name):\n",
        "    rows = []\n",
        "\n",
        "    for respondent in top_respondents:\n",
        "        respondent_data = [entry for entry in valid_labels if entry['respondent_id'] == respondent]\n",
        "        preferred = [entry['img_name'] for entry in respondent_data if entry['Q5'] == 2]\n",
        "        non_preferred = [entry['img_name'] for entry in respondent_data if entry['Q5'] == 1]\n",
        "\n",
        "        rows.append({\n",
        "            '응답자 ID': respondent,\n",
        "            f'{dataset_name} 스타일 선호': preferred,\n",
        "            f'{dataset_name} 스타일 비선호': non_preferred\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# DataFrame으로 생성 및 출력\n",
        "training_df = create_preference_df(valid_training_labels, top_training_respondents, 'Training')\n",
        "validation_df = create_preference_df(valid_validation_labels, top_validation_respondents, 'Validation')\n",
        "\n",
        "print(\"Training 응답자 스타일 선호 정보:\")\n",
        "display(training_df)\n",
        "print(\"\\nValidation 응답자 스타일 선호 정보:\")\n",
        "display(validation_df)\n",
        "\n",
        "# DataFrame을 CSV 파일로 저장\n",
        "output_csv_path = 'top_100_respondents_preferences.csv'\n",
        "top_preference_df.to_csv(output_csv_path, index=False)\n",
        "print(f\"\\n상위 100명의 응답자 선호도가 {output_csv_path}에 저장되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dpYomZ802TWZ",
        "outputId": "ed9eee70-61d5-41c3-fd78-14a20401b0a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 응답자 스타일 선호 정보:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    응답자 ID  \\\n",
              "0    21432   \n",
              "1    60234   \n",
              "2    62264   \n",
              "3    64345   \n",
              "4    63740   \n",
              "5    64221   \n",
              "6    64460   \n",
              "7    28912   \n",
              "8    60184   \n",
              "9    62525   \n",
              "10   63545   \n",
              "11   63583   \n",
              "12   63934   \n",
              "13   66592   \n",
              "14   60173   \n",
              "15   63207   \n",
              "16   63359   \n",
              "17   63508   \n",
              "18   63571   \n",
              "19   63769   \n",
              "20   63913   \n",
              "21   63927   \n",
              "22   64216   \n",
              "23   64571   \n",
              "24   64598   \n",
              "25   68891   \n",
              "26     837   \n",
              "27   30790   \n",
              "28   35514   \n",
              "29   61104   \n",
              "30   62155   \n",
              "31   62349   \n",
              "32   63156   \n",
              "33   63369   \n",
              "34   63424   \n",
              "35   63435   \n",
              "36   63748   \n",
              "37   64310   \n",
              "38   64397   \n",
              "39   64503   \n",
              "40   65139   \n",
              "41   66513   \n",
              "42    9096   \n",
              "43   22324   \n",
              "44   59083   \n",
              "45   59523   \n",
              "46   59637   \n",
              "47   59704   \n",
              "48   59812   \n",
              "49   63316   \n",
              "50   63479   \n",
              "51   63644   \n",
              "52   63759   \n",
              "53   64561   \n",
              "54   64662   \n",
              "55   64747   \n",
              "56   66469   \n",
              "57    7658   \n",
              "58   20768   \n",
              "59   28371   \n",
              "60   61250   \n",
              "61   61493   \n",
              "62   61859   \n",
              "63   63405   \n",
              "64   63505   \n",
              "65   63742   \n",
              "66   63910   \n",
              "67   64223   \n",
              "68   64364   \n",
              "69     368   \n",
              "70   18730   \n",
              "71   28358   \n",
              "72   28571   \n",
              "73   50277   \n",
              "74   59506   \n",
              "75   62113   \n",
              "76   62625   \n",
              "77   62868   \n",
              "78   63430   \n",
              "79   63481   \n",
              "80   63526   \n",
              "81   63717   \n",
              "82   63930   \n",
              "83   64252   \n",
              "84   64327   \n",
              "85   64336   \n",
              "86   64346   \n",
              "87   66731   \n",
              "88    4035   \n",
              "89    7905   \n",
              "90   18129   \n",
              "91   23108   \n",
              "92   58251   \n",
              "93   59642   \n",
              "94   59857   \n",
              "95   59901   \n",
              "96   62653   \n",
              "97   62952   \n",
              "98   63255   \n",
              "99   63391   \n",
              "\n",
              "                                                                                                                                                                                                                        Training 스타일 선호  \\\n",
              "0                                                                                                          [W_28523_90_hiphop_M.jpg, W_09891_90_hiphop_M.jpg, W_29023_00_metrosexual_M.jpg, W_15294_50_ivy_M.jpg, W_32448_50_ivy_M.jpg]   \n",
              "1                                                                                                                   [W_01693_19_normcore_M.jpg, W_17337_50_ivy_M.jpg, W_16539_50_ivy_M.jpg, W_07102_50_ivy_M.jpg, W_12748_50_ivy_M.jpg]   \n",
              "2                                                      [W_07260_10_sportivecasual_M.jpg, W_16449_10_sportivecasual_M.jpg, W_16403_10_sportivecasual_M.jpg, W_07098_19_normcore_M.jpg, W_07307_19_normcore_M.jpg, W_05869_60_mods_M.jpg]   \n",
              "3   [W_28449_10_sportivecasual_M.jpg, W_17467_19_normcore_M.jpg, W_00843_10_sportivecasual_M.jpg, W_29596_10_sportivecasual_M.jpg, W_27156_90_hiphop_M.jpg, W_32150_00_metrosexual_M.jpg, W_15856_60_mods_M.jpg, W_24155_60_mods_M.jpg]   \n",
              "4                                                                                            [W_04201_19_lounge_W.jpg, W_01179_10_sportivecasual_W.jpg, W_11824_70_military_W.jpg, W_14975_60_minimal_W.jpg, W_18894_50_feminine_W.jpg]   \n",
              "5                                                                                                 [W_28698_10_sportivecasual_M.jpg, W_25039_90_hiphop_M.jpg, W_32524_00_metrosexual_M.jpg, W_28728_50_ivy_M.jpg, W_24013_60_mods_M.jpg]   \n",
              "6                                                              [W_24294_80_bold_M.jpg, W_24934_90_hiphop_M.jpg, W_26530_00_metrosexual_M.jpg, W_06514_80_bold_M.jpg, W_10792_50_ivy_M.jpg, W_12817_50_ivy_M.jpg, W_15653_60_mods_M.jpg]   \n",
              "7                                                                                                                                              [W_01754_10_sportivecasual_M.jpg, W_04680_10_sportivecasual_M.jpg, W_02669_50_ivy_M.jpg]   \n",
              "8                                                                                                                                                       [W_01687_19_normcore_M.jpg, W_17427_00_metrosexual_M.jpg, W_17348_50_ivy_M.jpg]   \n",
              "9           [W_00760_19_normcore_W.jpg, W_05751_10_sportivecasual_W.jpg, W_19165_00_cityglam_W.jpg, W_03477_80_powersuit_W.jpg, W_01207_60_minimal_W.jpg, W_11223_60_popart_W.jpg, W_13104_50_classic_W.jpg, W_18495_50_feminine_W.jpg]   \n",
              "10                                                                                                                     [W_08322_19_normcore_W.jpg, W_14897_10_sportivecasual_W.jpg, W_04993_70_hippie_W.jpg, W_03842_50_feminine_W.jpg]   \n",
              "11                                                                                                                                                                               [W_02100_00_oriental_W.jpg, W_00385_50_feminine_W.jpg]   \n",
              "12                                                                                                                                                                                   [W_16255_19_normcore_M.jpg, W_12327_80_bold_M.jpg]   \n",
              "13                                                                            [W_46907_80_powersuit_W.jpg, W_53583_90_hiphop_W.jpg, W_53861_90_kitsch_W.jpg, W_53133_90_hiphop_W.jpg, W_44918_60_minimal_W.jpg, W_02343_60_space_W.jpg]   \n",
              "14                                                        [W_14216_10_sportivecasual_W.jpg, W_08869_10_sportivecasual_W.jpg, W_05458_10_athleisure_W.jpg, W_07964_70_military_W.jpg, W_14099_50_classic_W.jpg, W_09079_60_popart_W.jpg]   \n",
              "15                                                                                                                                                                                                    [W_02771_10_sportivecasual_M.jpg]   \n",
              "16                                                                                                                                                  [W_00410_19_genderless_W.jpg, W_01958_00_cityglam_W.jpg, W_08140_50_feminine_W.jpg]   \n",
              "17                                                                                              [W_15768_19_normcore_M.jpg, W_15156_00_metrosexual_M.jpg, W_12698_80_bold_M.jpg, W_16295_70_hippie_M.jpg, W_15488_00_metrosexual_M.jpg]   \n",
              "18                                                                                                                                                                                                    [W_04649_10_sportivecasual_M.jpg]   \n",
              "19                                                                                                                                                                                                    [W_09795_10_sportivecasual_M.jpg]   \n",
              "20                                                                      [W_00553_10_sportivecasual_M.jpg, W_07066_10_sportivecasual_M.jpg, W_07255_50_ivy_M.jpg, W_07150_70_hippie_M.jpg, W_06573_60_mods_M.jpg, W_06883_60_mods_M.jpg]   \n",
              "21                                                                                                                                                                                   [W_06824_19_normcore_M.jpg, W_06531_60_mods_M.jpg]   \n",
              "22                                                                                                                                                    [W_27674_10_sportivecasual_M.jpg, W_17855_90_hiphop_M.jpg, W_02816_60_mods_M.jpg]   \n",
              "23                                                                                                                                                                                                          [W_00794_19_normcore_M.jpg]   \n",
              "24                                                         [W_48074_10_sportivecasual_W.jpg, W_21732_10_sportivecasual_W.jpg, W_27930_80_powersuit_W.jpg, W_00638_90_hiphop_W.jpg, W_04895_50_classic_W.jpg, W_09961_50_feminine_W.jpg]   \n",
              "25                               [T_15458_10_sportivecasual_M.jpg, T_15453_10_sportivecasual_M.jpg, T_15468_10_sportivecasual_M.jpg, T_15477_10_sportivecasual_M.jpg, T_15488_10_sportivecasual_M.jpg, T_15467_10_sportivecasual_M.jpg]   \n",
              "26                                                     [W_00829_10_sportivecasual_M.jpg, W_28209_10_sportivecasual_M.jpg, W_28211_19_normcore_M.jpg, W_28722_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg, W_25073_90_hiphop_M.jpg]   \n",
              "27                                                                                                                              [W_33023_10_sportivecasual_M.jpg, W_26425_90_hiphop_M.jpg, W_06511_50_ivy_M.jpg, W_06863_60_mods_M.jpg]   \n",
              "28                                                                                                  [W_01716_19_normcore_M.jpg, W_04539_10_sportivecasual_M.jpg, W_01645_90_hiphop_M.jpg, W_01664_60_mods_M.jpg, W_09152_60_mods_M.jpg]   \n",
              "29                                                                                                                  [W_07906_00_ecology_W.jpg, W_08810_10_sportivecasual_W.jpg, W_04919_00_oriental_W.jpg, W_02487_10_athleisure_W.jpg]   \n",
              "30                                                                                                                                                                                    [W_31063_19_normcore_M.jpg, W_27854_50_ivy_M.jpg]   \n",
              "31                                                                                                                                                      [W_04689_10_sportivecasual_M.jpg, W_17802_80_bold_M.jpg, W_07101_60_mods_M.jpg]   \n",
              "32                                                                                                                                                                                                        [W_01318_10_athleisure_W.jpg]   \n",
              "33                                                                                              [W_03000_19_normcore_M.jpg, W_09785_19_normcore_M.jpg, W_01428_10_sportivecasual_M.jpg, W_04733_90_hiphop_M.jpg, W_09760_60_mods_M.jpg]   \n",
              "34                                                                                                                                                 [W_19801_19_genderless_W.jpg, W_09698_19_genderless_W.jpg, W_01962_60_minimal_W.jpg]   \n",
              "35                                                              [W_08285_19_normcore_W.jpg, W_19407_19_normcore_W.jpg, W_01041_10_sportivecasual_W.jpg, W_19010_00_oriental_W.jpg, W_18401_90_lingerie_W.jpg, W_04192_60_minimal_W.jpg]   \n",
              "36                                                                                                      [W_02890_19_normcore_M.jpg, W_00829_10_sportivecasual_M.jpg, W_15268_50_ivy_M.jpg, W_10092_60_mods_M.jpg, W_17867_50_ivy_M.jpg]   \n",
              "37                                                                                                                                 [W_26375_70_hippie_M.jpg, W_16007_70_hippie_M.jpg, W_25934_90_hiphop_M.jpg, W_04692_90_hiphop_M.jpg]   \n",
              "38                                                                                                                                                                                    [W_17793_19_normcore_M.jpg, W_24889_50_ivy_M.jpg]   \n",
              "39                                                                     [W_43214_19_genderless_W.jpg, W_45353_80_powersuit_W.jpg, W_40718_90_hiphop_W.jpg, W_43570_90_hiphop_W.jpg, W_36275_60_minimal_W.jpg, W_07755_50_feminine_W.jpg]   \n",
              "40                                                                                                                                                                               [W_64254_19_normcore_M.jpg, W_16523_19_normcore_M.jpg]   \n",
              "41                                                                                                                             [W_60789_90_lingerie_W.jpg, W_44554_90_grunge_W.jpg, W_35544_60_minimal_W.jpg, W_19031_50_classic_W.jpg]   \n",
              "42                                                                        [W_03582_19_normcore_W.jpg, W_03784_00_cityglam_W.jpg, W_08797_70_disco_W.jpg, W_14507_60_minimal_W.jpg, W_03160_60_minimal_W.jpg, W_19987_50_feminine_W.jpg]   \n",
              "43                                                                                                                      [W_04372_10_sportivecasual_M.jpg, W_07347_90_hiphop_M.jpg, W_17700_00_metrosexual_M.jpg, W_02696_60_mods_M.jpg]   \n",
              "44                                                                                                [W_09799_19_normcore_M.jpg, W_06836_00_metrosexual_M.jpg, W_06547_00_metrosexual_M.jpg, W_10803_80_bold_M.jpg, W_15367_60_mods_M.jpg]   \n",
              "45                                                                                               [W_09060_19_normcore_W.jpg, W_05673_10_sportivecasual_W.jpg, W_09533_90_grunge_W.jpg, W_05690_70_punk_W.jpg, W_18661_60_minimal_W.jpg]   \n",
              "46                                                                                                                      [W_00784_19_normcore_W.jpg, W_08042_10_athleisure_W.jpg, W_09626_10_athleisure_W.jpg, W_03580_60_minimal_W.jpg]   \n",
              "47                                                                                                                                                          [W_07211_00_metrosexual_M.jpg, W_04636_50_ivy_M.jpg, W_06558_60_mods_M.jpg]   \n",
              "48                                                                                                                                                                                                    [W_06672_10_sportivecasual_M.jpg]   \n",
              "49                                                                                                                    [W_06484_19_lounge_W.jpg, W_05594_19_genderless_W.jpg, W_05580_10_sportivecasual_W.jpg, W_07586_60_minimal_W.jpg]   \n",
              "50                                                                                                  [W_09086_19_normcore_W.jpg, W_19413_00_oriental_W.jpg, W_14584_50_classic_W.jpg, W_18202_60_minimal_W.jpg, W_04994_60_popart_W.jpg]   \n",
              "51                                                                                                                                 [W_05127_90_kitsch_W.jpg, W_03934_70_hippie_W.jpg, W_07688_70_disco_W.jpg, W_14787_60_minimal_W.jpg]   \n",
              "52                                                                                                                                                [W_05821_90_kitsch_W.jpg, W_09611_10_sportivecasual_W.jpg, W_05715_70_military_W.jpg]   \n",
              "53                                                                                                                                                   [W_36907_19_genderless_W.jpg, W_18759_50_feminine_W.jpg, W_18066_50_classic_W.jpg]   \n",
              "54                                                                                                                                                                                                                                   []   \n",
              "55                                                                                         [W_39725_19_normcore_W.jpg, W_29783_10_sportivecasual_W.jpg, W_34636_00_oriental_W.jpg, W_04972_90_kitsch_W.jpg, W_21223_80_powersuit_W.jpg]   \n",
              "56                                                                                [T_00456_10_sportivecasual_M.jpg, T_03772_90_hiphop_M.jpg, W_06657_60_mods_M.jpg, W_00486_60_mods_M.jpg, W_10810_60_mods_M.jpg, W_51362_50_ivy_M.jpg]   \n",
              "57                                                                                                                                                                   [W_01234_10_sportivecasual_W.jpg, W_08708_10_sportivecasual_W.jpg]   \n",
              "58                                                                                                                                                                          [W_09011_10_sportivecasual_W.jpg, W_18900_50_classic_W.jpg]   \n",
              "59                                                                                                                                                        [W_17461_19_normcore_M.jpg, W_57031_90_hiphop_M.jpg, W_25020_90_hiphop_M.jpg]   \n",
              "60                                                                                                                             [W_62598_19_normcore_W.jpg, W_47873_70_punk_W.jpg, W_01933_50_feminine_W.jpg, W_13173_50_feminine_W.jpg]   \n",
              "61                                                                                                                      [W_04661_10_sportivecasual_M.jpg, W_02881_10_sportivecasual_M.jpg, W_02818_60_mods_M.jpg, W_04232_50_ivy_M.jpg]   \n",
              "62                                                                                                                                                                                                                                   []   \n",
              "63                                                                                                                                                                                     [W_04684_90_hiphop_M.jpg, W_15400_60_mods_M.jpg]   \n",
              "64                                      [W_11117_19_normcore_M.jpg, W_09186_10_sportivecasual_M.jpg, W_07078_10_sportivecasual_M.jpg, W_12328_80_bold_M.jpg, W_17803_80_bold_M.jpg, W_17907_00_metrosexual_M.jpg, W_12393_50_ivy_M.jpg]   \n",
              "65                                                                                                                                                                                                                                   []   \n",
              "66                                                                                                                                                               [W_17529_70_hippie_M.jpg, W_17962_50_ivy_M.jpg, W_00495_60_mods_M.jpg]   \n",
              "67                                                                                                                                                                                                          [W_04537_19_normcore_M.jpg]   \n",
              "68                                                                                                                        [W_01472_19_normcore_M.jpg, W_32885_10_sportivecasual_M.jpg, W_16850_19_normcore_M.jpg, W_24141_50_ivy_M.jpg]   \n",
              "69                                                                                                                                                                                   [W_02804_19_normcore_M.jpg, W_06843_60_mods_M.jpg]   \n",
              "70                                                                                                                                                                [W_16362_80_bold_M.jpg, W_12196_80_bold_M.jpg, W_06847_60_mods_M.jpg]   \n",
              "71                                                                                                                                                                                                                                   []   \n",
              "72                                                                                                                                                                                                               [W_12826_50_ivy_M.jpg]   \n",
              "73                                                                                                                                                                              [W_09792_10_sportivecasual_M.jpg, W_06909_50_ivy_M.jpg]   \n",
              "74                                                                                                                                                     [W_02265_70_military_W.jpg, W_11218_50_feminine_W.jpg, W_13247_60_minimal_W.jpg]   \n",
              "75                                                                             [W_02567_10_sportivecasual_W.jpg, W_04068_10_athleisure_W.jpg, W_10554_80_bodyconscious_W.jpg, W_08595_80_bodyconscious_W.jpg, W_09639_50_classic_W.jpg]   \n",
              "76                                                                                                                                                    [W_09363_19_genderless_W.jpg, W_05247_90_hiphop_W.jpg, W_07950_70_military_W.jpg]   \n",
              "77                                                                                                                                                                                                                                   []   \n",
              "78                                                                                                                                                                                 [W_08809_19_lounge_W.jpg, W_00570_90_lingerie_W.jpg]   \n",
              "79                                                                                                                                          [W_01480_10_sportivecasual_M.jpg, W_16975_10_sportivecasual_M.jpg, W_05894_90_hiphop_M.jpg]   \n",
              "80                                                                                                                                                                               [W_03388_00_cityglam_W.jpg, W_01993_00_oriental_W.jpg]   \n",
              "81                                                                                                                                                                                                          [W_09352_70_military_W.jpg]   \n",
              "82                                                                                                                                            [W_01558_10_sportivecasual_M.jpg, W_09792_10_sportivecasual_M.jpg, W_12196_80_bold_M.jpg]   \n",
              "83                                                                                                                                                                                   [W_07138_19_normcore_M.jpg, W_24152_60_mods_M.jpg]   \n",
              "84                                                                                                                                                                                 [W_24403_00_metrosexual_M.jpg, W_15095_50_ivy_M.jpg]   \n",
              "85                                                                                                                                                                                     [W_06603_90_hiphop_M.jpg, W_00479_60_mods_M.jpg]   \n",
              "86                                                                                                       [W_00856_10_sportivecasual_M.jpg, W_16233_80_bold_M.jpg, W_24977_70_hippie_M.jpg, W_30040_60_mods_M.jpg, W_24103_50_ivy_M.jpg]   \n",
              "87                                                                                                                                                                               [W_01088_70_military_W.jpg, W_04781_50_feminine_W.jpg]   \n",
              "88                                                                                                                                                                                                               [W_15186_50_ivy_M.jpg]   \n",
              "89                                                                                                                                                                                                                                   []   \n",
              "90                                                                                                                                                                                      [W_01424_70_hippie_M.jpg, W_02710_50_ivy_M.jpg]   \n",
              "91                                                                                                                                                                                        [W_30483_80_bold_M.jpg, W_04601_50_ivy_M.jpg]   \n",
              "92                                                                                                                                                                                                          [W_01259_90_lingerie_W.jpg]   \n",
              "93                                                                                                                                [W_16917_10_athleisure_W.jpg, W_18366_70_disco_W.jpg, W_02444_70_punk_W.jpg, W_02095_60_popart_W.jpg]   \n",
              "94                                                                                                                                                         [W_14888_19_normcore_W.jpg, W_03599_70_punk_W.jpg, W_18546_50_classic_W.jpg]   \n",
              "95                                                                                                                                                       [W_04649_10_sportivecasual_M.jpg, W_00017_60_mods_M.jpg, W_12821_50_ivy_M.jpg]   \n",
              "96                                                                                                                                                                                [W_26093_00_metrosexual_M.jpg, W_02958_60_mods_M.jpg]   \n",
              "97                                                                                                                                                                               [W_38394_19_normcore_W.jpg, W_04928_50_feminine_W.jpg]   \n",
              "98                                                                                                                                          [W_02846_70_hippie_M.jpg, W_16541_50_ivy_M.jpg, W_10804_50_ivy_M.jpg, W_00036_50_ivy_M.jpg]   \n",
              "99                                                                                                                                                                                   [W_07215_19_normcore_M.jpg, W_09140_60_mods_M.jpg]   \n",
              "\n",
              "                                                                                                                                                                                                                                      Training 스타일 비선호  \n",
              "0                            [W_29224_10_sportivecasual_M.jpg, W_26017_10_sportivecasual_M.jpg, W_26151_80_bold_M.jpg, W_26296_70_hippie_M.jpg, W_12383_80_bold_M.jpg, W_24439_00_metrosexual_M.jpg, W_26397_70_hippie_M.jpg, W_25107_70_hippie_M.jpg]  \n",
              "1                                                  [W_17508_80_bold_M.jpg, W_02844_90_hiphop_M.jpg, W_16755_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_16673_70_hippie_M.jpg, W_15423_80_bold_M.jpg, W_06546_60_mods_M.jpg, W_15259_60_mods_M.jpg]  \n",
              "2                                                                             [W_16136_80_bold_M.jpg, W_15477_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_16428_90_hiphop_M.jpg, W_16189_50_ivy_M.jpg, W_16189_50_ivy_M.jpg, W_04233_60_mods_M.jpg]  \n",
              "3                                                                                                                       [W_24825_80_bold_M.jpg, W_25884_90_hiphop_M.jpg, W_11105_00_metrosexual_M.jpg, W_24352_70_hippie_M.jpg, W_24325_60_mods_M.jpg]  \n",
              "4                                                [W_05226_10_sportivecasual_W.jpg, W_08607_90_kitsch_W.jpg, W_19264_90_kitsch_W.jpg, W_03656_90_hiphop_W.jpg, W_05353_80_bodyconscious_W.jpg, W_06083_80_bodyconscious_W.jpg, W_07532_70_hippie_W.jpg]  \n",
              "5                                                                             [W_26397_70_hippie_M.jpg, W_25471_70_hippie_M.jpg, W_12130_80_bold_M.jpg, W_28207_90_hiphop_M.jpg, W_17747_80_bold_M.jpg, W_15129_50_ivy_M.jpg, W_07333_70_hippie_M.jpg]  \n",
              "6                                                                                                                       [W_25069_90_hiphop_M.jpg, W_31356_80_bold_M.jpg, W_25082_70_hippie_M.jpg, W_30522_00_metrosexual_M.jpg, W_25526_60_mods_M.jpg]  \n",
              "7                                                    [W_17260_19_normcore_M.jpg, W_16725_70_hippie_M.jpg, W_15745_80_bold_M.jpg, W_04723_90_hiphop_M.jpg, W_15923_80_bold_M.jpg, W_04242_60_mods_M.jpg, W_15246_50_ivy_M.jpg, W_03007_70_hippie_M.jpg]  \n",
              "8                                    [W_12453_10_sportivecasual_M.jpg, W_12095_80_bold_M.jpg, W_28377_80_bold_M.jpg, W_27913_00_metrosexual_M.jpg, W_25030_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_16016_70_hippie_M.jpg, W_04245_70_hippie_M.jpg]  \n",
              "9                                                                                                                                                                     [W_13667_00_oriental_W.jpg, W_08167_60_minimal_W.jpg, W_07447_50_feminine_W.jpg]  \n",
              "10                                                             [W_04035_19_normcore_W.jpg, W_08610_90_grunge_W.jpg, W_19342_70_hippie_W.jpg, W_10655_50_feminine_W.jpg, W_12003_60_minimal_W.jpg, W_13846_60_minimal_W.jpg, W_10981_50_feminine_W.jpg]  \n",
              "11        [W_10223_00_oriental_W.jpg, W_18920_00_oriental_W.jpg, W_03693_10_athleisure_W.jpg, W_01248_90_hiphop_W.jpg, W_18030_90_kitsch_W.jpg, W_19311_70_punk_W.jpg, W_19964_80_powersuit_W.jpg, W_18543_60_popart_W.jpg, W_04901_50_feminine_W.jpg]  \n",
              "12  [W_01630_10_sportivecasual_M.jpg, W_10791_19_normcore_M.jpg, W_16236_80_bold_M.jpg, W_11063_00_metrosexual_M.jpg, W_02755_90_hiphop_M.jpg, W_01794_00_metrosexual_M.jpg, W_15669_00_metrosexual_M.jpg, W_17603_50_ivy_M.jpg, W_06259_50_ivy_M.jpg]  \n",
              "13                                                                                                                     [W_52969_00_ecology_W.jpg, W_51690_80_powersuit_W.jpg, W_52731_90_kitsch_W.jpg, W_41924_70_punk_W.jpg, W_47960_60_popart_W.jpg]  \n",
              "14                                                                                                                                        [W_19273_00_ecology_W.jpg, W_07408_90_lingerie_W.jpg, W_06402_80_powersuit_W.jpg, W_09497_50_feminine_W.jpg]  \n",
              "15      [W_00505_10_sportivecasual_M.jpg, W_16390_10_sportivecasual_M.jpg, W_11033_90_hiphop_M.jpg, W_15634_80_bold_M.jpg, W_16684_00_metrosexual_M.jpg, W_16361_80_bold_M.jpg, W_09796_60_mods_M.jpg, W_10087_70_hippie_M.jpg, W_09132_60_mods_M.jpg]  \n",
              "16                                                     [W_10207_00_oriental_W.jpg, W_10289_00_oriental_W.jpg, W_13858_80_bodyconscious_W.jpg, W_13941_60_minimal_W.jpg, W_12019_50_feminine_W.jpg, W_19530_60_popart_W.jpg, W_07682_50_feminine_W.jpg]  \n",
              "17                                                                                                                 [W_07043_10_sportivecasual_M.jpg, W_13458_80_bold_M.jpg, W_11071_00_metrosexual_M.jpg, W_16180_50_ivy_M.jpg, W_10817_60_mods_M.jpg]  \n",
              "18             [W_00815_19_normcore_M.jpg, W_07001_19_normcore_M.jpg, W_02855_10_sportivecasual_M.jpg, W_17207_00_metrosexual_M.jpg, W_15623_70_hippie_M.jpg, W_15270_60_mods_M.jpg, W_00492_50_ivy_M.jpg, W_02740_50_ivy_M.jpg, W_15093_50_ivy_M.jpg]  \n",
              "19            [W_07373_19_normcore_M.jpg, W_17262_19_normcore_M.jpg, W_17688_19_normcore_M.jpg, W_11011_80_bold_M.jpg, W_12408_90_hiphop_M.jpg, W_16806_00_metrosexual_M.jpg, W_04632_90_hiphop_M.jpg, W_07123_70_hippie_M.jpg, W_10122_60_mods_M.jpg]  \n",
              "20                                                                                                                                    [W_17009_19_normcore_M.jpg, W_16444_10_sportivecasual_M.jpg, W_15843_00_metrosexual_M.jpg, W_10066_50_ivy_M.jpg]  \n",
              "21                               [W_16412_10_sportivecasual_M.jpg, W_12650_90_hiphop_M.jpg, W_11143_00_metrosexual_M.jpg, W_15276_00_metrosexual_M.jpg, W_17443_90_hiphop_M.jpg, W_15651_70_hippie_M.jpg, W_17779_80_bold_M.jpg, W_15080_50_ivy_M.jpg]  \n",
              "22                                                                    [W_31918_19_normcore_M.jpg, W_25452_19_normcore_M.jpg, W_32426_70_hippie_M.jpg, W_15666_90_hiphop_M.jpg, W_26288_70_hippie_M.jpg, W_24486_70_hippie_M.jpg, W_24931_50_ivy_M.jpg]  \n",
              "23        [W_29383_10_sportivecasual_M.jpg, W_31502_19_normcore_M.jpg, W_32860_80_bold_M.jpg, W_16985_70_hippie_M.jpg, W_11145_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_24059_50_ivy_M.jpg, W_25406_00_metrosexual_M.jpg, W_24180_60_mods_M.jpg]  \n",
              "24                                                                                                                                      [W_11262_00_oriental_W.jpg, W_31881_80_powersuit_W.jpg, W_27619_80_powersuit_W.jpg, W_02442_50_feminine_W.jpg]  \n",
              "25                                                                                                                [T_15462_10_sportivecasual_M.jpg, T_15443_10_sportivecasual_M.jpg, T_15441_10_sportivecasual_M.jpg, T_09788_10_sportivecasual_M.jpg]  \n",
              "26                                                                                                                                                                    [W_07130_19_normcore_M.jpg, W_24845_80_bold_M.jpg, W_16659_00_metrosexual_M.jpg]  \n",
              "27                                                                                                       [W_26359_19_normcore_M.jpg, W_25835_10_sportivecasual_M.jpg, W_29485_10_sportivecasual_M.jpg, W_24886_70_hippie_M.jpg, W_24769_60_mods_M.jpg]  \n",
              "28                                                                                                                                        [W_12634_10_sportivecasual_M.jpg, W_04406_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_10814_50_ivy_M.jpg]  \n",
              "29                                                                                                              [W_19430_00_oriental_W.jpg, W_07717_90_kitsch_W.jpg, W_14147_70_disco_W.jpg, W_08511_80_bodyconscious_W.jpg, W_08670_50_classic_W.jpg]  \n",
              "30                                                                [W_32383_00_metrosexual_M.jpg, W_15666_90_hiphop_M.jpg, W_24569_70_hippie_M.jpg, W_12265_00_metrosexual_M.jpg, W_24492_70_hippie_M.jpg, W_17353_50_ivy_M.jpg, W_01726_60_mods_M.jpg]  \n",
              "31                                                                                                 [W_06253_90_hiphop_M.jpg, W_16681_70_hippie_M.jpg, W_07095_00_metrosexual_M.jpg, W_12552_80_bold_M.jpg, W_15125_50_ivy_M.jpg, W_17353_50_ivy_M.jpg]  \n",
              "32                        [W_09007_19_normcore_W.jpg, W_11504_19_lounge_W.jpg, W_01166_10_sportivecasual_W.jpg, W_19061_90_kitsch_W.jpg, W_08180_80_bodyconscious_W.jpg, W_19838_60_popart_W.jpg, W_14259_50_feminine_W.jpg, W_18729_50_classic_W.jpg]  \n",
              "33                                                                                                                                             [W_12487_90_hiphop_M.jpg, W_01509_00_metrosexual_M.jpg, W_15884_80_bold_M.jpg, W_06563_70_hippie_M.jpg]  \n",
              "34                                                                          [W_07715_19_normcore_W.jpg, W_05652_10_athleisure_W.jpg, W_03717_10_athleisure_W.jpg, W_07675_80_bodyconscious_W.jpg, W_19301_50_feminine_W.jpg, W_14997_60_minimal_W.jpg]  \n",
              "35                                                                                                                                                               [W_08838_10_athleisure_W.jpg, W_03787_80_bodyconscious_W.jpg, W_14345_60_space_W.jpg]  \n",
              "36                                                                                                                                        [W_15116_00_metrosexual_M.jpg, W_04484_90_hiphop_M.jpg, W_11144_00_metrosexual_M.jpg, W_10079_60_mods_M.jpg]  \n",
              "37                                                                                                                   [W_28801_19_normcore_M.jpg, W_28741_19_normcore_M.jpg, W_01799_00_metrosexual_M.jpg, W_16259_80_bold_M.jpg, W_32131_50_ivy_M.jpg]  \n",
              "38                                                    [W_31360_19_normcore_M.jpg, W_30015_00_metrosexual_M.jpg, W_29830_90_hiphop_M.jpg, W_28319_90_hiphop_M.jpg, W_11080_00_metrosexual_M.jpg, W_06665_00_metrosexual_M.jpg, W_24348_70_hippie_M.jpg]  \n",
              "39                                                                                                                                                                  [W_34027_10_sportivecasual_W.jpg, W_42376_90_grunge_W.jpg, W_30932_70_disco_W.jpg]  \n",
              "40                                                                 [W_26315_19_normcore_M.jpg, W_01898_19_normcore_M.jpg, W_57822_90_hiphop_M.jpg, W_52693_00_metrosexual_M.jpg, W_16063_80_bold_M.jpg, W_62525_90_hiphop_M.jpg, W_66114_50_ivy_M.jpg]  \n",
              "41                                                                                                     [W_56334_10_sportivecasual_W.jpg, W_68199_10_sportivecasual_W.jpg, W_34173_19_normcore_W.jpg, W_38863_60_minimal_W.jpg, W_37404_60_space_W.jpg]  \n",
              "42                                                                                                                                                                                              [W_03461_19_normcore_W.jpg, W_12033_00_cityglam_W.jpg]  \n",
              "43                                                                                                                                               [W_15443_70_hippie_M.jpg, W_15091_80_bold_M.jpg, W_15511_00_metrosexual_M.jpg, W_17893_80_bold_M.jpg]  \n",
              "44                                                                                                                                                          [W_16435_10_sportivecasual_M.jpg, W_18545_19_normcore_M.jpg, W_12593_00_metrosexual_M.jpg]  \n",
              "45                                                                                                                                                                  [W_08092_90_hiphop_W.jpg, W_05246_80_bodyconscious_W.jpg, W_19742_60_popart_W.jpg]  \n",
              "46                                                                                                                                      [W_18644_19_genderless_W.jpg, W_14410_19_genderless_W.jpg, W_03430_90_lingerie_W.jpg, W_18462_90_kitsch_W.jpg]  \n",
              "47                                                                                                               [W_11141_19_normcore_M.jpg, W_04573_10_sportivecasual_M.jpg, W_12476_90_hiphop_M.jpg, W_16676_90_hiphop_M.jpg, W_15120_60_mods_M.jpg]  \n",
              "48                                                      [W_17916_10_sportivecasual_M.jpg, W_11085_19_normcore_M.jpg, W_03044_19_normcore_M.jpg, W_12564_00_metrosexual_M.jpg, W_06759_90_hiphop_M.jpg, W_12120_80_bold_M.jpg, W_05879_70_hippie_M.jpg]  \n",
              "49                                                                                                                                      [W_11796_19_genderless_W.jpg, W_19165_00_cityglam_W.jpg, W_11950_00_oriental_W.jpg, W_19177_50_feminine_W.jpg]  \n",
              "50                                                                                                                                                                        [W_18878_19_genderless_W.jpg, W_00631_70_disco_W.jpg, W_19921_70_punk_W.jpg]  \n",
              "51                                                                                                                 [W_05472_10_sportivecasual_W.jpg, W_01326_10_sportivecasual_W.jpg, W_01390_10_sportivecasual_W.jpg, W_14273_80_bodyconscious_W.jpg]  \n",
              "52                                                                                                          [W_18199_19_normcore_W.jpg, W_01334_19_normcore_W.jpg, W_03258_00_ecology_W.jpg, W_04031_80_bodyconscious_W.jpg, W_18549_60_minimal_W.jpg]  \n",
              "53                                                                                                               [W_26946_19_lounge_W.jpg, W_41279_19_genderless_W.jpg, W_32248_80_powersuit_W.jpg, W_02232_70_hippie_W.jpg, W_33622_60_minimal_W.jpg]  \n",
              "54                       [W_22067_19_normcore_W.jpg, W_41537_10_sportivecasual_W.jpg, W_46905_80_powersuit_W.jpg, W_46562_80_powersuit_W.jpg, W_20551_70_hippie_W.jpg, W_40817_70_military_W.jpg, W_34872_70_military_W.jpg, W_22856_60_minimal_W.jpg]  \n",
              "55                                                                                                                                                                     [W_47169_70_hippie_W.jpg, W_14102_50_feminine_W.jpg, W_02498_50_feminine_W.jpg]  \n",
              "56                                                                                                                                                                                                       [T_06076_60_mods_M.jpg, W_51757_50_ivy_M.jpg]  \n",
              "57                                                                                                                   [W_14380_90_hiphop_W.jpg, W_00344_90_grunge_W.jpg, W_08112_90_hiphop_W.jpg, W_18658_80_powersuit_W.jpg, W_13271_60_minimal_W.jpg]  \n",
              "58                                                                                                                 [W_11868_90_grunge_W.jpg, W_13238_80_powersuit_W.jpg, W_00148_60_popart_W.jpg, W_18730_50_feminine_W.jpg, W_06318_50_classic_W.jpg]  \n",
              "59                                                                                                                             [W_09860_10_sportivecasual_M.jpg, W_22928_10_sportivecasual_M.jpg, W_24917_80_bold_M.jpg, W_55201_00_metrosexual_M.jpg]  \n",
              "60                                                                                                                                                                         [W_50293_19_normcore_W.jpg, W_43573_90_hiphop_W.jpg, W_42046_70_punk_W.jpg]  \n",
              "61                                                                                                                                                                         [W_16695_19_normcore_M.jpg, W_12345_80_bold_M.jpg, W_16014_70_hippie_M.jpg]  \n",
              "62                                   [W_02966_10_sportivecasual_M.jpg, W_24995_10_sportivecasual_M.jpg, W_04363_10_sportivecasual_M.jpg, W_07364_00_metrosexual_M.jpg, W_24403_00_metrosexual_M.jpg, W_32257_90_hiphop_M.jpg, W_12504_90_hiphop_M.jpg]  \n",
              "63                                                                                                                  [W_17108_19_normcore_M.jpg, W_06691_10_sportivecasual_M.jpg, W_15517_70_hippie_M.jpg, W_15140_80_bold_M.jpg, W_12904_50_ivy_M.jpg]  \n",
              "64                                                                                                                                                                                                                                                  []  \n",
              "65                                                       [W_00191_10_sportivecasual_W.jpg, W_08047_90_hiphop_W.jpg, W_13399_90_kitsch_W.jpg, W_05957_70_disco_W.jpg, W_14310_80_powersuit_W.jpg, W_01956_50_feminine_W.jpg, W_01187_50_feminine_W.jpg]  \n",
              "66                                                                                                                                                  [W_15974_80_bold_M.jpg, W_16380_80_bold_M.jpg, W_04273_00_metrosexual_M.jpg, W_10779_50_ivy_M.jpg]  \n",
              "67                                                                                                 [W_01687_19_normcore_M.jpg, W_15815_70_hippie_M.jpg, W_24958_90_hiphop_M.jpg, W_07324_50_ivy_M.jpg, W_02736_60_mods_M.jpg, W_02715_70_hippie_M.jpg]  \n",
              "68                                                                                                                                                                        [W_24903_80_bold_M.jpg, W_26093_00_metrosexual_M.jpg, W_26631_80_bold_M.jpg]  \n",
              "69                                                                                                                                                     [W_02777_90_hiphop_M.jpg, W_15568_70_hippie_M.jpg, W_12459_50_ivy_M.jpg, W_15157_60_mods_M.jpg]  \n",
              "70                                                                                                                                                                       [W_12593_00_metrosexual_M.jpg, W_15795_70_hippie_M.jpg, W_06537_50_ivy_M.jpg]  \n",
              "71                                                                                    [W_17728_10_sportivecasual_M.jpg, W_12658_00_metrosexual_M.jpg, W_17252_50_ivy_M.jpg, W_15119_00_metrosexual_M.jpg, W_16962_60_mods_M.jpg, W_10075_50_ivy_M.jpg]  \n",
              "72                                                                                                                   [W_10791_19_normcore_M.jpg, W_16203_90_hiphop_M.jpg, W_15596_70_hippie_M.jpg, W_15388_00_metrosexual_M.jpg, W_06735_50_ivy_M.jpg]  \n",
              "73                                                                                                                                                   [W_16367_90_hiphop_M.jpg, W_00803_50_ivy_M.jpg, W_06686_70_hippie_M.jpg, W_11024_70_hippie_M.jpg]  \n",
              "74                                                                                                                                                                    [W_13958_00_cityglam_W.jpg, W_03529_90_grunge_W.jpg, W_06147_80_powersuit_W.jpg]  \n",
              "75                                                                                                                                                                                                                   [W_00754_10_sportivecasual_W.jpg]  \n",
              "76                                                                                                                                                               [W_18943_80_powersuit_W.jpg, W_11938_70_hippie_W.jpg, W_01955_80_bodyconscious_W.jpg]  \n",
              "77                                                                                        [W_17812_10_sportivecasual_M.jpg, W_10851_19_normcore_M.jpg, W_16930_19_normcore_M.jpg, W_15987_70_hippie_M.jpg, W_12807_50_ivy_M.jpg, W_16189_50_ivy_M.jpg]  \n",
              "78                                                                                                                                           [W_18618_80_powersuit_W.jpg, W_02282_70_hippie_W.jpg, W_08501_70_hippie_W.jpg, W_14852_50_feminine_W.jpg]  \n",
              "79                                                                                                                                                                         [W_16460_19_normcore_M.jpg, W_16039_70_hippie_M.jpg, W_12336_80_bold_M.jpg]  \n",
              "80                                                                                                                                              [W_19492_00_ecology_W.jpg, W_18797_70_disco_W.jpg, W_19750_70_hippie_W.jpg, W_18508_50_feminine_W.jpg]  \n",
              "81                                                                                                   [W_18335_00_oriental_W.jpg, W_14378_10_sportivecasual_W.jpg, W_11421_00_ecology_W.jpg, W_14221_80_bodyconscious_W.jpg, W_02047_50_feminine_W.jpg]  \n",
              "82                                                                                                                                                                   [W_27174_10_sportivecasual_M.jpg, W_16291_80_bold_M.jpg, W_15762_70_hippie_M.jpg]  \n",
              "83                                                                                                                                                 [W_32608_70_hippie_M.jpg, W_04510_00_metrosexual_M.jpg, W_30290_50_ivy_M.jpg, W_24101_50_ivy_M.jpg]  \n",
              "84                                                                                                                                                [W_21401_00_metrosexual_M.jpg, W_24357_70_hippie_M.jpg, W_33002_60_mods_M.jpg, W_32459_50_ivy_M.jpg]  \n",
              "85                                                                                                                                         [W_15920_00_metrosexual_M.jpg, W_24347_00_metrosexual_M.jpg, W_25202_90_hiphop_M.jpg, W_27903_50_ivy_M.jpg]  \n",
              "86                                                                                                                                                                                                                           [W_25721_90_hiphop_M.jpg]  \n",
              "87                                                                                                                                       [T_11421_00_cityglam_W.jpg, W_55996_90_lingerie_W.jpg, T_07471_80_bodyconscious_W.jpg, W_33100_70_punk_W.jpg]  \n",
              "88                                                                                                                                                        [W_15438_70_hippie_M.jpg, W_04677_50_ivy_M.jpg, W_12866_60_mods_M.jpg, W_10082_50_ivy_M.jpg]  \n",
              "89                                                                                                       [W_07025_10_sportivecasual_M.jpg, W_28443_10_sportivecasual_M.jpg, W_24557_19_normcore_M.jpg, W_06805_90_hiphop_M.jpg, W_24142_60_mods_M.jpg]  \n",
              "90                                                                                                                                                                                 [W_12309_80_bold_M.jpg, W_09835_50_ivy_M.jpg, W_15479_50_ivy_M.jpg]  \n",
              "91                                                                                                                                                                  [W_25106_00_metrosexual_M.jpg, W_26001_00_metrosexual_M.jpg, W_04302_50_ivy_M.jpg]  \n",
              "92                                                                                                                                   [W_63956_80_powersuit_W.jpg, W_13086_80_powersuit_W.jpg, W_13952_80_bodyconscious_W.jpg, W_34247_70_hippie_W.jpg]  \n",
              "93                                                                                                                                                                                                                    [W_08246_80_bodyconscious_W.jpg]  \n",
              "94                                                                                                                                                                                            [W_05586_80_bodyconscious_W.jpg, W_14299_70_disco_W.jpg]  \n",
              "95                                                                                                                                                                                                        [W_10796_50_ivy_M.jpg, W_15404_50_ivy_M.jpg]  \n",
              "96                                                                                                                                                                    [W_25941_10_sportivecasual_M.jpg, W_15586_70_hippie_M.jpg, W_26584_50_ivy_M.jpg]  \n",
              "97                                                                                                                                                                        [W_05818_90_lingerie_W.jpg, W_44650_90_kitsch_W.jpg, W_42705_70_disco_W.jpg]  \n",
              "98                                                                                                                                                                                                                           [W_15503_70_hippie_M.jpg]  \n",
              "99                                                                                                                                                                              [W_06617_90_hiphop_M.jpg, W_15124_80_bold_M.jpg, W_06511_50_ivy_M.jpg]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-23957c34-e95a-4470-9ee0-6cfd5c8d15e9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>응답자 ID</th>\n",
              "      <th>Training 스타일 선호</th>\n",
              "      <th>Training 스타일 비선호</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21432</td>\n",
              "      <td>[W_28523_90_hiphop_M.jpg, W_09891_90_hiphop_M.jpg, W_29023_00_metrosexual_M.jpg, W_15294_50_ivy_M.jpg, W_32448_50_ivy_M.jpg]</td>\n",
              "      <td>[W_29224_10_sportivecasual_M.jpg, W_26017_10_sportivecasual_M.jpg, W_26151_80_bold_M.jpg, W_26296_70_hippie_M.jpg, W_12383_80_bold_M.jpg, W_24439_00_metrosexual_M.jpg, W_26397_70_hippie_M.jpg, W_25107_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>60234</td>\n",
              "      <td>[W_01693_19_normcore_M.jpg, W_17337_50_ivy_M.jpg, W_16539_50_ivy_M.jpg, W_07102_50_ivy_M.jpg, W_12748_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17508_80_bold_M.jpg, W_02844_90_hiphop_M.jpg, W_16755_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_16673_70_hippie_M.jpg, W_15423_80_bold_M.jpg, W_06546_60_mods_M.jpg, W_15259_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>62264</td>\n",
              "      <td>[W_07260_10_sportivecasual_M.jpg, W_16449_10_sportivecasual_M.jpg, W_16403_10_sportivecasual_M.jpg, W_07098_19_normcore_M.jpg, W_07307_19_normcore_M.jpg, W_05869_60_mods_M.jpg]</td>\n",
              "      <td>[W_16136_80_bold_M.jpg, W_15477_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_16428_90_hiphop_M.jpg, W_16189_50_ivy_M.jpg, W_16189_50_ivy_M.jpg, W_04233_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>64345</td>\n",
              "      <td>[W_28449_10_sportivecasual_M.jpg, W_17467_19_normcore_M.jpg, W_00843_10_sportivecasual_M.jpg, W_29596_10_sportivecasual_M.jpg, W_27156_90_hiphop_M.jpg, W_32150_00_metrosexual_M.jpg, W_15856_60_mods_M.jpg, W_24155_60_mods_M.jpg]</td>\n",
              "      <td>[W_24825_80_bold_M.jpg, W_25884_90_hiphop_M.jpg, W_11105_00_metrosexual_M.jpg, W_24352_70_hippie_M.jpg, W_24325_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>63740</td>\n",
              "      <td>[W_04201_19_lounge_W.jpg, W_01179_10_sportivecasual_W.jpg, W_11824_70_military_W.jpg, W_14975_60_minimal_W.jpg, W_18894_50_feminine_W.jpg]</td>\n",
              "      <td>[W_05226_10_sportivecasual_W.jpg, W_08607_90_kitsch_W.jpg, W_19264_90_kitsch_W.jpg, W_03656_90_hiphop_W.jpg, W_05353_80_bodyconscious_W.jpg, W_06083_80_bodyconscious_W.jpg, W_07532_70_hippie_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>64221</td>\n",
              "      <td>[W_28698_10_sportivecasual_M.jpg, W_25039_90_hiphop_M.jpg, W_32524_00_metrosexual_M.jpg, W_28728_50_ivy_M.jpg, W_24013_60_mods_M.jpg]</td>\n",
              "      <td>[W_26397_70_hippie_M.jpg, W_25471_70_hippie_M.jpg, W_12130_80_bold_M.jpg, W_28207_90_hiphop_M.jpg, W_17747_80_bold_M.jpg, W_15129_50_ivy_M.jpg, W_07333_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>64460</td>\n",
              "      <td>[W_24294_80_bold_M.jpg, W_24934_90_hiphop_M.jpg, W_26530_00_metrosexual_M.jpg, W_06514_80_bold_M.jpg, W_10792_50_ivy_M.jpg, W_12817_50_ivy_M.jpg, W_15653_60_mods_M.jpg]</td>\n",
              "      <td>[W_25069_90_hiphop_M.jpg, W_31356_80_bold_M.jpg, W_25082_70_hippie_M.jpg, W_30522_00_metrosexual_M.jpg, W_25526_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>28912</td>\n",
              "      <td>[W_01754_10_sportivecasual_M.jpg, W_04680_10_sportivecasual_M.jpg, W_02669_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17260_19_normcore_M.jpg, W_16725_70_hippie_M.jpg, W_15745_80_bold_M.jpg, W_04723_90_hiphop_M.jpg, W_15923_80_bold_M.jpg, W_04242_60_mods_M.jpg, W_15246_50_ivy_M.jpg, W_03007_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>60184</td>\n",
              "      <td>[W_01687_19_normcore_M.jpg, W_17427_00_metrosexual_M.jpg, W_17348_50_ivy_M.jpg]</td>\n",
              "      <td>[W_12453_10_sportivecasual_M.jpg, W_12095_80_bold_M.jpg, W_28377_80_bold_M.jpg, W_27913_00_metrosexual_M.jpg, W_25030_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_16016_70_hippie_M.jpg, W_04245_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>62525</td>\n",
              "      <td>[W_00760_19_normcore_W.jpg, W_05751_10_sportivecasual_W.jpg, W_19165_00_cityglam_W.jpg, W_03477_80_powersuit_W.jpg, W_01207_60_minimal_W.jpg, W_11223_60_popart_W.jpg, W_13104_50_classic_W.jpg, W_18495_50_feminine_W.jpg]</td>\n",
              "      <td>[W_13667_00_oriental_W.jpg, W_08167_60_minimal_W.jpg, W_07447_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>63545</td>\n",
              "      <td>[W_08322_19_normcore_W.jpg, W_14897_10_sportivecasual_W.jpg, W_04993_70_hippie_W.jpg, W_03842_50_feminine_W.jpg]</td>\n",
              "      <td>[W_04035_19_normcore_W.jpg, W_08610_90_grunge_W.jpg, W_19342_70_hippie_W.jpg, W_10655_50_feminine_W.jpg, W_12003_60_minimal_W.jpg, W_13846_60_minimal_W.jpg, W_10981_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>63583</td>\n",
              "      <td>[W_02100_00_oriental_W.jpg, W_00385_50_feminine_W.jpg]</td>\n",
              "      <td>[W_10223_00_oriental_W.jpg, W_18920_00_oriental_W.jpg, W_03693_10_athleisure_W.jpg, W_01248_90_hiphop_W.jpg, W_18030_90_kitsch_W.jpg, W_19311_70_punk_W.jpg, W_19964_80_powersuit_W.jpg, W_18543_60_popart_W.jpg, W_04901_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>63934</td>\n",
              "      <td>[W_16255_19_normcore_M.jpg, W_12327_80_bold_M.jpg]</td>\n",
              "      <td>[W_01630_10_sportivecasual_M.jpg, W_10791_19_normcore_M.jpg, W_16236_80_bold_M.jpg, W_11063_00_metrosexual_M.jpg, W_02755_90_hiphop_M.jpg, W_01794_00_metrosexual_M.jpg, W_15669_00_metrosexual_M.jpg, W_17603_50_ivy_M.jpg, W_06259_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>66592</td>\n",
              "      <td>[W_46907_80_powersuit_W.jpg, W_53583_90_hiphop_W.jpg, W_53861_90_kitsch_W.jpg, W_53133_90_hiphop_W.jpg, W_44918_60_minimal_W.jpg, W_02343_60_space_W.jpg]</td>\n",
              "      <td>[W_52969_00_ecology_W.jpg, W_51690_80_powersuit_W.jpg, W_52731_90_kitsch_W.jpg, W_41924_70_punk_W.jpg, W_47960_60_popart_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>60173</td>\n",
              "      <td>[W_14216_10_sportivecasual_W.jpg, W_08869_10_sportivecasual_W.jpg, W_05458_10_athleisure_W.jpg, W_07964_70_military_W.jpg, W_14099_50_classic_W.jpg, W_09079_60_popart_W.jpg]</td>\n",
              "      <td>[W_19273_00_ecology_W.jpg, W_07408_90_lingerie_W.jpg, W_06402_80_powersuit_W.jpg, W_09497_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>63207</td>\n",
              "      <td>[W_02771_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_00505_10_sportivecasual_M.jpg, W_16390_10_sportivecasual_M.jpg, W_11033_90_hiphop_M.jpg, W_15634_80_bold_M.jpg, W_16684_00_metrosexual_M.jpg, W_16361_80_bold_M.jpg, W_09796_60_mods_M.jpg, W_10087_70_hippie_M.jpg, W_09132_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>63359</td>\n",
              "      <td>[W_00410_19_genderless_W.jpg, W_01958_00_cityglam_W.jpg, W_08140_50_feminine_W.jpg]</td>\n",
              "      <td>[W_10207_00_oriental_W.jpg, W_10289_00_oriental_W.jpg, W_13858_80_bodyconscious_W.jpg, W_13941_60_minimal_W.jpg, W_12019_50_feminine_W.jpg, W_19530_60_popart_W.jpg, W_07682_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>63508</td>\n",
              "      <td>[W_15768_19_normcore_M.jpg, W_15156_00_metrosexual_M.jpg, W_12698_80_bold_M.jpg, W_16295_70_hippie_M.jpg, W_15488_00_metrosexual_M.jpg]</td>\n",
              "      <td>[W_07043_10_sportivecasual_M.jpg, W_13458_80_bold_M.jpg, W_11071_00_metrosexual_M.jpg, W_16180_50_ivy_M.jpg, W_10817_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>63571</td>\n",
              "      <td>[W_04649_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_00815_19_normcore_M.jpg, W_07001_19_normcore_M.jpg, W_02855_10_sportivecasual_M.jpg, W_17207_00_metrosexual_M.jpg, W_15623_70_hippie_M.jpg, W_15270_60_mods_M.jpg, W_00492_50_ivy_M.jpg, W_02740_50_ivy_M.jpg, W_15093_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>63769</td>\n",
              "      <td>[W_09795_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_07373_19_normcore_M.jpg, W_17262_19_normcore_M.jpg, W_17688_19_normcore_M.jpg, W_11011_80_bold_M.jpg, W_12408_90_hiphop_M.jpg, W_16806_00_metrosexual_M.jpg, W_04632_90_hiphop_M.jpg, W_07123_70_hippie_M.jpg, W_10122_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>63913</td>\n",
              "      <td>[W_00553_10_sportivecasual_M.jpg, W_07066_10_sportivecasual_M.jpg, W_07255_50_ivy_M.jpg, W_07150_70_hippie_M.jpg, W_06573_60_mods_M.jpg, W_06883_60_mods_M.jpg]</td>\n",
              "      <td>[W_17009_19_normcore_M.jpg, W_16444_10_sportivecasual_M.jpg, W_15843_00_metrosexual_M.jpg, W_10066_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>63927</td>\n",
              "      <td>[W_06824_19_normcore_M.jpg, W_06531_60_mods_M.jpg]</td>\n",
              "      <td>[W_16412_10_sportivecasual_M.jpg, W_12650_90_hiphop_M.jpg, W_11143_00_metrosexual_M.jpg, W_15276_00_metrosexual_M.jpg, W_17443_90_hiphop_M.jpg, W_15651_70_hippie_M.jpg, W_17779_80_bold_M.jpg, W_15080_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>64216</td>\n",
              "      <td>[W_27674_10_sportivecasual_M.jpg, W_17855_90_hiphop_M.jpg, W_02816_60_mods_M.jpg]</td>\n",
              "      <td>[W_31918_19_normcore_M.jpg, W_25452_19_normcore_M.jpg, W_32426_70_hippie_M.jpg, W_15666_90_hiphop_M.jpg, W_26288_70_hippie_M.jpg, W_24486_70_hippie_M.jpg, W_24931_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>64571</td>\n",
              "      <td>[W_00794_19_normcore_M.jpg]</td>\n",
              "      <td>[W_29383_10_sportivecasual_M.jpg, W_31502_19_normcore_M.jpg, W_32860_80_bold_M.jpg, W_16985_70_hippie_M.jpg, W_11145_00_metrosexual_M.jpg, W_18424_80_bold_M.jpg, W_24059_50_ivy_M.jpg, W_25406_00_metrosexual_M.jpg, W_24180_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>64598</td>\n",
              "      <td>[W_48074_10_sportivecasual_W.jpg, W_21732_10_sportivecasual_W.jpg, W_27930_80_powersuit_W.jpg, W_00638_90_hiphop_W.jpg, W_04895_50_classic_W.jpg, W_09961_50_feminine_W.jpg]</td>\n",
              "      <td>[W_11262_00_oriental_W.jpg, W_31881_80_powersuit_W.jpg, W_27619_80_powersuit_W.jpg, W_02442_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>68891</td>\n",
              "      <td>[T_15458_10_sportivecasual_M.jpg, T_15453_10_sportivecasual_M.jpg, T_15468_10_sportivecasual_M.jpg, T_15477_10_sportivecasual_M.jpg, T_15488_10_sportivecasual_M.jpg, T_15467_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[T_15462_10_sportivecasual_M.jpg, T_15443_10_sportivecasual_M.jpg, T_15441_10_sportivecasual_M.jpg, T_09788_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>837</td>\n",
              "      <td>[W_00829_10_sportivecasual_M.jpg, W_28209_10_sportivecasual_M.jpg, W_28211_19_normcore_M.jpg, W_28722_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg, W_25073_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_07130_19_normcore_M.jpg, W_24845_80_bold_M.jpg, W_16659_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>30790</td>\n",
              "      <td>[W_33023_10_sportivecasual_M.jpg, W_26425_90_hiphop_M.jpg, W_06511_50_ivy_M.jpg, W_06863_60_mods_M.jpg]</td>\n",
              "      <td>[W_26359_19_normcore_M.jpg, W_25835_10_sportivecasual_M.jpg, W_29485_10_sportivecasual_M.jpg, W_24886_70_hippie_M.jpg, W_24769_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>35514</td>\n",
              "      <td>[W_01716_19_normcore_M.jpg, W_04539_10_sportivecasual_M.jpg, W_01645_90_hiphop_M.jpg, W_01664_60_mods_M.jpg, W_09152_60_mods_M.jpg]</td>\n",
              "      <td>[W_12634_10_sportivecasual_M.jpg, W_04406_00_metrosexual_M.jpg, W_15159_80_bold_M.jpg, W_10814_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>61104</td>\n",
              "      <td>[W_07906_00_ecology_W.jpg, W_08810_10_sportivecasual_W.jpg, W_04919_00_oriental_W.jpg, W_02487_10_athleisure_W.jpg]</td>\n",
              "      <td>[W_19430_00_oriental_W.jpg, W_07717_90_kitsch_W.jpg, W_14147_70_disco_W.jpg, W_08511_80_bodyconscious_W.jpg, W_08670_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>62155</td>\n",
              "      <td>[W_31063_19_normcore_M.jpg, W_27854_50_ivy_M.jpg]</td>\n",
              "      <td>[W_32383_00_metrosexual_M.jpg, W_15666_90_hiphop_M.jpg, W_24569_70_hippie_M.jpg, W_12265_00_metrosexual_M.jpg, W_24492_70_hippie_M.jpg, W_17353_50_ivy_M.jpg, W_01726_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>62349</td>\n",
              "      <td>[W_04689_10_sportivecasual_M.jpg, W_17802_80_bold_M.jpg, W_07101_60_mods_M.jpg]</td>\n",
              "      <td>[W_06253_90_hiphop_M.jpg, W_16681_70_hippie_M.jpg, W_07095_00_metrosexual_M.jpg, W_12552_80_bold_M.jpg, W_15125_50_ivy_M.jpg, W_17353_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>63156</td>\n",
              "      <td>[W_01318_10_athleisure_W.jpg]</td>\n",
              "      <td>[W_09007_19_normcore_W.jpg, W_11504_19_lounge_W.jpg, W_01166_10_sportivecasual_W.jpg, W_19061_90_kitsch_W.jpg, W_08180_80_bodyconscious_W.jpg, W_19838_60_popart_W.jpg, W_14259_50_feminine_W.jpg, W_18729_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>63369</td>\n",
              "      <td>[W_03000_19_normcore_M.jpg, W_09785_19_normcore_M.jpg, W_01428_10_sportivecasual_M.jpg, W_04733_90_hiphop_M.jpg, W_09760_60_mods_M.jpg]</td>\n",
              "      <td>[W_12487_90_hiphop_M.jpg, W_01509_00_metrosexual_M.jpg, W_15884_80_bold_M.jpg, W_06563_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>63424</td>\n",
              "      <td>[W_19801_19_genderless_W.jpg, W_09698_19_genderless_W.jpg, W_01962_60_minimal_W.jpg]</td>\n",
              "      <td>[W_07715_19_normcore_W.jpg, W_05652_10_athleisure_W.jpg, W_03717_10_athleisure_W.jpg, W_07675_80_bodyconscious_W.jpg, W_19301_50_feminine_W.jpg, W_14997_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>63435</td>\n",
              "      <td>[W_08285_19_normcore_W.jpg, W_19407_19_normcore_W.jpg, W_01041_10_sportivecasual_W.jpg, W_19010_00_oriental_W.jpg, W_18401_90_lingerie_W.jpg, W_04192_60_minimal_W.jpg]</td>\n",
              "      <td>[W_08838_10_athleisure_W.jpg, W_03787_80_bodyconscious_W.jpg, W_14345_60_space_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>63748</td>\n",
              "      <td>[W_02890_19_normcore_M.jpg, W_00829_10_sportivecasual_M.jpg, W_15268_50_ivy_M.jpg, W_10092_60_mods_M.jpg, W_17867_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15116_00_metrosexual_M.jpg, W_04484_90_hiphop_M.jpg, W_11144_00_metrosexual_M.jpg, W_10079_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>64310</td>\n",
              "      <td>[W_26375_70_hippie_M.jpg, W_16007_70_hippie_M.jpg, W_25934_90_hiphop_M.jpg, W_04692_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_28801_19_normcore_M.jpg, W_28741_19_normcore_M.jpg, W_01799_00_metrosexual_M.jpg, W_16259_80_bold_M.jpg, W_32131_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>64397</td>\n",
              "      <td>[W_17793_19_normcore_M.jpg, W_24889_50_ivy_M.jpg]</td>\n",
              "      <td>[W_31360_19_normcore_M.jpg, W_30015_00_metrosexual_M.jpg, W_29830_90_hiphop_M.jpg, W_28319_90_hiphop_M.jpg, W_11080_00_metrosexual_M.jpg, W_06665_00_metrosexual_M.jpg, W_24348_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>64503</td>\n",
              "      <td>[W_43214_19_genderless_W.jpg, W_45353_80_powersuit_W.jpg, W_40718_90_hiphop_W.jpg, W_43570_90_hiphop_W.jpg, W_36275_60_minimal_W.jpg, W_07755_50_feminine_W.jpg]</td>\n",
              "      <td>[W_34027_10_sportivecasual_W.jpg, W_42376_90_grunge_W.jpg, W_30932_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>65139</td>\n",
              "      <td>[W_64254_19_normcore_M.jpg, W_16523_19_normcore_M.jpg]</td>\n",
              "      <td>[W_26315_19_normcore_M.jpg, W_01898_19_normcore_M.jpg, W_57822_90_hiphop_M.jpg, W_52693_00_metrosexual_M.jpg, W_16063_80_bold_M.jpg, W_62525_90_hiphop_M.jpg, W_66114_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>66513</td>\n",
              "      <td>[W_60789_90_lingerie_W.jpg, W_44554_90_grunge_W.jpg, W_35544_60_minimal_W.jpg, W_19031_50_classic_W.jpg]</td>\n",
              "      <td>[W_56334_10_sportivecasual_W.jpg, W_68199_10_sportivecasual_W.jpg, W_34173_19_normcore_W.jpg, W_38863_60_minimal_W.jpg, W_37404_60_space_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>9096</td>\n",
              "      <td>[W_03582_19_normcore_W.jpg, W_03784_00_cityglam_W.jpg, W_08797_70_disco_W.jpg, W_14507_60_minimal_W.jpg, W_03160_60_minimal_W.jpg, W_19987_50_feminine_W.jpg]</td>\n",
              "      <td>[W_03461_19_normcore_W.jpg, W_12033_00_cityglam_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>22324</td>\n",
              "      <td>[W_04372_10_sportivecasual_M.jpg, W_07347_90_hiphop_M.jpg, W_17700_00_metrosexual_M.jpg, W_02696_60_mods_M.jpg]</td>\n",
              "      <td>[W_15443_70_hippie_M.jpg, W_15091_80_bold_M.jpg, W_15511_00_metrosexual_M.jpg, W_17893_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>59083</td>\n",
              "      <td>[W_09799_19_normcore_M.jpg, W_06836_00_metrosexual_M.jpg, W_06547_00_metrosexual_M.jpg, W_10803_80_bold_M.jpg, W_15367_60_mods_M.jpg]</td>\n",
              "      <td>[W_16435_10_sportivecasual_M.jpg, W_18545_19_normcore_M.jpg, W_12593_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>59523</td>\n",
              "      <td>[W_09060_19_normcore_W.jpg, W_05673_10_sportivecasual_W.jpg, W_09533_90_grunge_W.jpg, W_05690_70_punk_W.jpg, W_18661_60_minimal_W.jpg]</td>\n",
              "      <td>[W_08092_90_hiphop_W.jpg, W_05246_80_bodyconscious_W.jpg, W_19742_60_popart_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>59637</td>\n",
              "      <td>[W_00784_19_normcore_W.jpg, W_08042_10_athleisure_W.jpg, W_09626_10_athleisure_W.jpg, W_03580_60_minimal_W.jpg]</td>\n",
              "      <td>[W_18644_19_genderless_W.jpg, W_14410_19_genderless_W.jpg, W_03430_90_lingerie_W.jpg, W_18462_90_kitsch_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>59704</td>\n",
              "      <td>[W_07211_00_metrosexual_M.jpg, W_04636_50_ivy_M.jpg, W_06558_60_mods_M.jpg]</td>\n",
              "      <td>[W_11141_19_normcore_M.jpg, W_04573_10_sportivecasual_M.jpg, W_12476_90_hiphop_M.jpg, W_16676_90_hiphop_M.jpg, W_15120_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>59812</td>\n",
              "      <td>[W_06672_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17916_10_sportivecasual_M.jpg, W_11085_19_normcore_M.jpg, W_03044_19_normcore_M.jpg, W_12564_00_metrosexual_M.jpg, W_06759_90_hiphop_M.jpg, W_12120_80_bold_M.jpg, W_05879_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>63316</td>\n",
              "      <td>[W_06484_19_lounge_W.jpg, W_05594_19_genderless_W.jpg, W_05580_10_sportivecasual_W.jpg, W_07586_60_minimal_W.jpg]</td>\n",
              "      <td>[W_11796_19_genderless_W.jpg, W_19165_00_cityglam_W.jpg, W_11950_00_oriental_W.jpg, W_19177_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>63479</td>\n",
              "      <td>[W_09086_19_normcore_W.jpg, W_19413_00_oriental_W.jpg, W_14584_50_classic_W.jpg, W_18202_60_minimal_W.jpg, W_04994_60_popart_W.jpg]</td>\n",
              "      <td>[W_18878_19_genderless_W.jpg, W_00631_70_disco_W.jpg, W_19921_70_punk_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>63644</td>\n",
              "      <td>[W_05127_90_kitsch_W.jpg, W_03934_70_hippie_W.jpg, W_07688_70_disco_W.jpg, W_14787_60_minimal_W.jpg]</td>\n",
              "      <td>[W_05472_10_sportivecasual_W.jpg, W_01326_10_sportivecasual_W.jpg, W_01390_10_sportivecasual_W.jpg, W_14273_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>63759</td>\n",
              "      <td>[W_05821_90_kitsch_W.jpg, W_09611_10_sportivecasual_W.jpg, W_05715_70_military_W.jpg]</td>\n",
              "      <td>[W_18199_19_normcore_W.jpg, W_01334_19_normcore_W.jpg, W_03258_00_ecology_W.jpg, W_04031_80_bodyconscious_W.jpg, W_18549_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>64561</td>\n",
              "      <td>[W_36907_19_genderless_W.jpg, W_18759_50_feminine_W.jpg, W_18066_50_classic_W.jpg]</td>\n",
              "      <td>[W_26946_19_lounge_W.jpg, W_41279_19_genderless_W.jpg, W_32248_80_powersuit_W.jpg, W_02232_70_hippie_W.jpg, W_33622_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>64662</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_22067_19_normcore_W.jpg, W_41537_10_sportivecasual_W.jpg, W_46905_80_powersuit_W.jpg, W_46562_80_powersuit_W.jpg, W_20551_70_hippie_W.jpg, W_40817_70_military_W.jpg, W_34872_70_military_W.jpg, W_22856_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>64747</td>\n",
              "      <td>[W_39725_19_normcore_W.jpg, W_29783_10_sportivecasual_W.jpg, W_34636_00_oriental_W.jpg, W_04972_90_kitsch_W.jpg, W_21223_80_powersuit_W.jpg]</td>\n",
              "      <td>[W_47169_70_hippie_W.jpg, W_14102_50_feminine_W.jpg, W_02498_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>66469</td>\n",
              "      <td>[T_00456_10_sportivecasual_M.jpg, T_03772_90_hiphop_M.jpg, W_06657_60_mods_M.jpg, W_00486_60_mods_M.jpg, W_10810_60_mods_M.jpg, W_51362_50_ivy_M.jpg]</td>\n",
              "      <td>[T_06076_60_mods_M.jpg, W_51757_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>7658</td>\n",
              "      <td>[W_01234_10_sportivecasual_W.jpg, W_08708_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_14380_90_hiphop_W.jpg, W_00344_90_grunge_W.jpg, W_08112_90_hiphop_W.jpg, W_18658_80_powersuit_W.jpg, W_13271_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>20768</td>\n",
              "      <td>[W_09011_10_sportivecasual_W.jpg, W_18900_50_classic_W.jpg]</td>\n",
              "      <td>[W_11868_90_grunge_W.jpg, W_13238_80_powersuit_W.jpg, W_00148_60_popart_W.jpg, W_18730_50_feminine_W.jpg, W_06318_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>28371</td>\n",
              "      <td>[W_17461_19_normcore_M.jpg, W_57031_90_hiphop_M.jpg, W_25020_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_09860_10_sportivecasual_M.jpg, W_22928_10_sportivecasual_M.jpg, W_24917_80_bold_M.jpg, W_55201_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>61250</td>\n",
              "      <td>[W_62598_19_normcore_W.jpg, W_47873_70_punk_W.jpg, W_01933_50_feminine_W.jpg, W_13173_50_feminine_W.jpg]</td>\n",
              "      <td>[W_50293_19_normcore_W.jpg, W_43573_90_hiphop_W.jpg, W_42046_70_punk_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>61493</td>\n",
              "      <td>[W_04661_10_sportivecasual_M.jpg, W_02881_10_sportivecasual_M.jpg, W_02818_60_mods_M.jpg, W_04232_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16695_19_normcore_M.jpg, W_12345_80_bold_M.jpg, W_16014_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>61859</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_02966_10_sportivecasual_M.jpg, W_24995_10_sportivecasual_M.jpg, W_04363_10_sportivecasual_M.jpg, W_07364_00_metrosexual_M.jpg, W_24403_00_metrosexual_M.jpg, W_32257_90_hiphop_M.jpg, W_12504_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63405</td>\n",
              "      <td>[W_04684_90_hiphop_M.jpg, W_15400_60_mods_M.jpg]</td>\n",
              "      <td>[W_17108_19_normcore_M.jpg, W_06691_10_sportivecasual_M.jpg, W_15517_70_hippie_M.jpg, W_15140_80_bold_M.jpg, W_12904_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>63505</td>\n",
              "      <td>[W_11117_19_normcore_M.jpg, W_09186_10_sportivecasual_M.jpg, W_07078_10_sportivecasual_M.jpg, W_12328_80_bold_M.jpg, W_17803_80_bold_M.jpg, W_17907_00_metrosexual_M.jpg, W_12393_50_ivy_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>63742</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_00191_10_sportivecasual_W.jpg, W_08047_90_hiphop_W.jpg, W_13399_90_kitsch_W.jpg, W_05957_70_disco_W.jpg, W_14310_80_powersuit_W.jpg, W_01956_50_feminine_W.jpg, W_01187_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>63910</td>\n",
              "      <td>[W_17529_70_hippie_M.jpg, W_17962_50_ivy_M.jpg, W_00495_60_mods_M.jpg]</td>\n",
              "      <td>[W_15974_80_bold_M.jpg, W_16380_80_bold_M.jpg, W_04273_00_metrosexual_M.jpg, W_10779_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>64223</td>\n",
              "      <td>[W_04537_19_normcore_M.jpg]</td>\n",
              "      <td>[W_01687_19_normcore_M.jpg, W_15815_70_hippie_M.jpg, W_24958_90_hiphop_M.jpg, W_07324_50_ivy_M.jpg, W_02736_60_mods_M.jpg, W_02715_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>64364</td>\n",
              "      <td>[W_01472_19_normcore_M.jpg, W_32885_10_sportivecasual_M.jpg, W_16850_19_normcore_M.jpg, W_24141_50_ivy_M.jpg]</td>\n",
              "      <td>[W_24903_80_bold_M.jpg, W_26093_00_metrosexual_M.jpg, W_26631_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>368</td>\n",
              "      <td>[W_02804_19_normcore_M.jpg, W_06843_60_mods_M.jpg]</td>\n",
              "      <td>[W_02777_90_hiphop_M.jpg, W_15568_70_hippie_M.jpg, W_12459_50_ivy_M.jpg, W_15157_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>18730</td>\n",
              "      <td>[W_16362_80_bold_M.jpg, W_12196_80_bold_M.jpg, W_06847_60_mods_M.jpg]</td>\n",
              "      <td>[W_12593_00_metrosexual_M.jpg, W_15795_70_hippie_M.jpg, W_06537_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>28358</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17728_10_sportivecasual_M.jpg, W_12658_00_metrosexual_M.jpg, W_17252_50_ivy_M.jpg, W_15119_00_metrosexual_M.jpg, W_16962_60_mods_M.jpg, W_10075_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>28571</td>\n",
              "      <td>[W_12826_50_ivy_M.jpg]</td>\n",
              "      <td>[W_10791_19_normcore_M.jpg, W_16203_90_hiphop_M.jpg, W_15596_70_hippie_M.jpg, W_15388_00_metrosexual_M.jpg, W_06735_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>50277</td>\n",
              "      <td>[W_09792_10_sportivecasual_M.jpg, W_06909_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16367_90_hiphop_M.jpg, W_00803_50_ivy_M.jpg, W_06686_70_hippie_M.jpg, W_11024_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>59506</td>\n",
              "      <td>[W_02265_70_military_W.jpg, W_11218_50_feminine_W.jpg, W_13247_60_minimal_W.jpg]</td>\n",
              "      <td>[W_13958_00_cityglam_W.jpg, W_03529_90_grunge_W.jpg, W_06147_80_powersuit_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>62113</td>\n",
              "      <td>[W_02567_10_sportivecasual_W.jpg, W_04068_10_athleisure_W.jpg, W_10554_80_bodyconscious_W.jpg, W_08595_80_bodyconscious_W.jpg, W_09639_50_classic_W.jpg]</td>\n",
              "      <td>[W_00754_10_sportivecasual_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>62625</td>\n",
              "      <td>[W_09363_19_genderless_W.jpg, W_05247_90_hiphop_W.jpg, W_07950_70_military_W.jpg]</td>\n",
              "      <td>[W_18943_80_powersuit_W.jpg, W_11938_70_hippie_W.jpg, W_01955_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>62868</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17812_10_sportivecasual_M.jpg, W_10851_19_normcore_M.jpg, W_16930_19_normcore_M.jpg, W_15987_70_hippie_M.jpg, W_12807_50_ivy_M.jpg, W_16189_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>63430</td>\n",
              "      <td>[W_08809_19_lounge_W.jpg, W_00570_90_lingerie_W.jpg]</td>\n",
              "      <td>[W_18618_80_powersuit_W.jpg, W_02282_70_hippie_W.jpg, W_08501_70_hippie_W.jpg, W_14852_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>63481</td>\n",
              "      <td>[W_01480_10_sportivecasual_M.jpg, W_16975_10_sportivecasual_M.jpg, W_05894_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_16460_19_normcore_M.jpg, W_16039_70_hippie_M.jpg, W_12336_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>63526</td>\n",
              "      <td>[W_03388_00_cityglam_W.jpg, W_01993_00_oriental_W.jpg]</td>\n",
              "      <td>[W_19492_00_ecology_W.jpg, W_18797_70_disco_W.jpg, W_19750_70_hippie_W.jpg, W_18508_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>63717</td>\n",
              "      <td>[W_09352_70_military_W.jpg]</td>\n",
              "      <td>[W_18335_00_oriental_W.jpg, W_14378_10_sportivecasual_W.jpg, W_11421_00_ecology_W.jpg, W_14221_80_bodyconscious_W.jpg, W_02047_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>63930</td>\n",
              "      <td>[W_01558_10_sportivecasual_M.jpg, W_09792_10_sportivecasual_M.jpg, W_12196_80_bold_M.jpg]</td>\n",
              "      <td>[W_27174_10_sportivecasual_M.jpg, W_16291_80_bold_M.jpg, W_15762_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>64252</td>\n",
              "      <td>[W_07138_19_normcore_M.jpg, W_24152_60_mods_M.jpg]</td>\n",
              "      <td>[W_32608_70_hippie_M.jpg, W_04510_00_metrosexual_M.jpg, W_30290_50_ivy_M.jpg, W_24101_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>64327</td>\n",
              "      <td>[W_24403_00_metrosexual_M.jpg, W_15095_50_ivy_M.jpg]</td>\n",
              "      <td>[W_21401_00_metrosexual_M.jpg, W_24357_70_hippie_M.jpg, W_33002_60_mods_M.jpg, W_32459_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>64336</td>\n",
              "      <td>[W_06603_90_hiphop_M.jpg, W_00479_60_mods_M.jpg]</td>\n",
              "      <td>[W_15920_00_metrosexual_M.jpg, W_24347_00_metrosexual_M.jpg, W_25202_90_hiphop_M.jpg, W_27903_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>64346</td>\n",
              "      <td>[W_00856_10_sportivecasual_M.jpg, W_16233_80_bold_M.jpg, W_24977_70_hippie_M.jpg, W_30040_60_mods_M.jpg, W_24103_50_ivy_M.jpg]</td>\n",
              "      <td>[W_25721_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>66731</td>\n",
              "      <td>[W_01088_70_military_W.jpg, W_04781_50_feminine_W.jpg]</td>\n",
              "      <td>[T_11421_00_cityglam_W.jpg, W_55996_90_lingerie_W.jpg, T_07471_80_bodyconscious_W.jpg, W_33100_70_punk_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>4035</td>\n",
              "      <td>[W_15186_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15438_70_hippie_M.jpg, W_04677_50_ivy_M.jpg, W_12866_60_mods_M.jpg, W_10082_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>7905</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_07025_10_sportivecasual_M.jpg, W_28443_10_sportivecasual_M.jpg, W_24557_19_normcore_M.jpg, W_06805_90_hiphop_M.jpg, W_24142_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>18129</td>\n",
              "      <td>[W_01424_70_hippie_M.jpg, W_02710_50_ivy_M.jpg]</td>\n",
              "      <td>[W_12309_80_bold_M.jpg, W_09835_50_ivy_M.jpg, W_15479_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>23108</td>\n",
              "      <td>[W_30483_80_bold_M.jpg, W_04601_50_ivy_M.jpg]</td>\n",
              "      <td>[W_25106_00_metrosexual_M.jpg, W_26001_00_metrosexual_M.jpg, W_04302_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>58251</td>\n",
              "      <td>[W_01259_90_lingerie_W.jpg]</td>\n",
              "      <td>[W_63956_80_powersuit_W.jpg, W_13086_80_powersuit_W.jpg, W_13952_80_bodyconscious_W.jpg, W_34247_70_hippie_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>59642</td>\n",
              "      <td>[W_16917_10_athleisure_W.jpg, W_18366_70_disco_W.jpg, W_02444_70_punk_W.jpg, W_02095_60_popart_W.jpg]</td>\n",
              "      <td>[W_08246_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>59857</td>\n",
              "      <td>[W_14888_19_normcore_W.jpg, W_03599_70_punk_W.jpg, W_18546_50_classic_W.jpg]</td>\n",
              "      <td>[W_05586_80_bodyconscious_W.jpg, W_14299_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>59901</td>\n",
              "      <td>[W_04649_10_sportivecasual_M.jpg, W_00017_60_mods_M.jpg, W_12821_50_ivy_M.jpg]</td>\n",
              "      <td>[W_10796_50_ivy_M.jpg, W_15404_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>62653</td>\n",
              "      <td>[W_26093_00_metrosexual_M.jpg, W_02958_60_mods_M.jpg]</td>\n",
              "      <td>[W_25941_10_sportivecasual_M.jpg, W_15586_70_hippie_M.jpg, W_26584_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>62952</td>\n",
              "      <td>[W_38394_19_normcore_W.jpg, W_04928_50_feminine_W.jpg]</td>\n",
              "      <td>[W_05818_90_lingerie_W.jpg, W_44650_90_kitsch_W.jpg, W_42705_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>63255</td>\n",
              "      <td>[W_02846_70_hippie_M.jpg, W_16541_50_ivy_M.jpg, W_10804_50_ivy_M.jpg, W_00036_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15503_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>63391</td>\n",
              "      <td>[W_07215_19_normcore_M.jpg, W_09140_60_mods_M.jpg]</td>\n",
              "      <td>[W_06617_90_hiphop_M.jpg, W_15124_80_bold_M.jpg, W_06511_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23957c34-e95a-4470-9ee0-6cfd5c8d15e9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23957c34-e95a-4470-9ee0-6cfd5c8d15e9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23957c34-e95a-4470-9ee0-6cfd5c8d15e9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b1a6f971-9239-41a4-9a09-b77d26941802\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b1a6f971-9239-41a4-9a09-b77d26941802')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b1a6f971-9239-41a4-9a09-b77d26941802 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d9a98fa2-f241-4af3-8e0b-144aa6e6dfdc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('training_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d9a98fa2-f241-4af3-8e0b-144aa6e6dfdc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('training_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_df",
              "summary": "{\n  \"name\": \"training_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"\\uc751\\ub2f5\\uc790 ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 17863,\n        \"min\": 368,\n        \"max\": 68891,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          64252,\n          64561,\n          18730\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training \\uc2a4\\ud0c0\\uc77c \\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Training \\uc2a4\\ud0c0\\uc77c \\ube44\\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "    응답자 ID  \\\n",
              "0    63405   \n",
              "1    59642   \n",
              "2    63748   \n",
              "3    63913   \n",
              "4    64221   \n",
              "5    62155   \n",
              "6    63479   \n",
              "7    64216   \n",
              "8     7905   \n",
              "9    21432   \n",
              "10   22324   \n",
              "11   60184   \n",
              "12   61104   \n",
              "13   62625   \n",
              "14   63481   \n",
              "15   64295   \n",
              "16    7658   \n",
              "17   12826   \n",
              "18   15251   \n",
              "19   28371   \n",
              "20   28912   \n",
              "21   59523   \n",
              "22   59704   \n",
              "23   59778   \n",
              "24   59812   \n",
              "25   59857   \n",
              "26   60270   \n",
              "27   60510   \n",
              "28   61250   \n",
              "29   62349   \n",
              "30   63156   \n",
              "31   63195   \n",
              "32   63316   \n",
              "33   63392   \n",
              "34   63401   \n",
              "35   63430   \n",
              "36   63435   \n",
              "37   63473   \n",
              "38   63505   \n",
              "39   63545   \n",
              "40   63571   \n",
              "41   63740   \n",
              "42   63910   \n",
              "43   63934   \n",
              "44   63952   \n",
              "45   64252   \n",
              "46   64280   \n",
              "47   64310   \n",
              "48   64460   \n",
              "49   64496   \n",
              "50   64575   \n",
              "51   64747   \n",
              "52   66513   \n",
              "53   66592   \n",
              "54   66842   \n",
              "55   67975   \n",
              "56     837   \n",
              "57    2609   \n",
              "58    4035   \n",
              "59    4817   \n",
              "60    5931   \n",
              "61   10590   \n",
              "62   14276   \n",
              "63   18129   \n",
              "64   18667   \n",
              "65   19125   \n",
              "66   19339   \n",
              "67   19552   \n",
              "68   20768   \n",
              "69   23021   \n",
              "70   23054   \n",
              "71   24912   \n",
              "72   28534   \n",
              "73   28700   \n",
              "74   28828   \n",
              "75   30790   \n",
              "76   35283   \n",
              "77   38363   \n",
              "78   44117   \n",
              "79   50038   \n",
              "80   51939   \n",
              "81   54939   \n",
              "82   58251   \n",
              "83   59083   \n",
              "84   59468   \n",
              "85   59637   \n",
              "86   59843   \n",
              "87   59901   \n",
              "88   60056   \n",
              "89   60071   \n",
              "90   60234   \n",
              "91   60465   \n",
              "92   61145   \n",
              "93   61192   \n",
              "94   61227   \n",
              "95   61460   \n",
              "96   61818   \n",
              "97   61892   \n",
              "98   62125   \n",
              "99   62154   \n",
              "\n",
              "                                                                                               Validation 스타일 선호  \\\n",
              "0                                        [W_02677_60_mods_M.jpg, W_01853_60_mods_M.jpg, W_04684_90_hiphop_M.jpg]   \n",
              "1                                [W_05716_19_normcore_W.jpg, W_14706_19_normcore_W.jpg, W_02095_60_popart_W.jpg]   \n",
              "2                                                        [W_17867_50_ivy_M.jpg, W_00829_10_sportivecasual_M.jpg]   \n",
              "3                                                                                        [W_06883_60_mods_M.jpg]   \n",
              "4                                                     [W_28925_90_hiphop_M.jpg, W_25086_10_sportivecasual_M.jpg]   \n",
              "5                                                                                         [W_27854_50_ivy_M.jpg]   \n",
              "6                                  [W_04994_60_popart_W.jpg, W_06438_00_ecology_W.jpg, W_18202_60_minimal_W.jpg]   \n",
              "7                                                             [W_02816_60_mods_M.jpg, W_15662_19_normcore_M.jpg]   \n",
              "8                                                                                                             []   \n",
              "9                                     [W_06522_50_ivy_M.jpg, W_15294_50_ivy_M.jpg, W_29023_00_metrosexual_M.jpg]   \n",
              "10                                                                             [W_00931_10_sportivecasual_M.jpg]   \n",
              "11                                                                                                            []   \n",
              "12                                                       [W_08839_10_athleisure_W.jpg, W_09085_60_minimal_W.jpg]   \n",
              "13  [W_14785_00_cityglam_W.jpg, W_09363_19_genderless_W.jpg, W_01998_90_lingerie_W.jpg, W_03334_90_kitsch_W.jpg]   \n",
              "14                                                                                                            []   \n",
              "15                                                                                                            []   \n",
              "16                     [W_09731_19_genderless_W.jpg, W_04927_50_feminine_W.jpg, W_01234_10_sportivecasual_W.jpg]   \n",
              "17                                [W_16541_50_ivy_M.jpg, W_15244_80_bold_M.jpg, W_04670_10_sportivecasual_M.jpg]   \n",
              "18                                                              [W_17841_80_bold_M.jpg, W_16732_70_hippie_M.jpg]   \n",
              "19                                                               [W_26393_50_ivy_M.jpg, W_25020_90_hiphop_M.jpg]   \n",
              "20                                                                                       [W_16375_80_bold_M.jpg]   \n",
              "21                                                                                   [W_13251_19_normcore_W.jpg]   \n",
              "22                                                                                        [W_04636_50_ivy_M.jpg]   \n",
              "23                                                               [W_04643_50_ivy_M.jpg, W_04396_90_hiphop_M.jpg]   \n",
              "24                                                                                                            []   \n",
              "25                                                         [W_14888_19_normcore_W.jpg, W_18546_50_classic_W.jpg]   \n",
              "26                                                                                       [W_10844_60_mods_M.jpg]   \n",
              "27                                                          [W_03447_70_military_W.jpg, W_05736_90_kitsch_W.jpg]   \n",
              "28                           [W_28373_80_powersuit_W.jpg, W_44789_80_powersuit_W.jpg, W_01933_50_feminine_W.jpg]   \n",
              "29                                                                                                            []   \n",
              "30                                                                                    [W_14796_60_minimal_W.jpg]   \n",
              "31                                                                                        [W_26200_50_ivy_M.jpg]   \n",
              "32                                                                             [W_05580_10_sportivecasual_W.jpg]   \n",
              "33                                                                  [W_15370_50_ivy_M.jpg, W_06576_50_ivy_M.jpg]   \n",
              "34                                                                                        [W_00492_50_ivy_M.jpg]   \n",
              "35                                                                                   [W_01056_00_cityglam_W.jpg]   \n",
              "36                                                         [W_08285_19_normcore_W.jpg, W_02557_00_ecology_W.jpg]   \n",
              "37                                                                                                            []   \n",
              "38                                                               [W_12393_50_ivy_M.jpg, W_12518_90_hiphop_M.jpg]   \n",
              "39                                                                                   [W_03842_50_feminine_W.jpg]   \n",
              "40                                                                                                            []   \n",
              "41                                                                             [W_01179_10_sportivecasual_W.jpg]   \n",
              "42                                                                             [W_16851_10_sportivecasual_M.jpg]   \n",
              "43                                                                             [W_12897_10_sportivecasual_M.jpg]   \n",
              "44                                                             [W_00073_50_ivy_M.jpg, W_15662_19_normcore_M.jpg]   \n",
              "45                                                                                       [W_24152_60_mods_M.jpg]   \n",
              "46                                       [W_12567_60_mods_M.jpg, W_24628_70_hippie_M.jpg, W_02688_60_mods_M.jpg]   \n",
              "47                                                                                     [W_25934_90_hiphop_M.jpg]   \n",
              "48                                    [W_12817_50_ivy_M.jpg, W_25649_19_normcore_M.jpg, W_16732_70_hippie_M.jpg]   \n",
              "49                                     [W_24647_70_hippie_M.jpg, W_34080_70_hippie_M.jpg, W_30403_60_mods_M.jpg]   \n",
              "50                                                                                       [W_32445_60_mods_M.jpg]   \n",
              "51                                                                                                            []   \n",
              "52                                                                                                            []   \n",
              "53                                                        [W_46907_80_powersuit_W.jpg, W_44918_60_minimal_W.jpg]   \n",
              "54                                                      [W_27765_60_mods_M.jpg, T_06502_10_sportivecasual_M.jpg]   \n",
              "55                                                                                [W_07074_00_metrosexual_M.jpg]   \n",
              "56                                                    [W_00829_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg]   \n",
              "57                                                                                                            []   \n",
              "58                                                                                                            []   \n",
              "59                                                                                   [W_00831_19_normcore_M.jpg]   \n",
              "60                                                                                   [W_13354_50_feminine_W.jpg]   \n",
              "61                                                                                        [W_09156_50_ivy_M.jpg]   \n",
              "62                                                                                       [W_15295_60_mods_M.jpg]   \n",
              "63                                                                                                            []   \n",
              "64                                                                                       [W_29258_80_bold_M.jpg]   \n",
              "65                                                  [W_17413_00_metrosexual_M.jpg, W_12656_00_metrosexual_M.jpg]   \n",
              "66                                                                                                            []   \n",
              "67                                                               [W_07290_50_ivy_M.jpg, W_04268_70_hippie_M.jpg]   \n",
              "68                                                                                                            []   \n",
              "69                                                                                                            []   \n",
              "70                                                                                                            []   \n",
              "71                                                                                                            []   \n",
              "72                                                                                        [W_15294_50_ivy_M.jpg]   \n",
              "73                                                                             [W_06955_10_sportivecasual_M.jpg]   \n",
              "74                                                                                     [W_04245_70_hippie_M.jpg]   \n",
              "75                                                                                                            []   \n",
              "76                                                                                                            []   \n",
              "77                                                                                       [W_27750_60_mods_M.jpg]   \n",
              "78                                                      [T_06739_10_sportivecasual_M.jpg, T_15662_80_bold_M.jpg]   \n",
              "79                                                                                                            []   \n",
              "80                                                                                                            []   \n",
              "81                                                                                       [W_24696_80_bold_M.jpg]   \n",
              "82                                                         [W_19520_50_feminine_W.jpg, W_00716_60_minimal_W.jpg]   \n",
              "83                                               [W_16466_10_sportivecasual_M.jpg, W_06547_00_metrosexual_M.jpg]   \n",
              "84                                                                                                            []   \n",
              "85                                                                                                            []   \n",
              "86                                                                                    [W_44918_60_minimal_W.jpg]   \n",
              "87                                                                                        [W_05868_50_ivy_M.jpg]   \n",
              "88                                                    [W_16624_90_hiphop_M.jpg, W_07271_10_sportivecasual_M.jpg]   \n",
              "89                                                          [W_29942_50_ivy_M.jpg, W_27791_00_metrosexual_M.jpg]   \n",
              "90                                                                                       [W_10107_60_mods_M.jpg]   \n",
              "91                                                                                                            []   \n",
              "92                                                                                                            []   \n",
              "93                                                                             [W_44330_10_sportivecasual_W.jpg]   \n",
              "94                                                                                                            []   \n",
              "95                                                                                     [W_19158_90_kitsch_W.jpg]   \n",
              "96                                                                                       [W_09763_80_bold_M.jpg]   \n",
              "97                                                                                        [W_15248_50_ivy_M.jpg]   \n",
              "98                                                                                                            []   \n",
              "99                                                                                                            []   \n",
              "\n",
              "                                                                                                                       Validation 스타일 비선호  \n",
              "0                                           [W_12904_50_ivy_M.jpg, W_15140_80_bold_M.jpg, W_12304_80_bold_M.jpg, W_07187_70_hippie_M.jpg]  \n",
              "1                                               [W_08246_80_bodyconscious_W.jpg, W_00359_90_grunge_W.jpg, W_11444_80_bodyconscious_W.jpg]  \n",
              "2                 [W_00539_10_sportivecasual_M.jpg, W_10079_60_mods_M.jpg, W_11144_00_metrosexual_M.jpg, W_06955_10_sportivecasual_M.jpg]  \n",
              "3   [W_10066_50_ivy_M.jpg, W_15843_00_metrosexual_M.jpg, W_15947_80_bold_M.jpg, W_16444_10_sportivecasual_M.jpg, W_05876_70_hippie_M.jpg]  \n",
              "4                                 [W_17747_80_bold_M.jpg, W_07333_70_hippie_M.jpg, W_26397_70_hippie_M.jpg, W_02936_00_metrosexual_M.jpg]  \n",
              "5                                  [W_17353_50_ivy_M.jpg, W_32383_00_metrosexual_M.jpg, W_06186_60_mods_M.jpg, W_26120_19_normcore_M.jpg]  \n",
              "6                                                                                [W_18878_19_genderless_W.jpg, W_11936_00_oriental_W.jpg]  \n",
              "7                                                                [W_24931_50_ivy_M.jpg, W_24486_70_hippie_M.jpg, W_26288_70_hippie_M.jpg]  \n",
              "8                               [W_17603_50_ivy_M.jpg, W_28909_19_normcore_M.jpg, W_26179_60_mods_M.jpg, W_07025_10_sportivecasual_M.jpg]  \n",
              "9                                                                                                               [W_26397_70_hippie_M.jpg]  \n",
              "10                                                        [W_04395_80_bold_M.jpg, W_17481_10_sportivecasual_M.jpg, W_16104_60_mods_M.jpg]  \n",
              "11                              [W_12744_50_ivy_M.jpg, W_04245_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_12453_10_sportivecasual_M.jpg]  \n",
              "12                                                                                    [W_14147_70_disco_W.jpg, W_19430_00_oriental_W.jpg]  \n",
              "13                                                                                                                                     []  \n",
              "14                           [W_15184_60_mods_M.jpg, W_17032_10_sportivecasual_M.jpg, W_16460_19_normcore_M.jpg, W_16347_70_hippie_M.jpg]  \n",
              "15                       [W_16374_10_sportivecasual_M.jpg, W_32314_19_normcore_M.jpg, W_31478_19_normcore_M.jpg, W_15729_90_hiphop_M.jpg]  \n",
              "16                                                                                                                                     []  \n",
              "17                                                                                                                                     []  \n",
              "18                                                                                                              [W_10125_70_hippie_M.jpg]  \n",
              "19                                                                                                              [W_27184_90_hiphop_M.jpg]  \n",
              "20                                                                                          [W_00012_50_ivy_M.jpg, W_15745_80_bold_M.jpg]  \n",
              "21                                                                                 [W_19207_19_lounge_W.jpg, W_05665_19_genderless_W.jpg]  \n",
              "22                                                                                       [W_15120_60_mods_M.jpg, W_12476_90_hiphop_M.jpg]  \n",
              "23                                                                                                                [W_15184_60_mods_M.jpg]  \n",
              "24                                                         [W_12564_00_metrosexual_M.jpg, W_15508_60_mods_M.jpg, W_09278_70_hippie_M.jpg]  \n",
              "25                                                                                                               [W_14299_70_disco_W.jpg]  \n",
              "26                                                                                   [W_00117_19_normcore_M.jpg, W_07187_70_hippie_M.jpg]  \n",
              "27                                                                                                            [W_14039_00_cityglam_W.jpg]  \n",
              "28                                                                                                                                     []  \n",
              "29                                                               [W_17353_50_ivy_M.jpg, W_15141_70_hippie_M.jpg, W_16538_90_hiphop_M.jpg]  \n",
              "30                                                                                   [W_19454_90_kitsch_W.jpg, W_19545_00_oriental_W.jpg]  \n",
              "31                                                                                           [W_30593_50_ivy_M.jpg, W_00804_50_ivy_M.jpg]  \n",
              "32                                                                                  [W_13359_80_powersuit_W.jpg, W_05736_90_kitsch_W.jpg]  \n",
              "33                                                                                                                 [W_17603_50_ivy_M.jpg]  \n",
              "34                                                                                       [W_16283_90_hiphop_M.jpg, W_09119_60_mods_M.jpg]  \n",
              "35                                                                                 [W_10191_00_oriental_W.jpg, W_14852_50_feminine_W.jpg]  \n",
              "36                                                                                                            [W_13251_19_normcore_W.jpg]  \n",
              "37                                                        [W_13398_80_powersuit_W.jpg, W_09307_60_popart_W.jpg, W_18622_60_minimal_W.jpg]  \n",
              "38                                                                                                         [W_16699_00_metrosexual_M.jpg]  \n",
              "39                                                                                   [W_04801_19_lounge_W.jpg, W_14039_00_cityglam_W.jpg]  \n",
              "40                                                                 [W_00492_50_ivy_M.jpg, W_02794_90_hiphop_M.jpg, W_15270_60_mods_M.jpg]  \n",
              "41                                                                                    [W_12002_60_minimal_W.jpg, W_07532_70_hippie_W.jpg]  \n",
              "42                                                                                   [W_10779_50_ivy_M.jpg, W_15766_00_metrosexual_M.jpg]  \n",
              "43                                                                                        [W_17603_50_ivy_M.jpg, W_15684_70_hippie_M.jpg]  \n",
              "44                                                                                                              [W_12635_70_hippie_M.jpg]  \n",
              "45                                                                                        [W_17304_70_hippie_M.jpg, W_30290_50_ivy_M.jpg]  \n",
              "46                                                                                                                                     []  \n",
              "47                                                                                       [W_15362_60_mods_M.jpg, W_15740_70_hippie_M.jpg]  \n",
              "48                                                                                                                                     []  \n",
              "49                                                                                                                                     []  \n",
              "50                                                                                        [W_27850_50_ivy_M.jpg, W_17304_70_hippie_M.jpg]  \n",
              "51                                                        [W_14102_50_feminine_W.jpg, W_47169_70_hippie_W.jpg, W_02498_50_feminine_W.jpg]  \n",
              "52                                                    [W_37404_60_space_W.jpg, W_56334_10_sportivecasual_W.jpg, T_06910_50_classic_W.jpg]  \n",
              "53                                                                                                               [W_34436_60_space_W.jpg]  \n",
              "54                                                                                                         [W_16485_00_metrosexual_M.jpg]  \n",
              "55                                                                             [W_26965_90_hiphop_M.jpg, W_60184_10_sportivecasual_M.jpg]  \n",
              "56                                                                                                                                     []  \n",
              "57                                                                                   [W_09376_00_cityglam_W.jpg, W_11266_60_popart_W.jpg]  \n",
              "58                                                                                          [W_17603_50_ivy_M.jpg, W_12866_60_mods_M.jpg]  \n",
              "59                                                                                                              [W_34080_70_hippie_M.jpg]  \n",
              "60                                                                                                       [W_14272_80_bodyconscious_W.jpg]  \n",
              "61                                                                                                              [W_26634_90_hiphop_M.jpg]  \n",
              "62                                                                                                              [W_15497_70_hippie_M.jpg]  \n",
              "63                                                                                         [W_16067_80_bold_M.jpg, W_12309_80_bold_M.jpg]  \n",
              "64                                                                                                                 [W_23900_50_ivy_M.jpg]  \n",
              "65                                                                                                                                     []  \n",
              "66                                                                             [W_07226_90_hiphop_M.jpg, W_00829_10_sportivecasual_M.jpg]  \n",
              "67                                                                                                                                     []  \n",
              "68                                                                                  [W_10768_00_ecology_W.jpg, W_18730_50_feminine_W.jpg]  \n",
              "69                                                                                     [W_34436_60_space_W.jpg, W_05760_60_minimal_W.jpg]  \n",
              "70                                                                                  [W_15120_60_mods_M.jpg, W_06715_00_metrosexual_M.jpg]  \n",
              "71                                                                                       [W_24947_90_hiphop_M.jpg, W_15998_80_bold_M.jpg]  \n",
              "72                                                                                                              [W_16503_70_hippie_M.jpg]  \n",
              "73                                                                                                            [W_17062_19_normcore_M.jpg]  \n",
              "74                                                                                                              [W_16501_70_hippie_M.jpg]  \n",
              "75                                                                                   [W_25411_70_hippie_M.jpg, W_17767_19_normcore_M.jpg]  \n",
              "76                                                                                     [W_12476_90_hiphop_M.jpg, W_25884_90_hiphop_M.jpg]  \n",
              "77                                                                                                                [T_15662_80_bold_M.jpg]  \n",
              "78                                                                                                                                     []  \n",
              "79                                                                                       [W_24109_60_mods_M.jpg, W_16452_70_hippie_M.jpg]  \n",
              "80                                                                                [W_15486_00_metrosexual_M.jpg, W_17616_70_hippie_M.jpg]  \n",
              "81                                                                                                         [W_15658_00_metrosexual_M.jpg]  \n",
              "82                                                                                                                                     []  \n",
              "83                                                                                                                                     []  \n",
              "84                                                                             [W_12413_90_hiphop_M.jpg, W_00842_10_sportivecasual_M.jpg]  \n",
              "85                                                                           [W_06000_80_powersuit_W.jpg, W_08467_80_bodyconscious_W.jpg]  \n",
              "86                                                                                                           [W_28373_80_powersuit_W.jpg]  \n",
              "87                                                                                                                 [W_15404_50_ivy_M.jpg]  \n",
              "88                                                                                                                                     []  \n",
              "89                                                                                                                                     []  \n",
              "90                                                                                                         [W_16755_00_metrosexual_M.jpg]  \n",
              "91                                                                               [W_16915_10_sportivecasual_M.jpg, W_06883_60_mods_M.jpg]  \n",
              "92                                                                                   [W_18160_50_classic_W.jpg, W_14828_50_classic_W.jpg]  \n",
              "93                                                                                                      [W_05562_10_sportivecasual_W.jpg]  \n",
              "94                                                                                [W_17539_00_metrosexual_M.jpg, W_16047_70_hippie_M.jpg]  \n",
              "95                                                                                                              [W_08641_90_hiphop_W.jpg]  \n",
              "96                                                                                                              [W_12214_70_hippie_M.jpg]  \n",
              "97                                                                                                                 [W_16541_50_ivy_M.jpg]  \n",
              "98                                                                     [W_08862_10_sportivecasual_W.jpg, W_02394_10_sportivecasual_W.jpg]  \n",
              "99                                                                                           [W_24103_50_ivy_M.jpg, W_09156_50_ivy_M.jpg]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7350b2bf-8cba-4da5-a09a-f0b4f0793e13\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>응답자 ID</th>\n",
              "      <th>Validation 스타일 선호</th>\n",
              "      <th>Validation 스타일 비선호</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63405</td>\n",
              "      <td>[W_02677_60_mods_M.jpg, W_01853_60_mods_M.jpg, W_04684_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_12904_50_ivy_M.jpg, W_15140_80_bold_M.jpg, W_12304_80_bold_M.jpg, W_07187_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>59642</td>\n",
              "      <td>[W_05716_19_normcore_W.jpg, W_14706_19_normcore_W.jpg, W_02095_60_popart_W.jpg]</td>\n",
              "      <td>[W_08246_80_bodyconscious_W.jpg, W_00359_90_grunge_W.jpg, W_11444_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>63748</td>\n",
              "      <td>[W_17867_50_ivy_M.jpg, W_00829_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_00539_10_sportivecasual_M.jpg, W_10079_60_mods_M.jpg, W_11144_00_metrosexual_M.jpg, W_06955_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>63913</td>\n",
              "      <td>[W_06883_60_mods_M.jpg]</td>\n",
              "      <td>[W_10066_50_ivy_M.jpg, W_15843_00_metrosexual_M.jpg, W_15947_80_bold_M.jpg, W_16444_10_sportivecasual_M.jpg, W_05876_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64221</td>\n",
              "      <td>[W_28925_90_hiphop_M.jpg, W_25086_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17747_80_bold_M.jpg, W_07333_70_hippie_M.jpg, W_26397_70_hippie_M.jpg, W_02936_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>62155</td>\n",
              "      <td>[W_27854_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17353_50_ivy_M.jpg, W_32383_00_metrosexual_M.jpg, W_06186_60_mods_M.jpg, W_26120_19_normcore_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>63479</td>\n",
              "      <td>[W_04994_60_popart_W.jpg, W_06438_00_ecology_W.jpg, W_18202_60_minimal_W.jpg]</td>\n",
              "      <td>[W_18878_19_genderless_W.jpg, W_11936_00_oriental_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>64216</td>\n",
              "      <td>[W_02816_60_mods_M.jpg, W_15662_19_normcore_M.jpg]</td>\n",
              "      <td>[W_24931_50_ivy_M.jpg, W_24486_70_hippie_M.jpg, W_26288_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7905</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg, W_28909_19_normcore_M.jpg, W_26179_60_mods_M.jpg, W_07025_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>21432</td>\n",
              "      <td>[W_06522_50_ivy_M.jpg, W_15294_50_ivy_M.jpg, W_29023_00_metrosexual_M.jpg]</td>\n",
              "      <td>[W_26397_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>22324</td>\n",
              "      <td>[W_00931_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_04395_80_bold_M.jpg, W_17481_10_sportivecasual_M.jpg, W_16104_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>60184</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12744_50_ivy_M.jpg, W_04245_70_hippie_M.jpg, W_27819_70_hippie_M.jpg, W_12453_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>61104</td>\n",
              "      <td>[W_08839_10_athleisure_W.jpg, W_09085_60_minimal_W.jpg]</td>\n",
              "      <td>[W_14147_70_disco_W.jpg, W_19430_00_oriental_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>62625</td>\n",
              "      <td>[W_14785_00_cityglam_W.jpg, W_09363_19_genderless_W.jpg, W_01998_90_lingerie_W.jpg, W_03334_90_kitsch_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>63481</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_15184_60_mods_M.jpg, W_17032_10_sportivecasual_M.jpg, W_16460_19_normcore_M.jpg, W_16347_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>64295</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_16374_10_sportivecasual_M.jpg, W_32314_19_normcore_M.jpg, W_31478_19_normcore_M.jpg, W_15729_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>7658</td>\n",
              "      <td>[W_09731_19_genderless_W.jpg, W_04927_50_feminine_W.jpg, W_01234_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>12826</td>\n",
              "      <td>[W_16541_50_ivy_M.jpg, W_15244_80_bold_M.jpg, W_04670_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>15251</td>\n",
              "      <td>[W_17841_80_bold_M.jpg, W_16732_70_hippie_M.jpg]</td>\n",
              "      <td>[W_10125_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>28371</td>\n",
              "      <td>[W_26393_50_ivy_M.jpg, W_25020_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_27184_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>28912</td>\n",
              "      <td>[W_16375_80_bold_M.jpg]</td>\n",
              "      <td>[W_00012_50_ivy_M.jpg, W_15745_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>59523</td>\n",
              "      <td>[W_13251_19_normcore_W.jpg]</td>\n",
              "      <td>[W_19207_19_lounge_W.jpg, W_05665_19_genderless_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>59704</td>\n",
              "      <td>[W_04636_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15120_60_mods_M.jpg, W_12476_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>59778</td>\n",
              "      <td>[W_04643_50_ivy_M.jpg, W_04396_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_15184_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>59812</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12564_00_metrosexual_M.jpg, W_15508_60_mods_M.jpg, W_09278_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>59857</td>\n",
              "      <td>[W_14888_19_normcore_W.jpg, W_18546_50_classic_W.jpg]</td>\n",
              "      <td>[W_14299_70_disco_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>60270</td>\n",
              "      <td>[W_10844_60_mods_M.jpg]</td>\n",
              "      <td>[W_00117_19_normcore_M.jpg, W_07187_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>60510</td>\n",
              "      <td>[W_03447_70_military_W.jpg, W_05736_90_kitsch_W.jpg]</td>\n",
              "      <td>[W_14039_00_cityglam_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>61250</td>\n",
              "      <td>[W_28373_80_powersuit_W.jpg, W_44789_80_powersuit_W.jpg, W_01933_50_feminine_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>62349</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17353_50_ivy_M.jpg, W_15141_70_hippie_M.jpg, W_16538_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>63156</td>\n",
              "      <td>[W_14796_60_minimal_W.jpg]</td>\n",
              "      <td>[W_19454_90_kitsch_W.jpg, W_19545_00_oriental_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>63195</td>\n",
              "      <td>[W_26200_50_ivy_M.jpg]</td>\n",
              "      <td>[W_30593_50_ivy_M.jpg, W_00804_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>63316</td>\n",
              "      <td>[W_05580_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_13359_80_powersuit_W.jpg, W_05736_90_kitsch_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>63392</td>\n",
              "      <td>[W_15370_50_ivy_M.jpg, W_06576_50_ivy_M.jpg]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>63401</td>\n",
              "      <td>[W_00492_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16283_90_hiphop_M.jpg, W_09119_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>63430</td>\n",
              "      <td>[W_01056_00_cityglam_W.jpg]</td>\n",
              "      <td>[W_10191_00_oriental_W.jpg, W_14852_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>63435</td>\n",
              "      <td>[W_08285_19_normcore_W.jpg, W_02557_00_ecology_W.jpg]</td>\n",
              "      <td>[W_13251_19_normcore_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>63473</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_13398_80_powersuit_W.jpg, W_09307_60_popart_W.jpg, W_18622_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>63505</td>\n",
              "      <td>[W_12393_50_ivy_M.jpg, W_12518_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_16699_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>63545</td>\n",
              "      <td>[W_03842_50_feminine_W.jpg]</td>\n",
              "      <td>[W_04801_19_lounge_W.jpg, W_14039_00_cityglam_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>63571</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_00492_50_ivy_M.jpg, W_02794_90_hiphop_M.jpg, W_15270_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>63740</td>\n",
              "      <td>[W_01179_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_12002_60_minimal_W.jpg, W_07532_70_hippie_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>63910</td>\n",
              "      <td>[W_16851_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_10779_50_ivy_M.jpg, W_15766_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>63934</td>\n",
              "      <td>[W_12897_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg, W_15684_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>63952</td>\n",
              "      <td>[W_00073_50_ivy_M.jpg, W_15662_19_normcore_M.jpg]</td>\n",
              "      <td>[W_12635_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>64252</td>\n",
              "      <td>[W_24152_60_mods_M.jpg]</td>\n",
              "      <td>[W_17304_70_hippie_M.jpg, W_30290_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>64280</td>\n",
              "      <td>[W_12567_60_mods_M.jpg, W_24628_70_hippie_M.jpg, W_02688_60_mods_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>64310</td>\n",
              "      <td>[W_25934_90_hiphop_M.jpg]</td>\n",
              "      <td>[W_15362_60_mods_M.jpg, W_15740_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>64460</td>\n",
              "      <td>[W_12817_50_ivy_M.jpg, W_25649_19_normcore_M.jpg, W_16732_70_hippie_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>64496</td>\n",
              "      <td>[W_24647_70_hippie_M.jpg, W_34080_70_hippie_M.jpg, W_30403_60_mods_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>64575</td>\n",
              "      <td>[W_32445_60_mods_M.jpg]</td>\n",
              "      <td>[W_27850_50_ivy_M.jpg, W_17304_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>64747</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_14102_50_feminine_W.jpg, W_47169_70_hippie_W.jpg, W_02498_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>66513</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_37404_60_space_W.jpg, W_56334_10_sportivecasual_W.jpg, T_06910_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>66592</td>\n",
              "      <td>[W_46907_80_powersuit_W.jpg, W_44918_60_minimal_W.jpg]</td>\n",
              "      <td>[W_34436_60_space_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>66842</td>\n",
              "      <td>[W_27765_60_mods_M.jpg, T_06502_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_16485_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>67975</td>\n",
              "      <td>[W_07074_00_metrosexual_M.jpg]</td>\n",
              "      <td>[W_26965_90_hiphop_M.jpg, W_60184_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>837</td>\n",
              "      <td>[W_00829_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>2609</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_09376_00_cityglam_W.jpg, W_11266_60_popart_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>4035</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17603_50_ivy_M.jpg, W_12866_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>4817</td>\n",
              "      <td>[W_00831_19_normcore_M.jpg]</td>\n",
              "      <td>[W_34080_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>5931</td>\n",
              "      <td>[W_13354_50_feminine_W.jpg]</td>\n",
              "      <td>[W_14272_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>10590</td>\n",
              "      <td>[W_09156_50_ivy_M.jpg]</td>\n",
              "      <td>[W_26634_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>14276</td>\n",
              "      <td>[W_15295_60_mods_M.jpg]</td>\n",
              "      <td>[W_15497_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>18129</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_16067_80_bold_M.jpg, W_12309_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>18667</td>\n",
              "      <td>[W_29258_80_bold_M.jpg]</td>\n",
              "      <td>[W_23900_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>19125</td>\n",
              "      <td>[W_17413_00_metrosexual_M.jpg, W_12656_00_metrosexual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>19339</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_07226_90_hiphop_M.jpg, W_00829_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>19552</td>\n",
              "      <td>[W_07290_50_ivy_M.jpg, W_04268_70_hippie_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>20768</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_10768_00_ecology_W.jpg, W_18730_50_feminine_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>23021</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_34436_60_space_W.jpg, W_05760_60_minimal_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>23054</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_15120_60_mods_M.jpg, W_06715_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>24912</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_24947_90_hiphop_M.jpg, W_15998_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>28534</td>\n",
              "      <td>[W_15294_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16503_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>28700</td>\n",
              "      <td>[W_06955_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[W_17062_19_normcore_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>28828</td>\n",
              "      <td>[W_04245_70_hippie_M.jpg]</td>\n",
              "      <td>[W_16501_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>30790</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_25411_70_hippie_M.jpg, W_17767_19_normcore_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>35283</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12476_90_hiphop_M.jpg, W_25884_90_hiphop_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>38363</td>\n",
              "      <td>[W_27750_60_mods_M.jpg]</td>\n",
              "      <td>[T_15662_80_bold_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>44117</td>\n",
              "      <td>[T_06739_10_sportivecasual_M.jpg, T_15662_80_bold_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>50038</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_24109_60_mods_M.jpg, W_16452_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>51939</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_15486_00_metrosexual_M.jpg, W_17616_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>54939</td>\n",
              "      <td>[W_24696_80_bold_M.jpg]</td>\n",
              "      <td>[W_15658_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>58251</td>\n",
              "      <td>[W_19520_50_feminine_W.jpg, W_00716_60_minimal_W.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>59083</td>\n",
              "      <td>[W_16466_10_sportivecasual_M.jpg, W_06547_00_metrosexual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>59468</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_12413_90_hiphop_M.jpg, W_00842_10_sportivecasual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>59637</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_06000_80_powersuit_W.jpg, W_08467_80_bodyconscious_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>59843</td>\n",
              "      <td>[W_44918_60_minimal_W.jpg]</td>\n",
              "      <td>[W_28373_80_powersuit_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>59901</td>\n",
              "      <td>[W_05868_50_ivy_M.jpg]</td>\n",
              "      <td>[W_15404_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>60056</td>\n",
              "      <td>[W_16624_90_hiphop_M.jpg, W_07271_10_sportivecasual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>60071</td>\n",
              "      <td>[W_29942_50_ivy_M.jpg, W_27791_00_metrosexual_M.jpg]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>60234</td>\n",
              "      <td>[W_10107_60_mods_M.jpg]</td>\n",
              "      <td>[W_16755_00_metrosexual_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>60465</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_16915_10_sportivecasual_M.jpg, W_06883_60_mods_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>61145</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_18160_50_classic_W.jpg, W_14828_50_classic_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>61192</td>\n",
              "      <td>[W_44330_10_sportivecasual_W.jpg]</td>\n",
              "      <td>[W_05562_10_sportivecasual_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>61227</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_17539_00_metrosexual_M.jpg, W_16047_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>61460</td>\n",
              "      <td>[W_19158_90_kitsch_W.jpg]</td>\n",
              "      <td>[W_08641_90_hiphop_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>61818</td>\n",
              "      <td>[W_09763_80_bold_M.jpg]</td>\n",
              "      <td>[W_12214_70_hippie_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>61892</td>\n",
              "      <td>[W_15248_50_ivy_M.jpg]</td>\n",
              "      <td>[W_16541_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>62125</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_08862_10_sportivecasual_W.jpg, W_02394_10_sportivecasual_W.jpg]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>62154</td>\n",
              "      <td>[]</td>\n",
              "      <td>[W_24103_50_ivy_M.jpg, W_09156_50_ivy_M.jpg]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7350b2bf-8cba-4da5-a09a-f0b4f0793e13')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7350b2bf-8cba-4da5-a09a-f0b4f0793e13 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7350b2bf-8cba-4da5-a09a-f0b4f0793e13');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-218e1675-2b4d-4705-8398-27878ef8671f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-218e1675-2b4d-4705-8398-27878ef8671f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-218e1675-2b4d-4705-8398-27878ef8671f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9ad64d88-bb55-4ca9-ba64-9f5cce7a23ec\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('validation_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9ad64d88-bb55-4ca9-ba64-9f5cce7a23ec button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('validation_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "validation_df",
              "summary": "{\n  \"name\": \"validation_df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"\\uc751\\ub2f5\\uc790 ID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 20727,\n        \"min\": 837,\n        \"max\": 67975,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          59083,\n          66592,\n          23054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation \\uc2a4\\ud0c0\\uc77c \\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Validation \\uc2a4\\ud0c0\\uc77c \\ube44\\uc120\\ud638\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'top_preference_df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c3523efc9528>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;31m# DataFrame을 CSV 파일로 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0moutput_csv_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'top_100_respondents_preferences.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtop_preference_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_csv_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n상위 100명의 응답자 선호도가 {output_csv_path}에 저장되었습니다.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'top_preference_df' is not defined"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation 응답자 스타일 선호 정보:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-1]\n",
        "\n",
        "### 정의\n",
        " - 아이템 기반 필터링 (Item-based Filtering): 사용자들이 선호하는 항목 간의 유사성을 분석하여, 사용자가 좋아하는 항목과 유사한 다른 항목을 추천하는 방법이다. 이 방식은 사용자들 간의 유사성보다는 아이템 간의 관계에 초점을 맞춘다.\n",
        "\n",
        " - 사용자 기반 필터링 (User-based Filtering): 비슷한 취향을 가진 사용자들 간의 관계를 분석하여, 유사한 사용자가 선호하는 항목을 추천하는 방법이다. 이 방식은 사용자의과거 선호도와 다른 사용자의 행동을 기반으로 추천을 생성한다.  \n",
        "\n",
        " #### 1.아이템 기반 필터링\n",
        " ##### 적용방법\n",
        "  - 유사성 측정: 사용자가 선호한 스타일(2)을 바탕으로 스타일 간의 유사성을 계산한다.예를 들어, 코사인 유사도(cosine similarity) 또는 자카드 유사도(Jaccardsimilarity) 등을 사용하여 스타일 간의 관계를 분석한다.\n",
        "  \n",
        "  - 추천 생성: 사용자가 선호하는 스타일과 유사한 다른 스타일을 추천한다. 사용자가 A 스타일을 선호한다면, A 스타일과 유사한 B, C, D 스타일을 추천할 수 있다.\n",
        "\n",
        " ##### 장점\n",
        "  - 사용자의 자신의 평가 데이터를 활용하여 추천을 수행하기 때문에 더 관련성 높은 추천제공한다.\n",
        "   \n",
        "  - 다양한 항목을 추천할 가능성이 높아 추천 목록의 다양성 더 커진다.\n",
        "\n",
        "  - 비선호 스타일에 대한 정보가 부족하더라도, 이미 선호한 스타일을 기반으로 추천이 이루어지므로 추천의 질이 비교적 안정적이다.\n",
        "\n",
        "  - 스타일의 특성을 분석하여 유사한 스타일을 추천함으로써, 사용자의 취향을 잘 반영할 수 있다.\n",
        "\n",
        "  - 기존 스타일과의 유사성을 활용하여 새로운 스타일을 추천할 수있는 유연성을 가진다.\n",
        "\n",
        "   ##### 단점\n",
        "   - 이웃 사용자의 정보가 익명으로 처리되기 때문에 설명하기 어렵다.\n",
        "\n",
        "   - 스타일 간의 유사성을 제대로 분석하지 못하면 추천의 품질이떨어질 수 있다.\n",
        "\n",
        "   #### 2.사용자 기반 필터링\n",
        "   ##### 적용방법\n",
        "   - 유사 사용자 측정: 사용자의 선호(2)와 비선호(1) 데이터를 바탕으로 유사한 사용자를 찾는다. 이때, 사용자의 비선호 정보도 포함하여 유사성을 분석한다.\n",
        "\n",
        "   - 추천 생성: 유사한 사용자가 선호하는 스타일을 추천한다. 예를 들어, 사용자가 B 스타일을 비선호하는 경우, 그와 비슷한 사용자가 선호하는 다른 스타일을 추천할 수 있다.\n",
        "\n",
        "   ##### 장점\n",
        "   - 사용자의 취향을 반영한 추천이 가능하여, 개인화된 경험을 제공할 수 있다. → 추천의 이유를 명확하게 설명할 수 있다.\n",
        "\n",
        "   - 비슷한 취향을 가진 사용자들 간의 추천을 통해 다양한 스타일을추천할 수 있다.\n",
        "\n",
        "   ##### 단점\n",
        "   - 비선호(1) 스타일에 대한 정보가 많지 않으면, 유사한 사용자를 찾기 어려워질 수 있으며, 이는 추천의 질 저하로 이어질 수 있다.\n",
        "\n",
        "   - 사용자 수가 적거나 비선호 데이터가 부족할 경우, 유사한 사용자를 찾기가 힘들어질 수 있다. 이는 추천의 신뢰성을 떨어뜨릴 수 있다.\n",
        "\n",
        "   - 다른 사용자의 평가를 바탕으로 추천이 이루어지므로 정확도가 떨어질 수 있다."
      ],
      "metadata": {
        "id": "F10SgQDA2arE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-2 수정"
      ],
      "metadata": {
        "id": "krFI6BstzMPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).cpu().numpy().flatten()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 기타 필요한 함수들 정의 (get_labels, calculate_cosine_similarity, predict_style_preference, calculate_metrics 등)\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity(val_features, train_features):\n",
        "    return cosine_similarity(val_features, train_features)\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.8):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append('Unknown')  # 임계값보다 낮으면 Unknown\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\n",
        "top_100_file_path = 'top_100_respondents_preferences.csv'\n",
        "preferences_df = pd.read_csv(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/training_image'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/validation_image'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training 스타일 선호'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation 스타일 선호'], val_image_dir)\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 (Training 스타일 선호/비선호에 따라 레이블 생성)\n",
        "train_preferences = [1 if label in preferences_df['Training 스타일 선호'].values else 0 for label in train_labels]\n",
        "\n",
        "# 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences)\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5jDsOSfzNMP",
        "outputId": "63aa059d-5e89-4c5b-bf0a-99514e10fd92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-fe2cd6e80568>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n",
            "<ipython-input-14-fe2cd6e80568>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features:  12%|█▏        | 40/325 [00:30<03:23,  1.40it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 속도 개선"
      ],
      "metadata": {
        "id": "5ooKiRf33Egw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 2차원으로 변환 (만약 3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.8):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append('Unknown')  # 임계값보다 낮으면 Unknown\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "preferences_df = pd.read_csv(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/training_image'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/validation_image'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training 스타일 선호'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation 스타일 선호'], val_image_dir)\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 (Training 스타일 선호/비선호에 따라 레이블 생성)\n",
        "train_preferences = [1 if label in preferences_df['Training 스타일 선호'].values else 0 for label in train_labels]\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences)\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "jmaolqtC3Fri",
        "outputId": "6918d419-eb36-4335-a1a2-3087c62b5986"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-f7cebff52ef0>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 325/325 [01:38<00:00,  3.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for validation images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 114/114 [00:35<00:00,  3.23it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating similarity...\n",
            "Predicting preferences...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Mix of label input types (string and number)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-f7cebff52ef0>\u001b[0m in \u001b[0;36m<cell line: 152>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;31m# 정확도, 정밀도, 재현율, F1 점수 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_preferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;31m# 결과 출력\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-f7cebff52ef0>\u001b[0m in \u001b[0;36mcalculate_metrics\u001b[0;34m(predicted, actual)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalculate_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m                     )\n\u001b[1;32m    212\u001b[0m                 ):\n\u001b[0;32m--> 213\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1787\u001b[0m     \"\"\"\n\u001b[1;32m   1788\u001b[0m     \u001b[0m_check_zero_division\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1562\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1563\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1564\u001b[0;31m     \u001b[0mpresent_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maverage\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.8):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "preferences_df = pd.read_csv(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/training_image'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/validation_image'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training 스타일 선호'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation 스타일 선호'], val_image_dir)\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [1 if label in preferences_df['Training 스타일 선호'].values else 0 for label in train_labels]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [1 if label in preferences_df['Validation 스타일 선호'].values else 0 for label in val_labels]\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences)\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOXAeCSB-8zv",
        "outputId": "c01e9c23-3b65-4ce3-cf1f-2f750e958516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-c8b98c8adc0a>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 325/325 [01:36<00:00,  3.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for validation images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 114/114 [00:33<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-2 중복 확인"
      ],
      "metadata": {
        "id": "6CbjD7U2CEIM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.8):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "preferences_df = pd.read_csv(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/training_image'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/validation_image'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training 스타일 선호'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation 스타일 선호'], val_image_dir)\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "if common_images:\n",
        "    print(\"공통 이미지 파일:\")\n",
        "    print(common_images)\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [1 if label in preferences_df['Training 스타일 선호'].values else 0 for label in train_labels]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [1 if label in preferences_df['Validation 스타일 선호'].values else 0 for label in val_labels]\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences)\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVcCp176AriY",
        "outputId": "bf584709-c885-4bc2-b126-f24e06780e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-9be82627a59d>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 325/325 [01:36<00:00,  3.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for validation images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 114/114 [00:33<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3-2 레이블 확인"
      ],
      "metadata": {
        "id": "jMRCL5WMCCsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "preferences_df = pd.read_csv(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/training_image'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/validation_image'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training 스타일 선호'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation 스타일 선호'], val_image_dir)\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "if common_images:\n",
        "    print(\"공통 이미지 파일:\")\n",
        "    print(common_images)\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [1 if label in preferences_df['Training 스타일 선호'].values else 0 for label in train_labels]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [1 if label in preferences_df['Validation 스타일 선호'].values else 0 for label in val_labels]\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences)\n",
        "\n",
        "# 디버깅을 위한 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 값 일부 샘플 출력\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEHCSQ4ZCIFc",
        "outputId": "b942cdfb-632e-4a2b-d0e4-2c506f493247"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-06514a260607>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 325/325 [01:38<00:00,  3.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for validation images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 114/114 [00:32<00:00,  3.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Similarity scores sample:\n",
            "[[0.8853961  0.81390333 1.0000001  ... 0.9012476  0.8740969  0.85757166]\n",
            " [0.87628806 0.87581486 0.8823871  ... 0.88525504 0.88264567 0.8860845 ]\n",
            " [0.907057   0.8814254  0.8661924  ... 0.91906625 0.9227008  0.88517034]\n",
            " [0.9006591  0.8929478  0.8804139  ... 0.92253864 0.9202245  0.87378615]\n",
            " [0.8648086  0.89711004 0.85186684 ... 0.88210243 0.9062601  0.8720805 ]]\n",
            "Predicted Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Prediction and validation labels difference count: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_preferences와 val_preferences의 값을 점검하는 코드"
      ],
      "metadata": {
        "id": "lfKm_MWdEp-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "preferences_df = pd.read_csv(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/training_image'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/validation_image'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training 스타일 선호'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation 스타일 선호'], val_image_dir)\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [1 if label in preferences_df['Training 스타일 선호'].values else 0 for label in train_labels]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [1 if label in preferences_df['Validation 스타일 선호'].values else 0 for label in val_labels]\n",
        "\n",
        "# 디버깅을 위한 train_preferences와 val_preferences의 분포 확인\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.6)\n",
        "\n",
        "# 디버깅을 위한 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 값 일부 샘플 출력\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEEPRinFEqUu",
        "outputId": "b149766d-43f8-406b-81d5-9e8ecf4f5cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-343bd19e7964>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 325/325 [01:39<00:00,  3.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for validation images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 114/114 [00:37<00:00,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Preferences 분포: 0    325\n",
            "Name: count, dtype: int64\n",
            "Validation Preferences 분포: 0    114\n",
            "Name: count, dtype: int64\n",
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Similarity scores sample:\n",
            "[[0.91163343 0.88510025 1.0000002  ... 0.9313352  0.9092157  0.9164553 ]\n",
            " [0.9194087  0.8975162  0.9257333  ... 0.9293745  0.9197666  0.9180166 ]\n",
            " [0.9294648  0.91828763 0.9135726  ... 0.93681353 0.9356378  0.9288393 ]\n",
            " [0.9313044  0.9213519  0.9338911  ... 0.9501404  0.9390071  0.9293614 ]\n",
            " [0.91531354 0.9061108  0.90248096 ... 0.9264375  0.92872643 0.9156902 ]]\n",
            "Predicted Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Prediction and validation labels difference count: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# CSV 파일 경로 설정\n",
        "csv_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "\n",
        "# 여러 구분자와 인코딩을 시도하며 파일 읽기\n",
        "preferences_df = None\n",
        "separators = [',', ';', '\\t']\n",
        "encodings = ['utf-8', 'ISO-8859-1', 'utf-16']\n",
        "\n",
        "for sep in separators:\n",
        "    for encoding in encodings:\n",
        "        try:\n",
        "            print(f\"Trying separator='{sep}' and encoding='{encoding}'\")\n",
        "            preferences_df = pd.read_csv(csv_file_path, sep=sep, encoding=encoding)\n",
        "\n",
        "            # 파일이 성공적으로 로드되면 반복 중단\n",
        "            print(\"File loaded successfully\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"Failed with separator='{sep}' and encoding='{encoding}': {e}\")\n",
        "    if preferences_df is not None:\n",
        "        break\n",
        "\n",
        "# 열 데이터가 정상적으로 로드되었는지 점검\n",
        "if preferences_df is not None:\n",
        "    # 각 응답자의 'Training 스타일 선호'와 'Validation 스타일 선호' 열 확인\n",
        "    print(\"Training 스타일 선호 샘플:\\n\", preferences_df['Training 스타일 선호'].head())\n",
        "    print(\"Validation 스타일 선호 샘플:\\n\", preferences_df['Validation 스타일 선호'].head())\n",
        "\n",
        "    # 빈 배열이거나 데이터가 없는 경우 알림\n",
        "    if preferences_df['Training 스타일 선호'].isnull().all() or preferences_df['Validation 스타일 선호'].isnull().all():\n",
        "        print(\"Warning: 'Training 스타일 선호' 및 'Validation 스타일 선호' 열에 데이터가 없습니다.\")\n",
        "    else:\n",
        "        print(\"파일이 정상적으로 준비되었습니다.\")\n",
        "else:\n",
        "    print(\"preferences_df가 준비되지 않았습니다.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJWMsCh-F_ws",
        "outputId": "299b0ed1-ae69-4d23-f6b1-7f69d4861cb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying separator=',' and encoding='utf-8'\n",
            "File loaded successfully\n",
            "Training 스타일 선호 샘플:\n",
            " 0                                                                                                                                          ['W_02804_19_normcore_M.jpg', 'W_06843_60_mods_M.jpg']\n",
            "1    ['W_00829_10_sportivecasual_M.jpg', 'W_28209_10_sportivecasual_M.jpg', 'W_28211_19_normcore_M.jpg', 'W_28722_10_sportivecasual_M.jpg', 'W_17305_70_hippie_M.jpg', 'W_25073_90_hiphop_M.jpg']\n",
            "2                                                                                                                                                                                             NaN\n",
            "3                                                                                                                                                                        ['W_15186_50_ivy_M.jpg']\n",
            "4                                                                                                                                                                                             NaN\n",
            "Name: Training 스타일 선호, dtype: object\n",
            "Validation 스타일 선호 샘플:\n",
            " 0                                                               NaN\n",
            "1    ['W_00829_10_sportivecasual_M.jpg', 'W_17305_70_hippie_M.jpg']\n",
            "2                                                                []\n",
            "3                                                                []\n",
            "4                                     ['W_00831_19_normcore_M.jpg']\n",
            "Name: Validation 스타일 선호, dtype: object\n",
            "파일이 정상적으로 준비되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import ast\n",
        "\n",
        "# CSV 파일 경로 설정\n",
        "csv_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "\n",
        "# CSV 파일 로드 시도\n",
        "try:\n",
        "    # 여러 구분자와 인코딩 설정을 시도\n",
        "    print(\"Trying separator=',' and encoding='utf-8'\")\n",
        "    preferences_df = pd.read_csv(csv_file_path, sep=',', encoding='utf-8')\n",
        "    print(\"File loaded successfully\")\n",
        "\n",
        "except UnicodeDecodeError:\n",
        "    print(\"Trying separator=',' and encoding='ISO-8859-1'\")\n",
        "    preferences_df = pd.read_csv(csv_file_path, sep=',', encoding='ISO-8859-1')\n",
        "    print(\"File loaded successfully with ISO-8859-1 encoding\")\n",
        "\n",
        "except pd.errors.ParserError:\n",
        "    print(\"Trying separator=';'\")\n",
        "    preferences_df = pd.read_csv(csv_file_path, sep=';', encoding='utf-8')\n",
        "    print(\"File loaded successfully with separator ';'\")\n",
        "\n",
        "# CSV 파일 내용 점검\n",
        "print(\"Training 스타일 선호 샘플:\\n\", preferences_df['Training 스타일 선호'].head())\n",
        "print(\"Validation 스타일 선호 샘플:\\n\", preferences_df['Validation 스타일 선호'].head())\n",
        "\n",
        "# 'Training 스타일 선호' 및 'Validation 스타일 선호' 열을 리스트 형식으로 변환\n",
        "preferences_df['Training 스타일 선호'] = preferences_df['Training 스타일 선호'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
        "preferences_df['Validation 스타일 선호'] = preferences_df['Validation 스타일 선호'].apply(lambda x: ast.literal_eval(x) if pd.notnull(x) else [])\n",
        "\n",
        "# 변환 후 첫 5개 출력\n",
        "print(\"Converted 'Training 스타일 선호' Sample:\\n\", preferences_df['Training 스타일 선호'].head())\n",
        "print(\"Converted 'Validation 스타일 선호' Sample:\\n\", preferences_df['Validation 스타일 선호'].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvqM915EHHgA",
        "outputId": "907822cd-1f5a-4362-cf0a-88eed4090742"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying separator=',' and encoding='utf-8'\n",
            "File loaded successfully\n",
            "Training 스타일 선호 샘플:\n",
            " 0                                                                                                                                          ['W_02804_19_normcore_M.jpg', 'W_06843_60_mods_M.jpg']\n",
            "1    ['W_00829_10_sportivecasual_M.jpg', 'W_28209_10_sportivecasual_M.jpg', 'W_28211_19_normcore_M.jpg', 'W_28722_10_sportivecasual_M.jpg', 'W_17305_70_hippie_M.jpg', 'W_25073_90_hiphop_M.jpg']\n",
            "2                                                                                                                                                                                             NaN\n",
            "3                                                                                                                                                                        ['W_15186_50_ivy_M.jpg']\n",
            "4                                                                                                                                                                                             NaN\n",
            "Name: Training 스타일 선호, dtype: object\n",
            "Validation 스타일 선호 샘플:\n",
            " 0                                                               NaN\n",
            "1    ['W_00829_10_sportivecasual_M.jpg', 'W_17305_70_hippie_M.jpg']\n",
            "2                                                                []\n",
            "3                                                                []\n",
            "4                                     ['W_00831_19_normcore_M.jpg']\n",
            "Name: Validation 스타일 선호, dtype: object\n",
            "Converted 'Training 스타일 선호' Sample:\n",
            " 0                                                                                                                                  [W_02804_19_normcore_M.jpg, W_06843_60_mods_M.jpg]\n",
            "1    [W_00829_10_sportivecasual_M.jpg, W_28209_10_sportivecasual_M.jpg, W_28211_19_normcore_M.jpg, W_28722_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg, W_25073_90_hiphop_M.jpg]\n",
            "2                                                                                                                                                                                  []\n",
            "3                                                                                                                                                              [W_15186_50_ivy_M.jpg]\n",
            "4                                                                                                                                                                                  []\n",
            "Name: Training 스타일 선호, dtype: object\n",
            "Converted 'Validation 스타일 선호' Sample:\n",
            " 0                                                            []\n",
            "1    [W_00829_10_sportivecasual_M.jpg, W_17305_70_hippie_M.jpg]\n",
            "2                                                            []\n",
            "3                                                            []\n",
            "4                                   [W_00831_19_normcore_M.jpg]\n",
            "Name: Validation 스타일 선호, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "수정 수정 제발 돼라. csv 파일에서 선호 비선호가 1 0으로 안바뀌고 다 0 으로 비선호로 된거 였음"
      ],
      "metadata": {
        "id": "saeqoYCuH9MD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/top_100_respondents_preferences.csv'\n",
        "preferences_df = pd.read_csv(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/training_image'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/validation_image'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training 스타일 선호'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation 스타일 선호'], val_image_dir)\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [\n",
        "    1 if any(img in preferences_df['Training 스타일 선호'].dropna().values for img in [label]) else 0\n",
        "    for label in train_labels\n",
        "]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [\n",
        "    1 if any(img in preferences_df['Validation 스타일 선호'].dropna().values for img in [label]) else 0\n",
        "    for label in val_labels\n",
        "]\n",
        "\n",
        "# 결과 분포 출력\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.6)\n",
        "\n",
        "# 디버깅을 위한 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 값 일부 샘플 출력\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "vZkt6ym3IDeY",
        "outputId": "08d87a4c-c16a-4017-f09b-f6c8cc95277f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-6986d27c109e>\u001b[0m in \u001b[0;36m<cell line: 105>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;31m# 2-2에서 생성한 응답자 선호도 CSV 파일 로드\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0mtop_100_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mpreferences_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_100_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;31m# 학습 및 검증 이미지 경로 추출 함수\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode bytes in position 15-16: invalid continuation byte"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 선권씨 xlsx 쓴 버전"
      ],
      "metadata": {
        "id": "PJJ1iMRNKZ6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 빈 배열 또는 비정상 차원일 경우 예외 처리\n",
        "    if val_features.numel() == 0 or train_features.numel() == 0:\n",
        "        raise ValueError(\"Error: One or both of the feature arrays are empty or invalid.\")\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 Excel 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)  # Excel 파일 읽기\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training Style Preferred'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation Style Preferred'], val_image_dir)\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [\n",
        "    1 if any(img in preferences_df['Training Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in train_labels\n",
        "]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [\n",
        "    1 if any(img in preferences_df['Validation Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in val_labels\n",
        "]\n",
        "\n",
        "# 결과 분포 출력\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.5)\n",
        "\n",
        "# 디버깅을 위한 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 값 일부 샘플 출력\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "dSEVPonqKb3i",
        "outputId": "63edbd27-78d8-4170-d318-747ee931935d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-ddd446836eb2>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for validation images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Preferences 분포: Series([], Name: count, dtype: int64)\n",
            "Validation Preferences 분포: Series([], Name: count, dtype: int64)\n",
            "Calculating similarity...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error: One or both of the feature arrays are empty or invalid.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-ddd446836eb2>\u001b[0m in \u001b[0;36m<cell line: 167>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;31m# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating similarity...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cosine_similarity_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting preferences...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-ddd446836eb2>\u001b[0m in \u001b[0;36mcalculate_cosine_similarity_gpu\u001b[0;34m(val_features, train_features)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# 빈 배열 또는 비정상 차원일 경우 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: One or both of the feature arrays are empty or invalid.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# 2차원으로 변환 (3차원 이상의 텐서인 경우)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error: One or both of the feature arrays are empty or invalid."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18()  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "\n",
        "        # 모델의 state_dict에서 fc 레이어 관련 키 제거\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)  # 가중치를 strict=False로 로드\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)  # 배치 차원 추가 및 디바이스로 전송\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 Excel 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)  # Excel 파일 읽기\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        # 이미지 파일 경로로 변환 후 리스트에 추가\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]  # 실제 파일만 반환\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "print(\"Extracting train_image_paths and val_image_paths...\")\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training Style Preferred'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation Style Preferred'], val_image_dir)\n",
        "\n",
        "# 디버깅: 추출된 경로 수 출력\n",
        "print(f\"Number of train_image_paths: {len(train_image_paths)}\")\n",
        "print(f\"Number of val_image_paths: {len(val_image_paths)}\")\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "print(\"Extracting features for training images...\")\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "\n",
        "print(\"Extracting features for validation images...\")\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [\n",
        "    1 if any(img in preferences_df['Training Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in train_labels\n",
        "]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [\n",
        "    1 if any(img in preferences_df['Validation Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in val_labels\n",
        "]\n",
        "\n",
        "# 결과 분포 출력\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.5)\n",
        "\n",
        "# 디버깅을 위한 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 값 일부 샘플 출력\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "c86N4sLRTsGV",
        "outputId": "69245a94-43a7-476d-a9cb-9b955e6914eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting train_image_paths and val_image_paths...\n",
            "Number of train_image_paths: 0\n",
            "Number of val_image_paths: 0\n",
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-f52201662f03>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for training images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting features for validation images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Preferences 분포: Series([], Name: count, dtype: int64)\n",
            "Validation Preferences 분포: Series([], Name: count, dtype: int64)\n",
            "Calculating similarity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-f52201662f03>\u001b[0m in \u001b[0;36m<cell line: 168>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;31m# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating similarity...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cosine_similarity_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting preferences...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-f52201662f03>\u001b[0m in \u001b[0;36mcalculate_cosine_similarity_gpu\u001b[0;34m(val_features, train_features)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mval_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_features\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mval_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0mtrain_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(self, p, dim, keepdim, dtype)\u001b[0m\n\u001b[1;32m    825\u001b[0m                 \u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             )\n\u001b[0;32m--> 827\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1798\u001b[0m             ):\n\u001b[1;32m   1799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1800\u001b[0;31m                     return torch.linalg.vector_norm(\n\u001b[0m\u001b[1;32m   1801\u001b[0m                         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m                     )\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 엑셀 파일 로드 및 열 이름 수정\n",
        "file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(file_path)\n",
        "\n",
        "# 열 이름 표준화\n",
        "preferences_df.columns = [\"Respondent ID\", \"Training Style Preferred\", \"Training Style Not Preferred\",\n",
        "                          \"Validation Style Preferred\", \"Validation Style Not Preferred\"]\n",
        "\n",
        "# Training과 Validation의 선호 스타일 데이터를 리스트로 변환\n",
        "def parse_style_list(style_string):\n",
        "    if pd.isna(style_string):\n",
        "        return []\n",
        "    return [item.strip() for item in style_string.strip(\"[]\").replace(\"'\", \"\").split(\",\")]\n",
        "\n",
        "preferences_df[\"Training Style Preferred\"] = preferences_df[\"Training Style Preferred\"].apply(parse_style_list)\n",
        "preferences_df[\"Validation Style Preferred\"] = preferences_df[\"Validation Style Preferred\"].apply(parse_style_list)\n",
        "\n",
        "# 변환된 데이터 확인\n",
        "print(\"Training 스타일 선호 샘플:\")\n",
        "print(preferences_df[\"Training Style Preferred\"].head())\n",
        "print(\"Validation 스타일 선호 샘플:\")\n",
        "print(preferences_df[\"Validation Style Preferred\"].head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-FRyf00V4OT",
        "outputId": "43725c85-4486-4348-8179-4a7eadeddf7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training 스타일 선호 샘플:\n",
            "0    [W_07098_19_normcore_M.jpg, W_16449_10_sportivecasual_M.jpg, W_16403_10_sportivecasual_M.jpg, W_07307_19_normcore_M.jpg, W_07260_10_sportivecasual_M.jpg, W_01394_10_sportivecasual_M.jpg, W_17702_90_hiphop_M.jpg, W_04687_00_metrosexual_M.jpg, W_04324_90_hiphop_M.jpg, W_02693_70_hippie_M.jpg, W_16445_50_ivy_M.jpg, W_05869_60_mods_M.jpg]\n",
            "1                                                                                                                                                                             [W_02978_10_sportivecasual_M.jpg, W_02771_10_sportivecasual_M.jpg, W_00831_19_normcore_M.jpg, W_17273_19_normcore_M.jpg, W_06993_90_hiphop_M.jpg, W_01737_50_ivy_M.jpg]\n",
            "2                                                                                                                           [W_01989_19_normcore_W.jpg, W_09698_19_genderless_W.jpg, W_19801_19_genderless_W.jpg, W_05786_10_sportivecasual_W.jpg, W_13163_90_kitsch_W.jpg, W_07554_70_hippie_W.jpg, W_05597_70_punk_W.jpg, W_01962_60_minimal_W.jpg]\n",
            "3                                                                                                                                                                                                                                   [W_02962_10_sportivecasual_M.jpg, W_09795_10_sportivecasual_M.jpg, W_02846_70_hippie_M.jpg, W_16420_50_ivy_M.jpg]\n",
            "4                                                                          [W_00553_10_sportivecasual_M.jpg, W_04519_10_sportivecasual_M.jpg, W_07066_10_sportivecasual_M.jpg, W_09262_19_normcore_M.jpg, W_04759_90_hiphop_M.jpg, W_06883_60_mods_M.jpg, W_06573_60_mods_M.jpg, W_10082_50_ivy_M.jpg, W_07255_50_ivy_M.jpg, W_07150_70_hippie_M.jpg]\n",
            "Name: Training Style Preferred, dtype: object\n",
            "Validation 스타일 선호 샘플:\n",
            "0    [W_09278_70_hippie_M.jpg, W_04324_90_hiphop_M.jpg, W_09889_10_sportivecasual_M.jpg, W_12413_90_hiphop_M.jpg]\n",
            "1                                                                                     [W_00831_19_normcore_M.jpg]\n",
            "2                                 [W_09698_19_genderless_W.jpg, W_13163_90_kitsch_W.jpg, W_08641_90_hiphop_W.jpg]\n",
            "3                             [W_02962_10_sportivecasual_M.jpg, W_17366_19_normcore_M.jpg, W_03047_80_bold_M.jpg]\n",
            "4                                   [W_17239_19_normcore_M.jpg, W_01552_19_normcore_M.jpg, W_06883_60_mods_M.jpg]\n",
            "Name: Validation Style Preferred, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)  # 가중치 로드\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])  # 마지막 fc 레이어 제외\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 2-2에서 생성한 응답자 선호도 Excel 파일 로드\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출 함수\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        image_paths.extend([os.path.join(image_dir, img.strip()) for img in images if img.strip()])\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training Style Preferred'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation Style Preferred'], val_image_dir)\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출 및 저장\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 일관되게 변환)\n",
        "train_preferences = [\n",
        "    1 if any(img in preferences_df['Training Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in train_labels\n",
        "]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [\n",
        "    1 if any(img in preferences_df['Validation Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in val_labels\n",
        "]\n",
        "\n",
        "# 결과 분포 출력\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# 이후의 유사도 계산 및 선호도 예측 코드는 동일하게 진행합니다.\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 빈 배열 또는 비정상 차원일 경우 예외 처리\n",
        "    if val_features.numel() == 0 or train_features.numel() == 0:\n",
        "        raise ValueError(\"Error: One or both of the feature arrays are empty or invalid.\")\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.5)\n",
        "\n",
        "# 디버깅을 위한 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 값 일부 샘플 출력\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "bmsmLFfBawFr",
        "outputId": "151a8e48-9b1c-4e9e-eafe-eb0dcbd04ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-46-f36605ae7d16>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)  # 가중치 로드\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 0it [00:00, ?it/s]\n",
            "Extracting Features: 0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Preferences 분포: Series([], Name: count, dtype: int64)\n",
            "Validation Preferences 분포: Series([], Name: count, dtype: int64)\n",
            "Calculating similarity...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Error: One or both of the feature arrays are empty or invalid.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-f36605ae7d16>\u001b[0m in \u001b[0;36m<cell line: 164>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;31m# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Calculating similarity...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_cosine_similarity_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicting preferences...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-46-f36605ae7d16>\u001b[0m in \u001b[0;36mcalculate_cosine_similarity_gpu\u001b[0;34m(val_features, train_features)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;31m# 빈 배열 또는 비정상 차원일 경우 예외 처리\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mval_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: One or both of the feature arrays are empty or invalid.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;31m# 2차원으로 변환 (3차원 이상의 텐서인 경우)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Error: One or both of the feature arrays are empty or invalid."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수 및 저장\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device, save_path):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    features = np.array(features)\n",
        "    np.save(save_path, features)  # 특징 벡터 저장\n",
        "    return features\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^segmented_(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# 수정된 함수: 파일명에 접두사 추가하여 경로 생성\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        paths = [os.path.join(image_dir, f\"segmented_{img.strip()}\") for img in images if img.strip()]\n",
        "        image_paths.extend(paths)\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training Style Preferred'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation Style Preferred'], val_image_dir)\n",
        "\n",
        "# 경로 수 확인\n",
        "print(f\"Number of train_image_paths: {len(train_image_paths)}\")\n",
        "print(f\"Number of val_image_paths: {len(val_image_paths)}\")\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출 및 저장\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device, '/content/train_features.npy')\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device, '/content/val_features.npy')\n",
        "\n",
        "# 특징 벡터 배열 크기 확인\n",
        "print(f\"Train features shape: {train_features.shape}\")\n",
        "print(f\"Validation features shape: {val_features.shape}\")\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 변환)\n",
        "train_preferences = [\n",
        "    1 if any(img in preferences_df['Training Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in train_labels\n",
        "]\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = [\n",
        "    1 if any(img in preferences_df['Validation Style Preferred'].dropna().values for img in [label]) else 0\n",
        "    for label in val_labels\n",
        "]\n",
        "\n",
        "# 결과 분포 출력\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# 이후의 유사도 계산 및 선호도 예측 코드는 그대로 진행됩니다.\n",
        "\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 빈 배열 또는 비정상 차원일 경우 예외 처리\n",
        "    if val_features.numel() == 0 or train_features.numel() == 0:\n",
        "        raise ValueError(\"Error: One or both of the feature arrays are empty or invalid.\")\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.5)\n",
        "\n",
        "# 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ztw67y66bdJ-",
        "outputId": "bb205bae-f149-4fa8-e1f1-b8868a3022cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train_image_paths: 674\n",
            "Number of val_image_paths: 442\n",
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:09<00:00, 73.49it/s] \n",
            "Extracting Features: 100%|██████████| 442/442 [00:03<00:00, 116.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (674, 512, 7, 7)\n",
            "Validation features shape: (442, 512, 7, 7)\n",
            "Train Preferences 분포: 0    674\n",
            "Name: count, dtype: int64\n",
            "Validation Preferences 분포: 0    442\n",
            "Name: count, dtype: int64\n",
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Similarity scores sample:\n",
            "[[0.96352625 0.95435995 0.962906   ... 0.96968806 0.9568928  0.9613649 ]\n",
            " [0.96914303 0.95496446 0.96750534 ... 0.970698   0.9681988  0.96925116]\n",
            " [0.9632888  0.9543785  0.9693126  ... 0.97012174 0.96319926 0.96754843]\n",
            " [0.9752952  0.9611111  0.9694315  ... 0.9701168  0.96731836 0.96817917]\n",
            " [0.970234   0.96511286 0.97612244 ... 0.9713933  0.9606411  0.9806955 ]]\n",
            "Predicted Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Prediction and validation labels difference count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수 및 저장\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device, save_path):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    features = np.array(features)\n",
        "    np.save(save_path, features)  # 특징 벡터 저장\n",
        "    return features\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^segmented_(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# 수정된 함수: 파일명에 접두사 추가하여 경로 생성\n",
        "def extract_image_paths_from_preferences(preference_column, image_dir):\n",
        "    image_paths = []\n",
        "    for img_list in preference_column.dropna():\n",
        "        images = img_list.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        paths = [os.path.join(image_dir, f\"segmented_{img.strip()}\") for img in images if img.strip()]\n",
        "        image_paths.extend(paths)\n",
        "    return [img_path for img_path in image_paths if os.path.isfile(img_path)]\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)\n",
        "\n",
        "# 엑셀 파일의 선호도 컬럼 샘플 출력\n",
        "print(\"Sample of Training Style Preferred from Excel:\")\n",
        "print(preferences_df['Training Style Preferred'].head())\n",
        "print(\"Sample of Validation Style Preferred from Excel:\")\n",
        "print(preferences_df['Validation Style Preferred'].head())\n",
        "\n",
        "# 학습 및 검증 이미지 경로 추출\n",
        "train_image_paths = extract_image_paths_from_preferences(preferences_df['Training Style Preferred'], train_image_dir)\n",
        "val_image_paths = extract_image_paths_from_preferences(preferences_df['Validation Style Preferred'], val_image_dir)\n",
        "\n",
        "# 경로 수 확인\n",
        "print(f\"Number of train_image_paths: {len(train_image_paths)}\")\n",
        "print(f\"Number of val_image_paths: {len(val_image_paths)}\")\n",
        "\n",
        "# 중복 데이터 확인\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출 및 저장\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device, '/content/train_features.npy')\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device, '/content/val_features.npy')\n",
        "\n",
        "# 저장된 특징 벡터 파일 로드 및 크기 확인\n",
        "loaded_train_features = np.load('/content/train_features.npy')\n",
        "loaded_val_features = np.load('/content/val_features.npy')\n",
        "print(f\"Loaded Train features shape: {loaded_train_features.shape}\")\n",
        "print(f\"Loaded Validation features shape: {loaded_val_features.shape}\")\n",
        "\n",
        "# 학습 이미지와 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 파일명에서 접두어를 제거하는 함수 정의\n",
        "def normalize_filename(filename):\n",
        "    return filename.replace(\"segmented_\", \"\")\n",
        "\n",
        "# 학습 이미지의 선호도 레이블 (숫자 형식으로 변환)\n",
        "train_preferences = []\n",
        "for label in train_labels:\n",
        "    normalized_label = normalize_filename(label)  # 접두어 제거\n",
        "    preferred_list = preferences_df['Training Style Preferred'].dropna().tolist()\n",
        "    is_preferred = any(normalized_label == img.strip() for item in preferred_list for img in item.split(\", \"))\n",
        "    train_preferences.append(1 if is_preferred else 0)\n",
        "print(\"Train Preferences 샘플:\", train_preferences[:10])\n",
        "\n",
        "# 검증 이미지의 라벨도 숫자 형식으로 변환\n",
        "val_preferences = []\n",
        "for label in val_labels:\n",
        "    normalized_label = normalize_filename(label)  # 접두어 제거\n",
        "    preferred_list = preferences_df['Validation Style Preferred'].dropna().tolist()\n",
        "    is_preferred = any(normalized_label == img.strip() for item in preferred_list for img in item.split(\", \"))\n",
        "    val_preferences.append(1 if is_preferred else 0)\n",
        "print(\"Validation Preferences 샘플:\", val_preferences[:10])\n",
        "\n",
        "# 레이블 분포 출력\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "\n",
        "# 이후의 유사도 계산 및 선호도 예측 코드는 그대로 진행됩니다.\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 빈 배열 또는 비정상 차원일 경우 예외 처리\n",
        "    if val_features.numel() == 0 or train_features.numel() == 0:\n",
        "        raise ValueError(\"Error: One or both of the feature arrays are empty or invalid.\")\n",
        "\n",
        "    # 2차원으로 변환 (3차원 이상의 텐서인 경우)\n",
        "    if val_features.dim() > 2:\n",
        "        val_features = val_features.view(val_features.size(0), -1)\n",
        "    if train_features.dim() > 2:\n",
        "        train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값보다 낮으면 비선호로 처리\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.5)\n",
        "\n",
        "# 유사도, 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])\n",
        "\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "\n",
        "# 결과 출력\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 레이블 비교를 위한 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY5j8NGrj1W3",
        "outputId": "0583f1d7-c858-4126-9bb3-e6e279c8631f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample of Training Style Preferred from Excel:\n",
            "0    W_07098_19_normcore_M.jpg, W_16449_10_sportivecasual_M.jpg, W_16403_10_sportivecasual_M.jpg, W_07307_19_normcore_M.jpg, W_07260_10_sportivecasual_M.jpg, W_01394_10_sportivecasual_M.jpg, W_17702_90_hiphop_M.jpg, W_04687_00_metrosexual_M.jpg, W_04324_90_hiphop_M.jpg, W_02693_70_hippie_M.jpg, W_16445_50_ivy_M.jpg, W_05869_60_mods_M.jpg\n",
            "1                                                                                                                                                                             W_02978_10_sportivecasual_M.jpg, W_02771_10_sportivecasual_M.jpg, W_00831_19_normcore_M.jpg, W_17273_19_normcore_M.jpg, W_06993_90_hiphop_M.jpg, W_01737_50_ivy_M.jpg\n",
            "2                                                                                                                           W_01989_19_normcore_W.jpg, W_09698_19_genderless_W.jpg, W_19801_19_genderless_W.jpg, W_05786_10_sportivecasual_W.jpg, W_13163_90_kitsch_W.jpg, W_07554_70_hippie_W.jpg, W_05597_70_punk_W.jpg, W_01962_60_minimal_W.jpg\n",
            "3                                                                                                                                                                                                                                   W_02962_10_sportivecasual_M.jpg, W_09795_10_sportivecasual_M.jpg, W_02846_70_hippie_M.jpg, W_16420_50_ivy_M.jpg\n",
            "4                                                                          W_00553_10_sportivecasual_M.jpg, W_04519_10_sportivecasual_M.jpg, W_07066_10_sportivecasual_M.jpg, W_09262_19_normcore_M.jpg, W_04759_90_hiphop_M.jpg, W_06883_60_mods_M.jpg, W_06573_60_mods_M.jpg, W_10082_50_ivy_M.jpg, W_07255_50_ivy_M.jpg, W_07150_70_hippie_M.jpg\n",
            "Name: Training Style Preferred, dtype: object\n",
            "Sample of Validation Style Preferred from Excel:\n",
            "0    W_09278_70_hippie_M.jpg, W_04324_90_hiphop_M.jpg, W_09889_10_sportivecasual_M.jpg, W_12413_90_hiphop_M.jpg\n",
            "1                                                                                     W_00831_19_normcore_M.jpg\n",
            "2                                 W_09698_19_genderless_W.jpg, W_13163_90_kitsch_W.jpg, W_08641_90_hiphop_W.jpg\n",
            "3                             W_02962_10_sportivecasual_M.jpg, W_17366_19_normcore_M.jpg, W_03047_80_bold_M.jpg\n",
            "4                                   W_17239_19_normcore_M.jpg, W_01552_19_normcore_M.jpg, W_06883_60_mods_M.jpg\n",
            "Name: Validation Style Preferred, dtype: object\n",
            "Number of train_image_paths: 674\n",
            "Number of val_image_paths: 442\n",
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:08<00:00, 83.92it/s] \n",
            "Extracting Features: 100%|██████████| 442/442 [00:03<00:00, 114.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded Train features shape: (674, 512, 7, 7)\n",
            "Loaded Validation features shape: (442, 512, 7, 7)\n",
            "Train Preferences 샘플: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Preferences 샘플: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Train Preferences 분포: 0    674\n",
            "Name: count, dtype: int64\n",
            "Validation Preferences 분포: 0    442\n",
            "Name: count, dtype: int64\n",
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Similarity scores sample:\n",
            "[[0.96352625 0.95435995 0.962906   ... 0.96968806 0.9568928  0.9613649 ]\n",
            " [0.96914303 0.95496446 0.96750534 ... 0.970698   0.9681988  0.96925116]\n",
            " [0.9632888  0.9543785  0.9693126  ... 0.97012174 0.96319926 0.96754843]\n",
            " [0.9752952  0.9611111  0.9694315  ... 0.9701168  0.96731836 0.96817917]\n",
            " [0.970234   0.96511286 0.97612244 ... 0.9713933  0.9606411  0.9806955 ]]\n",
            "Predicted Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Prediction and validation labels difference count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)  # ResNet-18 모델 생성\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^segmented_(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 엑셀 파일에서 데이터를 읽고 분리\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)\n",
        "\n",
        "# 선호도를 구분할 기준 설정 (예: 특정 스타일에 대해 선호도 구분)\n",
        "def assign_preferences(styles):\n",
        "    preferences = []\n",
        "    for style in styles:\n",
        "        if \"specific_style\" in style:  # 예시 기준: 특정 스타일 이름 포함 여부\n",
        "            preferences.append(1)  # 선호\n",
        "        else:\n",
        "            preferences.append(0)  # 비선호\n",
        "    return preferences\n",
        "\n",
        "# Training Style Preferred와 Validation Style Preferred에서 파일명 추출 및 선호도 부여\n",
        "train_style = []\n",
        "val_style = []\n",
        "for items in preferences_df['Training Style Preferred'].dropna():\n",
        "    item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "    train_style.extend(item_list)\n",
        "\n",
        "for items in preferences_df['Validation Style Preferred'].dropna():\n",
        "    item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "    val_style.extend(item_list)\n",
        "\n",
        "# 이미지 경로로 변환\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "# 학습 및 검증 데이터 선호도 할당\n",
        "train_preferences = assign_preferences(train_style)\n",
        "val_preferences = assign_preferences(val_style)\n",
        "# 경로 및 중복 확인\n",
        "print(f\"Number of train_image_paths: {len(train_image_paths)}\")\n",
        "print(f\"Number of val_image_paths: {len(val_image_paths)}\")\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "print(f\"Train features shape: {train_features.shape}\")\n",
        "print(f\"Validation features shape: {val_features.shape}\")\n",
        "\n",
        "# 학습 및 검증 이미지의 라벨 추출\n",
        "train_labels = get_labels(train_image_paths)\n",
        "val_labels = get_labels(val_image_paths)\n",
        "\n",
        "# 학습 및 검증 이미지의 선호도 레이블 (숫자 형식으로 변환)\n",
        "train_preferences = [1] * len(train_labels)  # 선호 스타일이므로 1\n",
        "val_preferences = [1] * len(val_labels)  # 선호 스타일이므로 1\n",
        "\n",
        "# 결과 분포 출력\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환 및 2차원 형태로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 차원 축소: (batch_size, 512 * 7 * 7)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.5)\n",
        "\n",
        "# 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CgpFtVgLmKv3",
        "outputId": "cb64813d-5b58-4c1d-8ec5-1ad36ff01c5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-62-761a3d08cce9>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train_image_paths: 674\n",
            "Number of val_image_paths: 442\n",
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:13<00:00, 51.16it/s]\n",
            "Extracting Features: 100%|██████████| 442/442 [00:04<00:00, 105.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (674, 512, 7, 7)\n",
            "Validation features shape: (442, 512, 7, 7)\n",
            "Train Preferences 분포: 1    674\n",
            "Name: count, dtype: int64\n",
            "Validation Preferences 분포: 1    442\n",
            "Name: count, dtype: int64\n",
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Similarity scores sample:\n",
            "[[0.9804314  0.977074   0.98327285 ... 0.99003124 0.9762687  0.98570466]\n",
            " [0.9857222  0.97977865 0.9822368  ... 0.98882514 0.98261434 0.9863326 ]\n",
            " [0.9801007  0.9769698  0.983831   ... 0.98702765 0.97866565 0.9871478 ]\n",
            " [0.98965466 0.98082674 0.9777789  ... 0.9851641  0.98269784 0.98216987]\n",
            " [0.9763631  0.9734934  0.98768944 ... 0.98569    0.9712979  0.991022  ]]\n",
            "Predicted Preferences Sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Validation Preferences Sample: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Prediction and validation labels difference count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 파일명에서 스타일(라벨)을 추출하는 함수\n",
        "image_pattern = re.compile(r'^segmented_(W|T)_(\\d+)_(.*?)_(.*?)_(W|M)\\.jpg$')\n",
        "def get_labels(image_paths):\n",
        "    labels = []\n",
        "    for filename in image_paths:\n",
        "        match = image_pattern.match(os.path.basename(filename))\n",
        "        if match:\n",
        "            _, _, _, style, _ = match.groups()\n",
        "            labels.append(style)\n",
        "    return labels\n",
        "\n",
        "# 클래스 목록 (성별 + 스타일 조합으로 구성)\n",
        "fashion_classes = [\n",
        "    \"남성_bold\", \"남성_hiphop\", \"남성_hippie\", \"남성_ivy\", \"남성_metrosexual\",\n",
        "    \"남성_mods\", \"남성_normcore\", \"남성_sportivecasual\", \"여성_athleisure\",\n",
        "    \"여성_bodyconscious\", \"여성_cityglam\", \"여성_classic\", \"여성_disco\",\n",
        "    \"여성_ecology\", \"여성_feminine\", \"여성_genderless\", \"여성_grunge\",\n",
        "    \"여성_hiphop\", \"여성_hippie\", \"여성_kitsch\", \"여성_lingerie\",\n",
        "    \"여성_lounge\", \"여성_military\", \"여성_minimal\", \"여성_normcore\",\n",
        "    \"여성_oriental\", \"여성_popart\", \"여성_powersuit\", \"여성_punk\",\n",
        "    \"여성_space\", \"여성_sportivecasual\"\n",
        "]\n",
        "\n",
        "# 선호도를 구분할 기준 설정\n",
        "def assign_preferences(styles):\n",
        "    preferences = []\n",
        "    for style in styles:\n",
        "        gender, style_name = style.split(\"_\")[-2:]  # 파일명으로부터 성별 및 스타일 정보 추출\n",
        "        label = f\"{'남성' if gender == 'M' else '여성'}_{style_name}\"\n",
        "        if label in fashion_classes:\n",
        "            preferences.append(1)  # 선호\n",
        "        else:\n",
        "            preferences.append(0)  # 비선호\n",
        "    return preferences\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 엑셀 파일에서 데이터를 읽고 분리\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)\n",
        "\n",
        "# Training Style Preferred와 Validation Style Preferred에서 파일명 추출 및 선호도 부여\n",
        "train_style = []\n",
        "val_style = []\n",
        "for items in preferences_df['Training Style Preferred'].dropna():\n",
        "    item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "    train_style.extend(item_list)\n",
        "\n",
        "for items in preferences_df['Validation Style Preferred'].dropna():\n",
        "    item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "    val_style.extend(item_list)\n",
        "\n",
        "# 이미지 경로로 변환\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "# 학습 및 검증 데이터 선호도 할당\n",
        "train_preferences = assign_preferences(train_style)\n",
        "val_preferences = assign_preferences(val_style)\n",
        "\n",
        "# 경로 및 중복 확인\n",
        "print(f\"Number of train_image_paths: {len(train_image_paths)}\")\n",
        "print(f\"Number of val_image_paths: {len(val_image_paths)}\")\n",
        "common_images = set(train_image_paths) & set(val_image_paths)\n",
        "print(f\"Train과 Validation 데이터셋 간 중복 이미지 수: {len(common_images)}\")\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "print(f\"Train features shape: {train_features.shape}\")\n",
        "print(f\"Validation features shape: {val_features.shape}\")\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환 및 2차원 형태로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 차원 축소: (batch_size, 512 * 7 * 7)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.6):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.5)\n",
        "\n",
        "# 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 예측 및 검증 레이블 간 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VjspvrKn-Qt",
        "outputId": "692dc5db-cde3-4e81-81ad-519acc6c9158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-64-9c897b9857b7>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train_image_paths: 674\n",
            "Number of val_image_paths: 442\n",
            "Train과 Validation 데이터셋 간 중복 이미지 수: 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:06<00:00, 105.11it/s]\n",
            "Extracting Features: 100%|██████████| 442/442 [00:04<00:00, 104.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (674, 512, 7, 7)\n",
            "Validation features shape: (442, 512, 7, 7)\n",
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Similarity scores sample:\n",
            "[[0.94504374 0.92273325 0.9347446  ... 0.94943714 0.93698066 0.9287985 ]\n",
            " [0.956121   0.9233682  0.95403135 ... 0.958176   0.95452243 0.95237833]\n",
            " [0.94997996 0.9239968  0.9522519  ... 0.95290667 0.9466649  0.94507134]\n",
            " [0.96342987 0.93958867 0.9505069  ... 0.95801425 0.95531505 0.9392491 ]\n",
            " [0.9486501  0.9259146  0.9610124  ... 0.94613206 0.9402099  0.9654377 ]]\n",
            "Predicted Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Prediction and validation labels difference count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    return transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "    return np.array(features)\n",
        "\n",
        "# 엑셀 파일에서 스타일 선호/비선호 추출 함수 (eval 사용하지 않음)\n",
        "def load_styles_from_excel(file_path):\n",
        "    df = pd.read_excel(file_path)\n",
        "    train_style = []\n",
        "    val_style = []\n",
        "    for items in df['Training Style Preferred'].dropna():\n",
        "        item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        train_style.extend(item_list)\n",
        "\n",
        "    for items in df['Validation Style Preferred'].dropna():\n",
        "        item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "        val_style.extend(item_list)\n",
        "    return train_style, val_style\n",
        "\n",
        "# 이미지 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 엑셀 파일 로드 및 이미지 경로 생성\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "train_style, val_style = load_styles_from_excel(top_100_file_path)\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "# 피처 추출\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 선호도 레이블 설정 (선호: 1, 비선호: 0)\n",
        "train_preferences = [1] * len(train_style)\n",
        "val_preferences = [1] * len(val_style)  # 초기값을 1로 설정\n",
        "\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "    return torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.8):\n",
        "    return [1 if np.max(score_row) > threshold else 0 for score_row in similarity_scores]\n",
        "\n",
        "# 유사도 계산\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences)\n",
        "\n",
        "# 성능 평가\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qBTKScApsI1",
        "outputId": "f3fec6f2-4734-4418-beae-2ca0fdd5af84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-66-1c2027aadb86>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)\n",
            "Extracting Features: 100%|██████████| 674/674 [00:07<00:00, 86.11it/s]\n",
            "Extracting Features: 100%|██████████| 442/442 [00:04<00:00, 101.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000, Precision: 1.0000, Recall: 1.0000, F1-Score: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 클래스 목록 (성별 + 스타일 조합으로 구성)\n",
        "fashion_classes = [\n",
        "    \"남성_bold\", \"남성_hiphop\", \"남성_hippie\", \"남성_ivy\", \"남성_metrosexual\",\n",
        "    \"남성_mods\", \"남성_normcore\", \"남성_sportivecasual\", \"여성_athleisure\",\n",
        "    \"여성_bodyconscious\", \"여성_cityglam\", \"여성_classic\", \"여성_disco\",\n",
        "    \"여성_ecology\", \"여성_feminine\", \"여성_genderless\", \"여성_grunge\",\n",
        "    \"여성_hiphop\", \"여성_hippie\", \"여성_kitsch\", \"여성_lingerie\",\n",
        "    \"여성_lounge\", \"여성_military\", \"여성_minimal\", \"여성_normcore\",\n",
        "    \"여성_oriental\", \"여성_popart\", \"여성_powersuit\", \"여성_punk\",\n",
        "    \"여성_space\", \"여성_sportivecasual\"\n",
        "]\n",
        "\n",
        "# 선호도를 구분할 기준 설정\n",
        "def assign_preferences(styles):\n",
        "    preferences = []\n",
        "    for style in styles:\n",
        "        gender, style_name = style.split(\"_\")[-2:]  # 파일명으로부터 성별 및 스타일 정보 추출\n",
        "        label = f\"{'남성' if gender == 'M' else '여성'}_{style_name}\"\n",
        "        if label in fashion_classes:\n",
        "            preferences.append(1)  # 선호\n",
        "        else:\n",
        "            preferences.append(0)  # 비선호\n",
        "    return preferences\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 엑셀 파일에서 데이터를 읽고 분리\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_df = pd.read_excel(top_100_file_path)\n",
        "\n",
        "# Training Style Preferred와 Validation Style Preferred에서 파일명 추출 및 선호도 부여\n",
        "train_style = []\n",
        "val_style = []\n",
        "for items in preferences_df['Training Style Preferred'].dropna():\n",
        "    item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "    train_style.extend(item_list)\n",
        "\n",
        "for items in preferences_df['Validation Style Preferred'].dropna():\n",
        "    item_list = items.strip(\"[]\").replace(\"'\", \"\").split(\", \")\n",
        "    val_style.extend(item_list)\n",
        "\n",
        "# 이미지 경로로 변환\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "# 학습 및 검증 데이터 선호도 할당\n",
        "train_preferences = assign_preferences(train_style)\n",
        "val_preferences = assign_preferences(val_style)\n",
        "\n",
        "# 데이터 분포 확인\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Preferences 분포:\", pd.Series(val_preferences).value_counts())\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "print(f\"Train features shape: {train_features.shape}\")\n",
        "print(f\"Validation features shape: {val_features.shape}\")\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환 및 2차원 형태로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 차원 축소: (batch_size, 512 * 7 * 7)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.7):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = np.argmax(score_row)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold=0.7)\n",
        "\n",
        "# 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 점수의 일부를 출력\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:10])  # 예측 결과 일부 출력\n",
        "print(\"Validation Preferences Sample:\", val_preferences[:10])  # 실제 레이블 일부 출력\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_preferences)\n",
        "print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "# 예측 및 검증 레이블 간 차이점 계산\n",
        "diff_count = sum([1 for pred, actual in zip(predicted_preferences, val_preferences) if pred != actual])\n",
        "print(f\"Prediction and validation labels difference count: {diff_count}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31q0sjfYs7ff",
        "outputId": "c629389a-da65-42b2-ca42-c4b50e0545a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-73-08ed31a0b0a4>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Preferences 분포: 0    674\n",
            "Name: count, dtype: int64\n",
            "Validation Preferences 분포: 0    442\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:07<00:00, 91.34it/s] \n",
            "Extracting Features: 100%|██████████| 442/442 [00:04<00:00, 109.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (674, 512, 7, 7)\n",
            "Validation features shape: (442, 512, 7, 7)\n",
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Similarity scores sample:\n",
            "[[0.95333195 0.94281924 0.94824344 ... 0.9614783  0.9497949  0.9460572 ]\n",
            " [0.9601681  0.94528604 0.9581765  ... 0.96413857 0.95836973 0.9583902 ]\n",
            " [0.9575387  0.9421646  0.9573164  ... 0.9618231  0.95690095 0.95695454]\n",
            " [0.9682179  0.9525788  0.96047443 ... 0.9632424  0.9612097  0.9552729 ]\n",
            " [0.9622929  0.9527761  0.96820956 ... 0.961179   0.9569083  0.9711716 ]]\n",
            "Predicted Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Validation Preferences Sample: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Prediction Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-Score: 1.0000\n",
            "Prediction and validation labels difference count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 클래스 목록 (성별 + 스타일 조합으로 구성)\n",
        "fashion_classes = [\n",
        "    \"남성_bold\", \"남성_hiphop\", \"남성_hippie\", \"남성_ivy\", \"남성_metrosexual\",\n",
        "    \"남성_mods\", \"남성_normcore\", \"남성_sportivecasual\", \"여성_athleisure\",\n",
        "    \"여성_bodyconscious\", \"여성_cityglam\", \"여성_classic\", \"여성_disco\",\n",
        "    \"여성_ecology\", \"여성_feminine\", \"여성_genderless\", \"여성_grunge\",\n",
        "    \"여성_hiphop\", \"여성_hippie\", \"여성_kitsch\", \"여성_lingerie\",\n",
        "    \"여성_lounge\", \"여성_military\", \"여성_minimal\", \"여성_normcore\",\n",
        "    \"여성_oriental\", \"여성_popart\", \"여성_powersuit\", \"여성_punk\",\n",
        "    \"여성_space\", \"여성_sportivecasual\"\n",
        "]\n",
        "\n",
        "# 엑셀 파일에서 데이터 추출 함수\n",
        "def extract_preferences_from_excel(file_path):\n",
        "    preferences_dict = {}\n",
        "    preferences_df = pd.read_excel(file_path)\n",
        "\n",
        "    for idx, row in preferences_df.iterrows():\n",
        "        respondent_id = row['Respondent ID']\n",
        "        training_preferred = row['Training Style Preferred']\n",
        "        training_not_preferred = row['Training Style Not Preferred']\n",
        "        validation_preferred = row['Validation Style Preferred']\n",
        "        validation_not_preferred = row['Validation Style Not Preferred']\n",
        "\n",
        "        # 리스트 형태로 변환\n",
        "        training_preferred_list = training_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_preferred) else []\n",
        "        training_not_preferred_list = training_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_not_preferred) else []\n",
        "        validation_preferred_list = validation_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_preferred) else []\n",
        "        validation_not_preferred_list = validation_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_not_preferred) else []\n",
        "\n",
        "        preferences_dict[respondent_id] = {\n",
        "            'training_preferred': training_preferred_list,\n",
        "            'training_not_preferred': training_not_preferred_list,\n",
        "            'validation_preferred': validation_preferred_list,\n",
        "            'validation_not_preferred': validation_not_preferred_list\n",
        "        }\n",
        "\n",
        "    return preferences_dict\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'  # 학습된 가중치 경로 설정\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 엑셀 파일에서 선호 및 비선호 이미지 리스트 추출\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_dict = extract_preferences_from_excel(top_100_file_path)\n",
        "\n",
        "# Training Style Preferred 리스트 추출\n",
        "train_style = []\n",
        "for respondent_id, prefs in preferences_dict.items():\n",
        "    train_style.extend(prefs['training_preferred'])\n",
        "\n",
        "# Validation Style Preferred 리스트 추출 및 스타일 선호도 할당\n",
        "val_style = []\n",
        "val_labels = []  # 검증 레이블 리스트 초기화\n",
        "for respondent_id, prefs in preferences_dict.items():\n",
        "    val_style.extend(prefs['validation_preferred'])\n",
        "    # Validation Preferred는 1, Validation Not Preferred는 0으로 설정\n",
        "    val_labels.extend([1] * len(prefs['validation_preferred']))\n",
        "    val_labels.extend([0] * len(prefs['validation_not_preferred']))\n",
        "\n",
        "# 이미지 경로로 변환 (segmented_가 추가됨)\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "# 학습 및 검증 데이터 선호도 할당\n",
        "train_preferences = assign_preferences(train_style)\n",
        "\n",
        "# 데이터 분포 확인\n",
        "print(\"Train Preferences 분포:\", pd.Series(train_preferences).value_counts())\n",
        "print(\"Validation Labels 분포:\", pd.Series(val_labels).value_counts())  # 수정된 부분\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "print(f\"Train features shape: {train_features.shape}\")\n",
        "print(f\"Validation features shape: {val_features.shape}\")\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환 및 2차원 형태로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 차원 축소: (batch_size, 512 * 7 * 7)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        max_index = np.argmax(score_row)\n",
        "        predicted_label = train_preferences[max_index]  # 최대 유사도를 가진 라벨을 사용\n",
        "\n",
        "        # 여기에서 기본적으로 0으로 설정하는 것이 아니라, 항상 예측 값을 추가합니다.\n",
        "        predicted_preferences.append(predicted_label)\n",
        "\n",
        "        print(f\"Score Row: {score_row}, Max Similarity: {max_similarity}, Max Index: {max_index}, Predicted Label: {predicted_label}\")  # 디버깅 정보\n",
        "\n",
        "    return predicted_preferences\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences)\n",
        "\n",
        "# 예측 값, 실제 값 출력\n",
        "print(\"Similarity scores sample:\")\n",
        "print(similarity_scores[:5])  # 유사도 점수의 일부를 출력\n",
        "print(\"Predicted Preferences Sample:\", predicted_preferences[:])  # 예측 결과 일부 출력\n",
        "print(\"Validation Labels Sample:\", val_labels[:])  # 실제 레이블 일부 출력\n",
        "\n",
        "# 예측된 선호도의 길이 확인\n",
        "print(f\"Length of Predicted Preferences: {len(predicted_preferences)}\")\n",
        "print(f\"Length of Validation Labels: {len(val_labels)}\")\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산\n",
        "if len(predicted_preferences) == len(val_labels):\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "    print(f\"Prediction Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-Score: {f1:.4f}\")\n",
        "else:\n",
        "    print(\"Error: The lengths of predicted preferences and validation labels do not match.\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "Vzr3fD_wwbcL",
        "outputId": "6b36e88e-dd0c-4aab-a83c-94d4814f6fda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'assign_preferences' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9ada527e96b1>\u001b[0m in \u001b[0;36m<cell line: 122>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;31m# 학습 및 검증 데이터 선호도 할당\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m \u001b[0mtrain_preferences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0massign_preferences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_style\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;31m# 데이터 분포 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'assign_preferences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2 김진 수정 드디어 됐다"
      ],
      "metadata": {
        "id": "2hzTs7H3Ciwo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "씨바 드디어 됐다 !!!!"
      ],
      "metadata": {
        "id": "wI_Y_7fvCeZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 엑셀 파일에서 데이터 추출 함수\n",
        "def extract_preferences_from_excel(file_path):\n",
        "    preferences_dict = {}\n",
        "    preferences_df = pd.read_excel(file_path)\n",
        "\n",
        "    for idx, row in preferences_df.iterrows():\n",
        "        respondent_id = row['Respondent ID']\n",
        "        training_preferred = row['Training Style Preferred']\n",
        "        training_not_preferred = row['Training Style Not Preferred']\n",
        "        validation_preferred = row['Validation Style Preferred']\n",
        "        validation_not_preferred = row['Validation Style Not Preferred']\n",
        "\n",
        "        # 리스트 형태로 변환\n",
        "        training_preferred_list = training_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_preferred) else []\n",
        "        training_not_preferred_list = training_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_not_preferred) else []\n",
        "        validation_preferred_list = validation_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_preferred) else []\n",
        "        validation_not_preferred_list = validation_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_not_preferred) else []\n",
        "\n",
        "        preferences_dict[respondent_id] = {\n",
        "            'training_preferred': training_preferred_list,\n",
        "            'training_not_preferred': training_not_preferred_list,\n",
        "            'validation_preferred': validation_preferred_list,\n",
        "            'validation_not_preferred': validation_not_preferred_list\n",
        "        }\n",
        "\n",
        "    return preferences_dict\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 엑셀 파일에서 선호 및 비선호 이미지 리스트 추출\n",
        "top_100_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "preferences_dict = extract_preferences_from_excel(top_100_file_path)\n",
        "\n",
        "# Training Style Preferred 리스트 추출\n",
        "train_style = []\n",
        "for respondent_id, prefs in preferences_dict.items():\n",
        "    train_style.extend(prefs['training_preferred'])\n",
        "\n",
        "# Validation Style Preferred 및 Not Preferred 리스트 추출 및 스타일 선호도 할당\n",
        "val_style = []\n",
        "val_labels = []  # 검증 레이블 리스트 초기화\n",
        "for respondent_id, prefs in preferences_dict.items():\n",
        "    val_style.extend(prefs['validation_preferred'])\n",
        "    val_style.extend(prefs['validation_not_preferred'])\n",
        "    # Validation Preferred는 1, Validation Not Preferred는 0으로 설정\n",
        "    val_labels.extend([1] * len(prefs['validation_preferred']))\n",
        "    val_labels.extend([0] * len(prefs['validation_not_preferred']))\n",
        "\n",
        "# 이미지 경로로 변환 (segmented_가 추가됨)\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "print(f\"Train features shape: {train_features.shape}\")\n",
        "print(f\"Validation features shape: {val_features.shape}\")\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수 (퍼센트 변환)\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted) * 100  # 퍼센트로 변환\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted', zero_division=0)\n",
        "    return accuracy, precision * 100, recall * 100, f1 * 100  # 퍼센트로 변환\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    # numpy 배열을 torch 텐서로 변환 및 2차원 형태로 변환\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "\n",
        "    # 차원 축소: (batch_size, 512 * 7 * 7)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 정규화하여 벡터를 단위 벡터로 변환 (L2 노멀라이즈)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "\n",
        "    # 코사인 유사도 계산\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "\n",
        "# GPU에서 코사인 유사도 계산 및 스타일 선호도 예측\n",
        "print(\"Calculating similarity...\")\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "\n",
        "print(\"Predicting preferences...\")\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences=[1]*len(train_features))\n",
        "\n",
        "# 예측 값과 실제 값 비교 및 평가\n",
        "if len(predicted_preferences) == len(val_labels):\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "    print(f\"Prediction Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Precision: {precision:.2f}%\")\n",
        "    print(f\"Recall: {recall:.2f}%\")\n",
        "    print(f\"F1-Score: {f1:.2f}%\")\n",
        "else:\n",
        "    print(\"Error: The lengths of predicted preferences and validation labels do not match.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39gDMCbz1p1A",
        "outputId": "b1b4011f-66d7-45d6-82da-caace65fc791"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:05<00:00, 127.77it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:08<00:00, 133.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (674, 512, 7, 7)\n",
            "Validation features shape: (1102, 512, 7, 7)\n",
            "Calculating similarity...\n",
            "Predicting preferences...\n",
            "Prediction Accuracy: 40.11%\n",
            "Precision: 16.09%\n",
            "Recall: 40.11%\n",
            "F1-Score: 22.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# 다양한 임계값을 테스트하여 최적의 threshold를 찾는 함수\n",
        "def find_best_threshold(similarity_scores, val_labels, train_preferences, thresholds):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "\n",
        "    for threshold in thresholds:\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        if len(predicted_preferences) == len(val_labels):\n",
        "            _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "            if f1 > best_f1:\n",
        "                best_f1 = f1\n",
        "                best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 다양한 threshold 값을 테스트\n",
        "thresholds = np.arange(0.5, 0.9, 0.05)\n",
        "optimal_threshold = find_best_threshold(similarity_scores, val_labels, train_preferences=[1]*len(train_features), thresholds=thresholds)\n",
        "\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}\")\n",
        "\n",
        "# 최적 threshold로 다시 예측 수행\n",
        "predicted_preferences = predict_style_preference(similarity_scores, train_preferences=[1]*len(train_features), threshold=optimal_threshold)\n",
        "\n",
        "# 최종 평가 출력\n",
        "if len(predicted_preferences) == len(val_labels):\n",
        "    accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "    print(f\"Final Prediction Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"Final Precision: {precision:.2f}%\")\n",
        "    print(f\"Final Recall: {recall:.2f}%\")\n",
        "    print(f\"Final F1-Score: {f1:.2f}%\")\n",
        "else:\n",
        "    print(\"Error: The lengths of predicted preferences and validation labels do not match.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2Pk3r9jCOtC",
        "outputId": "fd3255f0-0bf2-445c-8f1c-4292c0d9eb36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Threshold: 0.50\n",
            "Final Prediction Accuracy: 0.401089%\n",
            "Final Precision: 0.160872%\n",
            "Final Recall: 0.401089%\n",
            "Final F1-Score: 0.229639%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "수정본들"
      ],
      "metadata": {
        "id": "edlxYt5EC2Zh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "68퍼 나온다!!!!!!!!!!!!!"
      ],
      "metadata": {
        "id": "UljP9VbQGYTZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 코사인 유사도 및 유클리디안 거리 계산 함수\n",
        "def calculate_similarity_scores(val_features, train_features):\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 코사인 유사도\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "    cosine_similarity = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "\n",
        "    # 유클리디안 거리\n",
        "    val_expand = val_features.unsqueeze(1)\n",
        "    train_expand = train_features.unsqueeze(0)\n",
        "    euclidean_distance = -torch.cdist(val_expand, train_expand).cpu().numpy()\n",
        "\n",
        "    return cosine_similarity, euclidean_distance\n",
        "\n",
        "# 코사인 유사도와 유클리디안 거리 결합\n",
        "def combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=0.5):\n",
        "    combined_score = alpha * cosine_similarity + (1 - alpha) * euclidean_distance\n",
        "    return combined_score\n",
        "\n",
        "# 최적 threshold 찾기 함수\n",
        "def find_optimal_threshold(similarity_scores, train_preferences, val_labels):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "    for threshold in np.arange(0.1, 0.9, 0.05):\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    train_len = len(train_preferences)\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            # 유효한 인덱스 범위 내에서만 접근\n",
        "            most_similar_index = min(np.argmax(score_row), train_len - 1)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값 미만인 경우 비선호로 분류\n",
        "    return predicted_preferences\n",
        "\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 데이터 불러오기 및 준비\n",
        "# 이미지 경로 및 특징 벡터 추출\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "train_preferences = [1] * len(train_features)  # 선호 라벨로 지정\n",
        "\n",
        "# 유사도 계산 및 결합 점수 산출\n",
        "cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features)\n",
        "combined_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=0.5)\n",
        "\n",
        "# 최적 threshold 찾기\n",
        "optimal_threshold = find_optimal_threshold(combined_scores, train_preferences, val_labels)\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}\")\n",
        "\n",
        "# 최적 threshold로 예측 및 성능 평가\n",
        "predicted_preferences = predict_style_preference(combined_scores, train_preferences, optimal_threshold)\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "print(f\"Final Prediction Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Final Precision: {precision*100:.2f}%\")\n",
        "print(f\"Final Recall: {recall*100:.2f}%\")\n",
        "print(f\"Final F1-Score: {f1*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "_yVuUWWbCtQU",
        "outputId": "4ef77f20-4766-4fda-87c7-f6d3e5937487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:04<00:00, 135.81it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:07<00:00, 143.03it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 69.42 GiB. GPU 0 has a total capacity of 14.75 GiB of which 14.22 GiB is free. Process 4325 has 536.00 MiB memory in use. Of the allocated memory 391.82 MiB is allocated by PyTorch, and 16.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2979db624663>\u001b[0m in \u001b[0;36m<cell line: 119>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;31m# 유사도 계산 및 결합 점수 산출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_similarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0mcombined_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_similarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-2979db624663>\u001b[0m in \u001b[0;36mcalculate_similarity_scores\u001b[0;34m(val_features, train_features)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mval_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtrain_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0meuclidean_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_expand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode)\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist_if_necessary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 69.42 GiB. GPU 0 has a total capacity of 14.75 GiB of which 14.22 GiB is free. Process 4325 has 536.00 MiB memory in use. Of the allocated memory 391.82 MiB is allocated by PyTorch, and 16.18 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 코사인 유사도 및 유클리디안 거리 계산 함수\n",
        "def calculate_similarity_scores(val_features, train_features):\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    # 코사인 유사도\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "    cosine_similarity = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "\n",
        "    # 유클리디안 거리\n",
        "    val_expand = val_features.unsqueeze(1)\n",
        "    train_expand = train_features.unsqueeze(0)\n",
        "    euclidean_distance = -torch.cdist(val_expand, train_expand).cpu().numpy()\n",
        "\n",
        "    return cosine_similarity, euclidean_distance\n",
        "\n",
        "# 최적 alpha 찾기 함수\n",
        "def find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels):\n",
        "    best_alpha = 0.5\n",
        "    best_f1 = 0\n",
        "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
        "        combined_score = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha)\n",
        "        predicted_preferences = predict_style_preference(combined_score, train_preferences)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_alpha = alpha\n",
        "    return best_alpha\n",
        "\n",
        "# 최적 threshold 찾기 함수\n",
        "def find_optimal_threshold(similarity_scores, train_preferences, val_labels):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    train_len = len(train_preferences)\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = min(np.argmax(score_row), train_len - 1)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값 미만인 경우 비선호로 분류\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 데이터 불러오기 및 준비\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "train_preferences = [1] * len(train_features)  # 선호 라벨로 지정\n",
        "\n",
        "# 유사도 계산 및 결합 점수 산출\n",
        "cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features)\n",
        "optimal_alpha = find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels)\n",
        "combined_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=optimal_alpha)\n",
        "\n",
        "# 최적 threshold 찾기\n",
        "optimal_threshold = find_optimal_threshold(combined_scores, train_preferences, val_labels)\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}, Optimal Alpha: {optimal_alpha:.2f}\")\n",
        "\n",
        "# 최적 threshold로 예측 및 성능 평가\n",
        "predicted_preferences = predict_style_preference(combined_scores, train_preferences, optimal_threshold)\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "print(f\"Final Prediction Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Final Precision: {precision*100:.2f}%\")\n",
        "print(f\"Final Recall: {recall*100:.2f}%\")\n",
        "print(f\"Final F1-Score: {f1*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "ZZP2Vv6yG2pZ",
        "outputId": "f4e86cdf-224c-47ee-c96d-aba318703ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:04<00:00, 137.40it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:08<00:00, 136.84it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 69.42 GiB. GPU 0 has a total capacity of 14.75 GiB of which 13.55 GiB is free. Process 4325 has 1.20 GiB memory in use. Of the allocated memory 1.05 GiB is allocated by PyTorch, and 22.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c002496d81a4>\u001b[0m in \u001b[0;36m<cell line: 123>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;31m# 유사도 계산 및 결합 점수 산출\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_similarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0moptimal_alpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_optimal_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_preferences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0mcombined_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_similarity_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimal_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c002496d81a4>\u001b[0m in \u001b[0;36mcalculate_similarity_scores\u001b[0;34m(val_features, train_features)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mval_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mtrain_expand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0meuclidean_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_expand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_expand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meuclidean_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/functional.py\u001b[0m in \u001b[0;36mcdist\u001b[0;34m(x1, x2, p, compute_mode)\u001b[0m\n\u001b[1;32m   1334\u001b[0m             cdist, (x1, x2), x1, x2, p=p, compute_mode=compute_mode)\n\u001b[1;32m   1335\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist_if_necessary'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcompute_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'use_mm_for_euclid_dist'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 69.42 GiB. GPU 0 has a total capacity of 14.75 GiB of which 13.55 GiB is free. Process 4325 has 1.20 GiB memory in use. Of the allocated memory 1.05 GiB is allocated by PyTorch, and 22.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아웃오브 메모리 방지"
      ],
      "metadata": {
        "id": "6mK6Xo_FOkPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 코사인 유사도 및 유클리디안 거리 계산 함수 (배치 처리 적용)\n",
        "def calculate_similarity_scores(val_features, train_features, batch_size=100):\n",
        "    cosine_similarity_list = []\n",
        "    euclidean_distance_list = []\n",
        "\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(val_features), batch_size):\n",
        "            val_batch = val_features[i:i + batch_size]\n",
        "\n",
        "            # 코사인 유사도 계산\n",
        "            val_norm = val_batch / val_batch.norm(dim=1, keepdim=True)\n",
        "            train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "            cosine_sim_batch = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "            cosine_similarity_list.append(cosine_sim_batch)\n",
        "\n",
        "            # 유클리디안 거리 계산 (CPU에서 수행)\n",
        "            val_batch_cpu = val_batch.cpu().numpy()\n",
        "            train_features_cpu = train_features.cpu().numpy()\n",
        "            euclidean_dist_batch = -np.linalg.norm(val_batch_cpu[:, None, :] - train_features_cpu[None, :, :], axis=2)\n",
        "            euclidean_distance_list.append(euclidean_dist_batch)\n",
        "\n",
        "    cosine_similarity = np.vstack(cosine_similarity_list)\n",
        "    euclidean_distance = np.vstack(euclidean_distance_list)\n",
        "\n",
        "    return cosine_similarity, euclidean_distance\n",
        "\n",
        "# 최적 alpha 찾기 함수\n",
        "def find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels):\n",
        "    best_alpha = 0.5\n",
        "    best_f1 = 0\n",
        "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
        "        combined_score = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha)\n",
        "        predicted_preferences = predict_style_preference(combined_score, train_preferences)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_alpha = alpha\n",
        "    return best_alpha\n",
        "\n",
        "# 최적 threshold 찾기 함수\n",
        "def find_optimal_threshold(similarity_scores, train_preferences, val_labels):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    train_len = len(train_preferences)\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = min(np.argmax(score_row), train_len - 1)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값 미만인 경우 비선호로 분류\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        actual, predicted, average='weighted', zero_division=0\n",
        "    )\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "\n",
        "# 데이터 불러오기 및 준비\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "train_preferences = [1] * len(train_features)  # 선호 라벨로 지정\n",
        "\n",
        "# 유사도 계산 및 결합 점수 산출\n",
        "cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features, batch_size=100)\n",
        "optimal_alpha = find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels)\n",
        "combined_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=optimal_alpha)\n",
        "\n",
        "# 최적 threshold 찾기\n",
        "optimal_threshold = find_optimal_threshold(combined_scores, train_preferences, val_labels)\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}, Optimal Alpha: {optimal_alpha:.2f}\")\n",
        "\n",
        "# 최적 threshold로 예측 및 성능 평가\n",
        "predicted_preferences = predict_style_preference(combined_scores, train_preferences, optimal_threshold)\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "print(f\"Final Prediction Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Final Precision: {precision*100:.2f}%\")\n",
        "print(f\"Final Recall: {recall*100:.2f}%\")\n",
        "print(f\"Final F1-Score: {f1*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vszx_QcNPs1_",
        "outputId": "0aae56bd-6803-416e-d317-528a54f59c35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:05<00:00, 119.65it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:07<00:00, 143.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Threshold: 0.10, Optimal Alpha: 0.60\n",
            "Final Prediction Accuracy: 67.88%\n",
            "Final Precision: 74.04%\n",
            "Final Recall: 67.88%\n",
            "Final F1-Score: 61.82%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 코사인 유사도 및 유클리디안 거리 계산 함수 (배치 방식으로 최적화)\n",
        "def calculate_similarity_scores(val_features, train_features, batch_size=100):\n",
        "    cosine_similarity_list = []\n",
        "    euclidean_distance_list = []\n",
        "\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(val_features), batch_size):\n",
        "            val_batch = val_features[i:i + batch_size]\n",
        "\n",
        "            # 코사인 유사도 계산\n",
        "            val_norm = val_batch / val_batch.norm(dim=1, keepdim=True)\n",
        "            train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "            cosine_sim_batch = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "            cosine_similarity_list.append(cosine_sim_batch)\n",
        "\n",
        "            # 유클리디안 거리 계산 (CPU에서 수행)\n",
        "            val_batch_cpu = val_batch.cpu().numpy()\n",
        "            train_features_cpu = train_features.cpu().numpy()\n",
        "            euclidean_dist_batch = -np.linalg.norm(val_batch_cpu[:, None, :] - train_features_cpu[None, :, :], axis=2)\n",
        "            euclidean_distance_list.append(euclidean_dist_batch)\n",
        "\n",
        "    cosine_similarity = np.vstack(cosine_similarity_list)\n",
        "    euclidean_distance = np.vstack(euclidean_distance_list)\n",
        "\n",
        "    return cosine_similarity, euclidean_distance\n",
        "\n",
        "# 최적 alpha 찾기 함수\n",
        "def find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels):\n",
        "    best_alpha = 0.5\n",
        "    best_f1 = 0\n",
        "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
        "        combined_score = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha)\n",
        "        predicted_preferences = predict_style_preference(combined_score, train_preferences)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_alpha = alpha\n",
        "    return best_alpha\n",
        "\n",
        "# 최적 threshold 찾기 함수\n",
        "def find_optimal_threshold(similarity_scores, train_preferences, val_labels):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    train_len = len(train_preferences)\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = min(np.argmax(score_row), train_len - 1)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)  # 임계값 미만인 경우 비선호로 분류\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 데이터 불러오기 및 준비\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "train_preferences = [1] * len(train_features)  # 선호 라벨로 지정\n",
        "\n",
        "# 유사도 계산 및 결합 점수 산출\n",
        "cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features, batch_size=100)\n",
        "optimal_alpha = find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels)\n",
        "combined_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=optimal_alpha)\n",
        "\n",
        "# 최적 threshold 찾기\n",
        "optimal_threshold = find_optimal_threshold(combined_scores, train_preferences, val_labels)\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}, Optimal Alpha: {optimal_alpha:.2f}\")\n",
        "\n",
        "# 최적 threshold로 예측 및 성능 평가\n",
        "predicted_preferences = predict_style_preference(combined_scores, train_preferences, optimal_threshold)\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "print(f\"Final Prediction Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Final Precision: {precision*100:.2f}%\")\n",
        "print(f\"Final Recall: {recall*100:.2f}%\")\n",
        "print(f\"Final F1-Score: {f1*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWe8PW6SOj5T",
        "outputId": "56d305b7-0989-4c0a-8bf9-fc01eb5c8085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:04<00:00, 139.53it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:07<00:00, 144.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Threshold: 0.10, Optimal Alpha: 0.60\n",
            "Final Prediction Accuracy: 57.89%\n",
            "Final Precision: 52.30%\n",
            "Final Recall: 57.89%\n",
            "Final F1-Score: 49.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "xlsx 내용 리스트로 바꾸기"
      ],
      "metadata": {
        "id": "2IvUyYGlC472"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 엑셀 파일 경로\n",
        "excel_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "\n",
        "# 엑셀 파일 읽기\n",
        "preferences_df = pd.read_excel(excel_file_path)\n",
        "\n",
        "# 각 Respondent ID 별로 선호 및 비선호 이미지 리스트 추출\n",
        "for idx, row in preferences_df.iterrows():\n",
        "    respondent_id = row['Respondent ID']\n",
        "    training_preferred = row['Training Style Preferred']\n",
        "    training_not_preferred = row['Training Style Not Preferred']\n",
        "    validation_preferred = row['Validation Style Preferred']\n",
        "    validation_not_preferred = row['Validation Style Not Preferred']\n",
        "\n",
        "    # 리스트 형태로 변환\n",
        "    training_preferred_list = training_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_preferred) else []\n",
        "    training_not_preferred_list = training_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_not_preferred) else []\n",
        "    validation_preferred_list = validation_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_preferred) else []\n",
        "    validation_not_preferred_list = validation_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_not_preferred) else []\n",
        "\n",
        "    # 출력\n",
        "    print(f\"Respondent ID: {respondent_id}\")\n",
        "    print(f\"  Training Preferred: {training_preferred_list}\")\n",
        "    print(f\"  Training Not Preferred: {training_not_preferred_list}\")\n",
        "    print(f\"  Validation Preferred: {validation_preferred_list}\")\n",
        "    print(f\"  Validation Not Preferred: {validation_not_preferred_list}\")\n",
        "    print(\"-\" * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGMz0jshxx1x",
        "outputId": "b8d399d4-6755-4acf-d38e-2a284464c8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Respondent ID: 62264\n",
            "  Training Preferred: ['W_07098_19_normcore_M.jpg', 'W_16449_10_sportivecasual_M.jpg', 'W_16403_10_sportivecasual_M.jpg', 'W_07307_19_normcore_M.jpg', 'W_07260_10_sportivecasual_M.jpg', 'W_01394_10_sportivecasual_M.jpg', 'W_17702_90_hiphop_M.jpg', 'W_04687_00_metrosexual_M.jpg', 'W_04324_90_hiphop_M.jpg', 'W_02693_70_hippie_M.jpg', 'W_16445_50_ivy_M.jpg', 'W_05869_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_12869_19_normcore_M.jpg', 'W_17469_19_normcore_M.jpg', 'W_17704_19_normcore_M.jpg', 'W_12309_80_bold_M.jpg', 'W_16136_80_bold_M.jpg', 'W_16428_90_hiphop_M.jpg', 'W_15159_80_bold_M.jpg', 'W_16354_80_bold_M.jpg', 'W_15477_00_metrosexual_M.jpg', 'W_16601_70_hippie_M.jpg', 'W_02721_00_metrosexual_M.jpg', 'W_16189_50_ivy_M.jpg', 'W_16189_50_ivy_M.jpg', 'W_10125_70_hippie_M.jpg', 'W_04233_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_09278_70_hippie_M.jpg', 'W_04324_90_hiphop_M.jpg', 'W_09889_10_sportivecasual_M.jpg', 'W_12413_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_12112_80_bold_M.jpg', 'W_12309_80_bold_M.jpg', 'W_16624_90_hiphop_M.jpg', 'W_10125_70_hippie_M.jpg', 'W_04233_60_mods_M.jpg', 'W_15341_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63207\n",
            "  Training Preferred: ['W_02978_10_sportivecasual_M.jpg', 'W_02771_10_sportivecasual_M.jpg', 'W_00831_19_normcore_M.jpg', 'W_17273_19_normcore_M.jpg', 'W_06993_90_hiphop_M.jpg', 'W_01737_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_15250_19_normcore_M.jpg', 'W_16390_10_sportivecasual_M.jpg', 'W_00505_10_sportivecasual_M.jpg', 'W_16361_80_bold_M.jpg', 'W_15634_80_bold_M.jpg', 'W_16404_90_hiphop_M.jpg', 'W_15193_00_metrosexual_M.jpg', 'W_11103_00_metrosexual_M.jpg', 'W_16395_80_bold_M.jpg', 'W_02938_90_hiphop_M.jpg', 'W_11033_90_hiphop_M.jpg', 'W_16684_00_metrosexual_M.jpg', 'W_01780_00_metrosexual_M.jpg', 'W_09796_60_mods_M.jpg', 'W_15376_60_mods_M.jpg', 'W_10087_70_hippie_M.jpg', 'W_09132_60_mods_M.jpg', 'W_01689_60_mods_M.jpg', 'W_04212_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_00831_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_10066_50_ivy_M.jpg', 'W_04212_50_ivy_M.jpg', 'W_06148_50_ivy_M.jpg', 'W_12247_80_bold_M.jpg', 'W_15499_70_hippie_M.jpg', 'W_12599_60_mods_M.jpg', 'W_11024_70_hippie_M.jpg', 'W_17135_00_metrosexual_M.jpg', 'W_02946_10_sportivecasual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63424\n",
            "  Training Preferred: ['W_01989_19_normcore_W.jpg', 'W_09698_19_genderless_W.jpg', 'W_19801_19_genderless_W.jpg', 'W_05786_10_sportivecasual_W.jpg', 'W_13163_90_kitsch_W.jpg', 'W_07554_70_hippie_W.jpg', 'W_05597_70_punk_W.jpg', 'W_01962_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_07715_19_normcore_W.jpg', 'W_03717_10_athleisure_W.jpg', 'W_01390_10_sportivecasual_W.jpg', 'W_05652_10_athleisure_W.jpg', 'W_07791_00_cityglam_W.jpg', 'W_12984_00_ecology_W.jpg', 'W_01886_70_hippie_W.jpg', 'W_13141_80_powersuit_W.jpg', 'W_07675_80_bodyconscious_W.jpg', 'W_05172_70_hippie_W.jpg', 'W_14997_60_minimal_W.jpg', 'W_19301_50_feminine_W.jpg', 'W_09449_50_feminine_W.jpg', 'W_19073_60_minimal_W.jpg', 'W_10944_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_09698_19_genderless_W.jpg', 'W_13163_90_kitsch_W.jpg', 'W_08641_90_hiphop_W.jpg']\n",
            "  Validation Not Preferred: ['W_13533_19_normcore_W.jpg', 'W_11235_50_classic_W.jpg', 'W_09089_60_minimal_W.jpg', 'W_11726_50_feminine_W.jpg', 'W_07445_80_bodyconscious_W.jpg', 'W_01886_70_hippie_W.jpg', 'W_08262_50_feminine_W.jpg', 'W_03717_10_athleisure_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63769\n",
            "  Training Preferred: ['W_02962_10_sportivecasual_M.jpg', 'W_09795_10_sportivecasual_M.jpg', 'W_02846_70_hippie_M.jpg', 'W_16420_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_17262_19_normcore_M.jpg', 'W_07373_19_normcore_M.jpg', 'W_06237_10_sportivecasual_M.jpg', 'W_17688_19_normcore_M.jpg', 'W_16806_00_metrosexual_M.jpg', 'W_04524_90_hiphop_M.jpg', 'W_15450_00_metrosexual_M.jpg', 'W_12337_80_bold_M.jpg', 'W_15776_70_hippie_M.jpg', 'W_11011_80_bold_M.jpg', 'W_04632_90_hiphop_M.jpg', 'W_16289_80_bold_M.jpg', 'W_15647_70_hippie_M.jpg', 'W_12408_90_hiphop_M.jpg', 'W_09763_80_bold_M.jpg', 'W_10122_60_mods_M.jpg', 'W_07123_70_hippie_M.jpg', 'W_15404_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_02962_10_sportivecasual_M.jpg', 'W_17366_19_normcore_M.jpg', 'W_03047_80_bold_M.jpg']\n",
            "  Validation Not Preferred: ['W_15404_50_ivy_M.jpg', 'W_04207_50_ivy_M.jpg', 'W_09156_50_ivy_M.jpg', 'W_16738_50_ivy_M.jpg', 'W_06533_60_mods_M.jpg', 'W_06966_19_normcore_M.jpg', 'W_12260_80_bold_M.jpg', 'W_16037_19_normcore_M.jpg', 'W_09763_80_bold_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63913\n",
            "  Training Preferred: ['W_00553_10_sportivecasual_M.jpg', 'W_04519_10_sportivecasual_M.jpg', 'W_07066_10_sportivecasual_M.jpg', 'W_09262_19_normcore_M.jpg', 'W_04759_90_hiphop_M.jpg', 'W_06883_60_mods_M.jpg', 'W_06573_60_mods_M.jpg', 'W_10082_50_ivy_M.jpg', 'W_07255_50_ivy_M.jpg', 'W_07150_70_hippie_M.jpg']\n",
            "  Training Not Preferred: ['W_16444_10_sportivecasual_M.jpg', 'W_17009_19_normcore_M.jpg', 'W_12732_90_hiphop_M.jpg', 'W_12650_90_hiphop_M.jpg', 'W_15947_80_bold_M.jpg', 'W_15624_70_hippie_M.jpg', 'W_15843_00_metrosexual_M.jpg', 'W_16121_80_bold_M.jpg', 'W_12307_50_ivy_M.jpg', 'W_10066_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_17239_19_normcore_M.jpg', 'W_01552_19_normcore_M.jpg', 'W_06883_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_04212_50_ivy_M.jpg', 'W_10066_50_ivy_M.jpg', 'W_05876_70_hippie_M.jpg', 'W_15843_00_metrosexual_M.jpg', 'W_09777_90_hiphop_M.jpg', 'W_16121_80_bold_M.jpg', 'W_15947_80_bold_M.jpg', 'W_16960_19_normcore_M.jpg', 'W_12524_00_metrosexual_M.jpg', 'W_17655_80_bold_M.jpg', 'W_16444_10_sportivecasual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64633\n",
            "  Training Preferred: ['W_25949_19_normcore_M.jpg', 'W_33251_19_normcore_M.jpg', 'W_31604_00_metrosexual_M.jpg', 'W_32384_00_metrosexual_M.jpg', 'W_00031_50_ivy_M.jpg', 'W_25518_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_28726_19_normcore_M.jpg', 'W_12663_10_sportivecasual_M.jpg', 'W_24982_90_hiphop_M.jpg', 'W_27033_80_bold_M.jpg', 'W_17499_70_hippie_M.jpg', 'W_26387_90_hiphop_M.jpg', 'W_25285_90_hiphop_M.jpg', 'W_25698_00_metrosexual_M.jpg', 'W_31694_90_hiphop_M.jpg', 'W_31925_00_metrosexual_M.jpg', 'W_32756_00_metrosexual_M.jpg', 'W_15631_80_bold_M.jpg', 'W_24816_80_bold_M.jpg', 'W_24758_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_12817_50_ivy_M.jpg', 'W_30403_60_mods_M.jpg', 'W_34004_80_bold_M.jpg', 'W_29258_80_bold_M.jpg', 'W_06797_70_hippie_M.jpg', 'W_16690_60_mods_M.jpg', 'W_16906_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_24758_50_ivy_M.jpg', 'W_26393_50_ivy_M.jpg', 'W_17414_70_hippie_M.jpg', 'W_33259_70_hippie_M.jpg', 'W_29658_90_hiphop_M.jpg', 'W_17058_19_normcore_M.jpg', 'W_27899_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59642\n",
            "  Training Preferred: ['W_13676_19_normcore_W.jpg', 'W_14814_19_normcore_W.jpg', 'W_14544_00_cityglam_W.jpg', 'W_19522_00_ecology_W.jpg', 'W_06105_10_sportivecasual_W.jpg', 'W_08346_10_athleisure_W.jpg', 'W_16917_10_athleisure_W.jpg', 'W_07819_00_ecology_W.jpg', 'W_11983_90_kitsch_W.jpg', 'W_18366_70_disco_W.jpg', 'W_13125_80_powersuit_W.jpg', 'W_03268_80_powersuit_W.jpg', 'W_02444_70_punk_W.jpg', 'W_02095_60_popart_W.jpg']\n",
            "  Training Not Preferred: ['W_06049_10_athleisure_W.jpg', 'W_03890_80_bodyconscious_W.jpg', 'W_08246_80_bodyconscious_W.jpg']\n",
            "  Validation Preferred: ['W_05716_19_normcore_W.jpg', 'W_14706_19_normcore_W.jpg', 'W_00625_80_bodyconscious_W.jpg', 'W_10984_50_feminine_W.jpg', 'W_18737_50_feminine_W.jpg', 'W_02095_60_popart_W.jpg', 'W_07643_90_grunge_W.jpg', 'W_02394_10_sportivecasual_W.jpg', 'W_08715_90_kitsch_W.jpg', 'W_00366_60_minimal_W.jpg', 'W_08492_70_punk_W.jpg', 'W_05917_60_space_W.jpg']\n",
            "  Validation Not Preferred: ['W_00359_90_grunge_W.jpg', 'W_11444_80_bodyconscious_W.jpg', 'W_18949_70_disco_W.jpg', 'W_08246_80_bodyconscious_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 28371\n",
            "  Training Preferred: ['W_17461_19_normcore_M.jpg', 'W_15402_70_hippie_M.jpg', 'W_57031_90_hiphop_M.jpg', 'W_25020_90_hiphop_M.jpg', 'W_12900_60_mods_M.jpg', 'W_51060_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_09860_10_sportivecasual_M.jpg', 'W_22928_10_sportivecasual_M.jpg', 'W_55470_19_normcore_M.jpg', 'W_12681_10_sportivecasual_M.jpg', 'W_27184_90_hiphop_M.jpg', 'W_31426_90_hiphop_M.jpg', 'W_55201_00_metrosexual_M.jpg', 'W_24949_80_bold_M.jpg', 'W_24470_70_hippie_M.jpg', 'W_33185_00_metrosexual_M.jpg', 'W_24917_80_bold_M.jpg', 'W_56065_50_ivy_M.jpg', 'W_24922_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_26393_50_ivy_M.jpg', 'W_30591_50_ivy_M.jpg', 'W_04638_00_metrosexual_M.jpg', 'W_24770_60_mods_M.jpg', 'W_50836_19_normcore_M.jpg', 'W_38585_60_mods_M.jpg', 'W_25020_90_hiphop_M.jpg', 'W_57473_10_sportivecasual_M.jpg', 'W_15402_70_hippie_M.jpg']\n",
            "  Validation Not Preferred: ['W_52140_70_hippie_M.jpg', 'W_27184_90_hiphop_M.jpg', 'W_24643_90_hiphop_M.jpg', 'W_25940_10_sportivecasual_M.jpg', 'W_24973_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63545\n",
            "  Training Preferred: ['W_08322_19_normcore_W.jpg', 'W_14897_10_sportivecasual_W.jpg', 'W_02378_10_sportivecasual_W.jpg', 'W_03587_10_sportivecasual_W.jpg', 'W_10299_90_kitsch_W.jpg', 'W_00682_70_punk_W.jpg', 'W_04993_70_hippie_W.jpg', 'W_07461_70_hippie_W.jpg', 'W_03842_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_04035_19_normcore_W.jpg', 'W_11422_00_ecology_W.jpg', 'W_11927_00_oriental_W.jpg', 'W_04087_10_athleisure_W.jpg', 'W_10919_00_ecology_W.jpg', 'W_08610_90_grunge_W.jpg', 'W_19342_70_hippie_W.jpg', 'W_18505_80_powersuit_W.jpg', 'W_13846_60_minimal_W.jpg', 'W_12003_60_minimal_W.jpg', 'W_10655_50_feminine_W.jpg', 'W_10981_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_03531_19_normcore_W.jpg', 'W_08733_90_grunge_W.jpg', 'W_03587_10_sportivecasual_W.jpg', 'W_03842_50_feminine_W.jpg']\n",
            "  Validation Not Preferred: ['W_04801_19_lounge_W.jpg', 'W_01273_90_lingerie_W.jpg', 'W_13859_10_athleisure_W.jpg', 'W_14039_00_cityglam_W.jpg', 'W_02277_80_bodyconscious_W.jpg', 'W_14357_70_disco_W.jpg', 'W_11256_80_bodyconscious_W.jpg', 'W_19356_50_feminine_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63934\n",
            "  Training Preferred: ['W_16255_19_normcore_M.jpg', 'W_12897_10_sportivecasual_M.jpg', 'W_12327_80_bold_M.jpg', 'W_05866_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_10791_19_normcore_M.jpg', 'W_01630_10_sportivecasual_M.jpg', 'W_11063_00_metrosexual_M.jpg', 'W_02755_90_hiphop_M.jpg', 'W_16236_80_bold_M.jpg', 'W_01794_00_metrosexual_M.jpg', 'W_01514_90_hiphop_M.jpg', 'W_15669_00_metrosexual_M.jpg', 'W_15224_50_ivy_M.jpg', 'W_06259_50_ivy_M.jpg', 'W_17202_60_mods_M.jpg', 'W_17603_50_ivy_M.jpg', 'W_11045_70_hippie_M.jpg', 'W_06636_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_02701_60_mods_M.jpg', 'W_17854_10_sportivecasual_M.jpg', 'W_07018_19_normcore_M.jpg', 'W_12897_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_17603_50_ivy_M.jpg', 'W_06788_60_mods_M.jpg', 'W_15569_70_hippie_M.jpg', 'W_12102_80_bold_M.jpg', 'W_15684_70_hippie_M.jpg', 'W_12342_80_bold_M.jpg', 'W_15722_70_hippie_M.jpg', 'W_17202_60_mods_M.jpg', 'W_16747_00_metrosexual_M.jpg', 'W_17619_00_metrosexual_M.jpg', 'W_11163_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64364\n",
            "  Training Preferred: ['W_16850_19_normcore_M.jpg', 'W_32885_10_sportivecasual_M.jpg', 'W_00824_10_sportivecasual_M.jpg', 'W_06254_10_sportivecasual_M.jpg', 'W_01472_19_normcore_M.jpg', 'W_04394_90_hiphop_M.jpg', 'W_24141_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_29504_19_normcore_M.jpg', 'W_17537_19_normcore_M.jpg', 'W_15172_00_metrosexual_M.jpg', 'W_24903_80_bold_M.jpg', 'W_25981_80_bold_M.jpg', 'W_12099_80_bold_M.jpg', 'W_16659_00_metrosexual_M.jpg', 'W_01615_90_hiphop_M.jpg', 'W_26631_80_bold_M.jpg', 'W_00107_00_metrosexual_M.jpg', 'W_26093_00_metrosexual_M.jpg', 'W_24084_70_hippie_M.jpg', 'W_23904_50_ivy_M.jpg', 'W_23983_60_mods_M.jpg', 'W_32136_50_ivy_M.jpg', 'W_12207_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_26200_50_ivy_M.jpg', 'W_24141_50_ivy_M.jpg', 'W_04670_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_23904_50_ivy_M.jpg', 'W_32136_50_ivy_M.jpg', 'W_25209_90_hiphop_M.jpg', 'W_29993_90_hiphop_M.jpg', 'W_16281_70_hippie_M.jpg', 'W_24109_60_mods_M.jpg', 'W_25981_80_bold_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59083\n",
            "  Training Preferred: ['W_12464_19_normcore_M.jpg', 'W_17945_10_sportivecasual_M.jpg', 'W_09799_19_normcore_M.jpg', 'W_07327_19_normcore_M.jpg', 'W_12252_80_bold_M.jpg', 'W_01704_90_hiphop_M.jpg', 'W_06547_00_metrosexual_M.jpg', 'W_06836_00_metrosexual_M.jpg', 'W_10803_80_bold_M.jpg', 'W_15367_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_16435_10_sportivecasual_M.jpg', 'W_18545_19_normcore_M.jpg', 'W_17365_90_hiphop_M.jpg', 'W_12593_00_metrosexual_M.jpg', 'W_12533_80_bold_M.jpg', 'W_12613_70_hippie_M.jpg', 'W_16541_50_ivy_M.jpg', 'W_02765_70_hippie_M.jpg']\n",
            "  Validation Preferred: ['W_04643_50_ivy_M.jpg', 'W_16466_10_sportivecasual_M.jpg', 'W_12656_00_metrosexual_M.jpg', 'W_09285_00_metrosexual_M.jpg', 'W_06190_60_mods_M.jpg', 'W_04629_90_hiphop_M.jpg', 'W_06547_00_metrosexual_M.jpg']\n",
            "  Validation Not Preferred: ['W_16541_50_ivy_M.jpg', 'W_15375_80_bold_M.jpg', 'W_15998_80_bold_M.jpg', 'W_17414_70_hippie_M.jpg', 'W_01559_10_sportivecasual_M.jpg', 'W_12410_70_hippie_M.jpg', 'W_17447_80_bold_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59704\n",
            "  Training Preferred: ['W_07211_00_metrosexual_M.jpg', 'W_06558_60_mods_M.jpg', 'W_04636_50_ivy_M.jpg', 'W_02728_60_mods_M.jpg', 'W_01549_50_ivy_M.jpg', 'W_01853_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_04573_10_sportivecasual_M.jpg', 'W_17017_10_sportivecasual_M.jpg', 'W_00026_10_sportivecasual_M.jpg', 'W_11141_19_normcore_M.jpg', 'W_06926_90_hiphop_M.jpg', 'W_15595_00_metrosexual_M.jpg', 'W_12881_90_hiphop_M.jpg', 'W_12476_90_hiphop_M.jpg', 'W_16676_90_hiphop_M.jpg', 'W_15732_00_metrosexual_M.jpg', 'W_15815_70_hippie_M.jpg', 'W_00517_70_hippie_M.jpg', 'W_15120_60_mods_M.jpg', 'W_12821_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_04636_50_ivy_M.jpg', 'W_01549_50_ivy_M.jpg', 'W_02728_60_mods_M.jpg', 'W_12092_80_bold_M.jpg', 'W_16219_70_hippie_M.jpg', 'W_01853_60_mods_M.jpg', 'W_15244_80_bold_M.jpg']\n",
            "  Validation Not Preferred: ['W_17697_50_ivy_M.jpg', 'W_19833_50_ivy_M.jpg', 'W_12476_90_hiphop_M.jpg', 'W_06875_90_hiphop_M.jpg', 'W_15120_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63405\n",
            "  Training Preferred: ['W_04684_90_hiphop_M.jpg', 'W_02931_00_metrosexual_M.jpg', 'W_01853_60_mods_M.jpg', 'W_06785_50_ivy_M.jpg', 'W_15294_50_ivy_M.jpg', 'W_15400_60_mods_M.jpg', 'W_06812_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_06691_10_sportivecasual_M.jpg', 'W_17108_19_normcore_M.jpg', 'W_17454_80_bold_M.jpg', 'W_15782_70_hippie_M.jpg', 'W_15517_70_hippie_M.jpg', 'W_17443_90_hiphop_M.jpg', 'W_17219_70_hippie_M.jpg', 'W_15134_80_bold_M.jpg', 'W_15140_80_bold_M.jpg', 'W_12383_80_bold_M.jpg', 'W_12904_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_15294_50_ivy_M.jpg', 'W_04522_50_ivy_M.jpg', 'W_04684_90_hiphop_M.jpg', 'W_02677_60_mods_M.jpg', 'W_01853_60_mods_M.jpg', 'W_06860_19_normcore_M.jpg', 'W_02879_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_12904_50_ivy_M.jpg', 'W_16501_70_hippie_M.jpg', 'W_17443_90_hiphop_M.jpg', 'W_15140_80_bold_M.jpg', 'W_16755_00_metrosexual_M.jpg', 'W_12304_80_bold_M.jpg', 'W_07187_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 66469\n",
            "  Training Preferred: ['T_00456_10_sportivecasual_M.jpg', 'T_01322_19_normcore_M.jpg', 'T_01883_10_sportivecasual_M.jpg', 'T_03772_90_hiphop_M.jpg', 'W_59268_70_hippie_M.jpg', 'W_58066_80_bold_M.jpg', 'W_06657_60_mods_M.jpg', 'W_10810_60_mods_M.jpg', 'W_00486_60_mods_M.jpg', 'W_06532_60_mods_M.jpg', 'W_51362_50_ivy_M.jpg', 'W_51186_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_55375_90_hiphop_M.jpg', 'W_55609_90_hiphop_M.jpg', 'W_55616_80_bold_M.jpg', 'T_06076_60_mods_M.jpg', 'W_51757_50_ivy_M.jpg', 'W_15861_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_51577_50_ivy_M.jpg', 'W_52231_50_ivy_M.jpg', 'T_01514_50_ivy_M.jpg', 'W_53446_80_bold_M.jpg', 'W_12517_70_hippie_M.jpg', 'W_52417_00_metrosexual_M.jpg', 'W_53808_80_bold_M.jpg', 'T_00456_10_sportivecasual_M.jpg', 'T_07990_60_mods_M.jpg', 'T_01123_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_58887_00_metrosexual_M.jpg', 'W_24647_70_hippie_M.jpg', 'W_24553_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 60173\n",
            "  Training Preferred: ['W_01268_19_normcore_W.jpg', 'W_09499_19_normcore_W.jpg', 'W_12994_19_genderless_W.jpg', 'W_08869_10_sportivecasual_W.jpg', 'W_01380_10_sportivecasual_W.jpg', 'W_14216_10_sportivecasual_W.jpg', 'W_05458_10_athleisure_W.jpg', 'W_09755_00_ecology_W.jpg', 'W_06015_80_powersuit_W.jpg', 'W_07964_70_military_W.jpg', 'W_14099_50_classic_W.jpg', 'W_09079_60_popart_W.jpg', 'W_03510_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_19553_00_ecology_W.jpg', 'W_19273_00_ecology_W.jpg', 'W_04877_00_oriental_W.jpg', 'W_10902_90_lingerie_W.jpg', 'W_07408_90_lingerie_W.jpg', 'W_14299_70_disco_W.jpg', 'W_06402_80_powersuit_W.jpg', 'W_14386_80_powersuit_W.jpg', 'W_01911_70_hippie_W.jpg', 'W_09497_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_14570_60_minimal_W.jpg', 'W_00152_50_feminine_W.jpg', 'W_06015_80_powersuit_W.jpg']\n",
            "  Validation Not Preferred: ['W_14221_80_bodyconscious_W.jpg', 'W_01236_10_sportivecasual_W.jpg', 'W_18094_60_space_W.jpg', 'W_14299_70_disco_W.jpg', 'W_00351_70_hippie_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 61250\n",
            "  Training Preferred: ['W_62598_19_normcore_W.jpg', 'W_68175_19_normcore_W.jpg', 'W_62690_00_oriental_W.jpg', 'W_62541_90_kitsch_W.jpg', 'W_47251_70_hippie_W.jpg', 'W_47873_70_punk_W.jpg', 'W_42248_70_punk_W.jpg', 'W_13173_50_feminine_W.jpg', 'W_01933_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_50293_19_normcore_W.jpg', 'W_20251_19_normcore_W.jpg', 'W_21868_00_ecology_W.jpg', 'W_43573_90_hiphop_W.jpg', 'W_42046_70_punk_W.jpg', 'W_26909_60_space_W.jpg', 'W_48362_60_popart_W.jpg', 'W_34093_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_62253_19_lounge_W.jpg', 'W_65122_10_sportivecasual_W.jpg', 'W_08913_10_athleisure_W.jpg', 'W_01387_50_feminine_W.jpg', 'W_28373_80_powersuit_W.jpg', 'W_47408_80_powersuit_W.jpg', 'W_34504_80_bodyconscious_W.jpg', 'W_01933_50_feminine_W.jpg', 'W_10184_50_feminine_W.jpg', 'W_44789_80_powersuit_W.jpg', 'W_29347_80_bodyconscious_W.jpg']\n",
            "  Validation Not Preferred: ['W_61790_10_sportivecasual_W.jpg', 'W_20986_70_disco_W.jpg', 'W_34093_60_minimal_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 61859\n",
            "  Training Preferred: []\n",
            "  Training Not Preferred: ['W_12663_10_sportivecasual_M.jpg', 'W_17643_19_normcore_M.jpg', 'W_04363_10_sportivecasual_M.jpg', 'W_29186_10_sportivecasual_M.jpg', 'W_04743_19_normcore_M.jpg', 'W_02966_10_sportivecasual_M.jpg', 'W_24995_10_sportivecasual_M.jpg', 'W_29051_90_hiphop_M.jpg', 'W_24315_70_hippie_M.jpg', 'W_17703_80_bold_M.jpg', 'W_24062_80_bold_M.jpg', 'W_16939_70_hippie_M.jpg', 'W_07364_00_metrosexual_M.jpg', 'W_12504_90_hiphop_M.jpg', 'W_32257_90_hiphop_M.jpg', 'W_24403_00_metrosexual_M.jpg', 'W_24130_60_mods_M.jpg', 'W_06583_50_ivy_M.jpg', 'W_30443_60_mods_M.jpg', 'W_24031_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_07290_50_ivy_M.jpg', 'W_00012_50_ivy_M.jpg']\n",
            "  Validation Not Preferred: ['W_26211_50_ivy_M.jpg', 'W_00073_50_ivy_M.jpg', 'W_44321_80_bold_M.jpg', 'W_25194_00_metrosexual_M.jpg', 'W_09119_60_mods_M.jpg', 'W_32257_90_hiphop_M.jpg', 'W_24556_19_normcore_M.jpg', 'W_25163_90_hiphop_M.jpg', 'W_24130_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63435\n",
            "  Training Preferred: ['W_08285_19_normcore_W.jpg', 'W_19407_19_normcore_W.jpg', 'W_02585_19_normcore_W.jpg', 'W_01041_10_sportivecasual_W.jpg', 'W_19010_00_oriental_W.jpg', 'W_09962_00_oriental_W.jpg', 'W_18401_90_lingerie_W.jpg', 'W_13650_90_hiphop_W.jpg', 'W_04192_60_minimal_W.jpg', 'W_10151_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_00473_19_genderless_W.jpg', 'W_08838_10_athleisure_W.jpg', 'W_05386_00_cityglam_W.jpg', 'W_11589_90_kitsch_W.jpg', 'W_03787_80_bodyconscious_W.jpg', 'W_14444_80_bodyconscious_W.jpg', 'W_14055_60_minimal_W.jpg', 'W_14345_60_space_W.jpg', 'W_14647_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_19158_90_kitsch_W.jpg', 'W_08285_19_normcore_W.jpg', 'W_06030_90_hiphop_W.jpg', 'W_13277_50_classic_W.jpg', 'W_01896_10_sportivecasual_W.jpg', 'W_02275_70_disco_W.jpg', 'W_04854_50_feminine_W.jpg', 'W_02557_00_ecology_W.jpg']\n",
            "  Validation Not Preferred: ['W_13251_19_normcore_W.jpg', 'W_14444_80_bodyconscious_W.jpg', 'W_07871_00_cityglam_W.jpg', 'W_14055_60_minimal_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63481\n",
            "  Training Preferred: ['W_01480_10_sportivecasual_M.jpg', 'W_16975_10_sportivecasual_M.jpg', 'W_16131_80_bold_M.jpg', 'W_05894_90_hiphop_M.jpg', 'W_01636_90_hiphop_M.jpg', 'W_03033_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_16460_19_normcore_M.jpg', 'W_04709_90_hiphop_M.jpg', 'W_04727_00_metrosexual_M.jpg', 'W_12336_80_bold_M.jpg', 'W_16039_70_hippie_M.jpg', 'W_15574_00_metrosexual_M.jpg', 'W_15184_60_mods_M.jpg', 'W_00490_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_12817_50_ivy_M.jpg', 'W_00073_50_ivy_M.jpg', 'W_02837_00_metrosexual_M.jpg', 'W_10079_60_mods_M.jpg', 'W_07238_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_00946_50_ivy_M.jpg', 'W_15184_60_mods_M.jpg', 'W_17032_10_sportivecasual_M.jpg', 'W_06867_60_mods_M.jpg', 'W_17874_80_bold_M.jpg', 'W_00103_70_hippie_M.jpg', 'W_10844_60_mods_M.jpg', 'W_16172_70_hippie_M.jpg', 'W_16347_70_hippie_M.jpg', 'W_07077_19_normcore_M.jpg', 'W_16460_19_normcore_M.jpg', 'W_06626_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63910\n",
            "  Training Preferred: ['W_01666_19_normcore_M.jpg', 'W_17529_70_hippie_M.jpg', 'W_09813_90_hiphop_M.jpg', 'W_04697_90_hiphop_M.jpg', 'W_12224_80_bold_M.jpg', 'W_00495_60_mods_M.jpg', 'W_17962_50_ivy_M.jpg', 'W_04678_50_ivy_M.jpg', 'W_01595_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_15974_80_bold_M.jpg', 'W_07012_00_metrosexual_M.jpg', 'W_15578_70_hippie_M.jpg', 'W_12197_80_bold_M.jpg', 'W_04273_00_metrosexual_M.jpg', 'W_15766_00_metrosexual_M.jpg', 'W_16380_80_bold_M.jpg', 'W_15681_80_bold_M.jpg', 'W_10779_50_ivy_M.jpg', 'W_15262_60_mods_M.jpg', 'W_16962_60_mods_M.jpg', 'W_15186_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_04678_50_ivy_M.jpg', 'W_00540_90_hiphop_M.jpg', 'W_00033_60_mods_M.jpg', 'W_17310_70_hippie_M.jpg', 'W_16851_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_10779_50_ivy_M.jpg', 'W_17333_19_normcore_M.jpg', 'W_17857_00_metrosexual_M.jpg', 'W_16032_80_bold_M.jpg', 'W_15766_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64221\n",
            "  Training Preferred: ['W_28698_10_sportivecasual_M.jpg', 'W_32524_00_metrosexual_M.jpg', 'W_25039_90_hiphop_M.jpg', 'W_24013_60_mods_M.jpg', 'W_28728_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_33162_19_normcore_M.jpg', 'W_16008_80_bold_M.jpg', 'W_17747_80_bold_M.jpg', 'W_28207_90_hiphop_M.jpg', 'W_17663_80_bold_M.jpg', 'W_25471_70_hippie_M.jpg', 'W_12130_80_bold_M.jpg', 'W_26395_90_hiphop_M.jpg', 'W_16295_70_hippie_M.jpg', 'W_26397_70_hippie_M.jpg', 'W_10834_50_ivy_M.jpg', 'W_15129_50_ivy_M.jpg', 'W_07333_70_hippie_M.jpg', 'W_24053_60_mods_M.jpg', 'W_15389_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_10783_50_ivy_M.jpg', 'W_28453_10_sportivecasual_M.jpg', 'W_28925_90_hiphop_M.jpg', 'W_25086_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_26397_70_hippie_M.jpg', 'W_07333_70_hippie_M.jpg', 'W_12410_70_hippie_M.jpg', 'W_17747_80_bold_M.jpg', 'W_15508_60_mods_M.jpg', 'W_16295_70_hippie_M.jpg', 'W_02936_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64346\n",
            "  Training Preferred: ['W_09289_19_normcore_M.jpg', 'W_28693_10_sportivecasual_M.jpg', 'W_00856_10_sportivecasual_M.jpg', 'W_12527_70_hippie_M.jpg', 'W_12155_80_bold_M.jpg', 'W_24977_70_hippie_M.jpg', 'W_16233_80_bold_M.jpg', 'W_24268_00_metrosexual_M.jpg', 'W_29990_90_hiphop_M.jpg', 'W_30040_60_mods_M.jpg', 'W_24103_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_25065_10_sportivecasual_M.jpg', 'W_16822_19_normcore_M.jpg', 'W_24250_90_hiphop_M.jpg', 'W_25721_90_hiphop_M.jpg', 'W_16121_80_bold_M.jpg', 'W_12268_80_bold_M.jpg', 'W_02678_50_ivy_M.jpg', 'W_24931_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_09154_50_ivy_M.jpg', 'W_24103_50_ivy_M.jpg', 'W_29918_19_normcore_M.jpg', 'W_07316_00_metrosexual_M.jpg', 'W_29990_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_24931_50_ivy_M.jpg', 'W_00496_60_mods_M.jpg', 'W_16430_90_hiphop_M.jpg', 'W_24838_70_hippie_M.jpg', 'W_26099_19_normcore_M.jpg', 'W_24250_90_hiphop_M.jpg', 'W_16121_80_bold_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 65139\n",
            "  Training Preferred: ['W_16523_19_normcore_M.jpg', 'W_64254_19_normcore_M.jpg']\n",
            "  Training Not Preferred: ['W_26315_19_normcore_M.jpg', 'W_25400_19_normcore_M.jpg', 'W_01898_19_normcore_M.jpg', 'W_17098_19_normcore_M.jpg', 'W_58911_00_metrosexual_M.jpg', 'W_52693_00_metrosexual_M.jpg', 'W_62525_90_hiphop_M.jpg', 'W_16063_80_bold_M.jpg', 'W_15618_70_hippie_M.jpg', 'W_57822_90_hiphop_M.jpg', 'W_64955_50_ivy_M.jpg', 'W_50824_50_ivy_M.jpg', 'W_24432_60_mods_M.jpg', 'W_51514_50_ivy_M.jpg', 'W_24717_60_mods_M.jpg', 'W_66114_50_ivy_M.jpg', 'W_24968_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_63644_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_51514_50_ivy_M.jpg', 'W_29942_50_ivy_M.jpg', 'W_31913_90_hiphop_M.jpg', 'W_54129_19_normcore_M.jpg', 'W_28314_10_sportivecasual_M.jpg', 'W_24717_60_mods_M.jpg', 'W_24517_70_hippie_M.jpg', 'W_58793_00_metrosexual_M.jpg', 'W_52693_00_metrosexual_M.jpg', 'W_54465_80_bold_M.jpg', 'W_27138_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59812\n",
            "  Training Preferred: ['W_06672_10_sportivecasual_M.jpg', 'W_06777_10_sportivecasual_M.jpg', 'W_06874_90_hiphop_M.jpg']\n",
            "  Training Not Preferred: ['W_11085_19_normcore_M.jpg', 'W_03044_19_normcore_M.jpg', 'W_17916_10_sportivecasual_M.jpg', 'W_15924_19_normcore_M.jpg', 'W_06822_19_normcore_M.jpg', 'W_15912_90_hiphop_M.jpg', 'W_17648_80_bold_M.jpg', 'W_12564_00_metrosexual_M.jpg', 'W_06759_90_hiphop_M.jpg', 'W_16661_00_metrosexual_M.jpg', 'W_12120_80_bold_M.jpg', 'W_15579_70_hippie_M.jpg', 'W_17251_50_ivy_M.jpg', 'W_15479_50_ivy_M.jpg', 'W_05879_70_hippie_M.jpg']\n",
            "  Validation Preferred: ['W_06874_90_hiphop_M.jpg', 'W_06609_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_16630_50_ivy_M.jpg', 'W_12773_50_ivy_M.jpg', 'W_17347_00_metrosexual_M.jpg', 'W_15508_60_mods_M.jpg', 'W_15497_70_hippie_M.jpg', 'W_12564_00_metrosexual_M.jpg', 'W_16047_70_hippie_M.jpg', 'W_09278_70_hippie_M.jpg', 'W_15192_00_metrosexual_M.jpg', 'W_12746_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 60184\n",
            "  Training Preferred: ['W_01687_19_normcore_M.jpg', 'W_06294_19_normcore_M.jpg', 'W_17427_00_metrosexual_M.jpg', 'W_29661_90_hiphop_M.jpg', 'W_17348_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_12453_10_sportivecasual_M.jpg', 'W_27913_00_metrosexual_M.jpg', 'W_16016_70_hippie_M.jpg', 'W_27000_00_metrosexual_M.jpg', 'W_12095_80_bold_M.jpg', 'W_27819_70_hippie_M.jpg', 'W_40976_00_metrosexual_M.jpg', 'W_28377_80_bold_M.jpg', 'W_29381_90_hiphop_M.jpg', 'W_25030_70_hippie_M.jpg', 'W_24985_90_hiphop_M.jpg', 'W_12744_50_ivy_M.jpg', 'W_04245_70_hippie_M.jpg', 'W_17185_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_00004_50_ivy_M.jpg', 'W_27765_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_19833_50_ivy_M.jpg', 'W_12744_50_ivy_M.jpg', 'W_24590_60_mods_M.jpg', 'W_25761_90_hiphop_M.jpg', 'W_24696_80_bold_M.jpg', 'W_27819_70_hippie_M.jpg', 'W_04245_70_hippie_M.jpg', 'W_29381_90_hiphop_M.jpg', 'W_12453_10_sportivecasual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 60234\n",
            "  Training Preferred: ['W_06990_10_sportivecasual_M.jpg', 'W_01693_19_normcore_M.jpg', 'W_02762_90_hiphop_M.jpg', 'W_17337_50_ivy_M.jpg', 'W_16539_50_ivy_M.jpg', 'W_12748_50_ivy_M.jpg', 'W_07102_50_ivy_M.jpg', 'W_10107_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_17508_80_bold_M.jpg', 'W_12783_00_metrosexual_M.jpg', 'W_02844_90_hiphop_M.jpg', 'W_18424_80_bold_M.jpg', 'W_15465_70_hippie_M.jpg', 'W_16755_00_metrosexual_M.jpg', 'W_16673_70_hippie_M.jpg', 'W_16365_70_hippie_M.jpg', 'W_16383_70_hippie_M.jpg', 'W_15423_80_bold_M.jpg', 'W_06546_60_mods_M.jpg', 'W_15259_60_mods_M.jpg', 'W_06786_70_hippie_M.jpg']\n",
            "  Validation Preferred: ['W_12789_00_metrosexual_M.jpg', 'W_10107_60_mods_M.jpg', 'W_17413_00_metrosexual_M.jpg', 'W_02908_10_sportivecasual_M.jpg', 'W_02770_90_hiphop_M.jpg', 'W_00842_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_16755_00_metrosexual_M.jpg', 'W_16698_00_metrosexual_M.jpg', 'W_06786_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62653\n",
            "  Training Preferred: ['W_30565_19_normcore_M.jpg', 'W_25658_19_normcore_M.jpg', 'W_33198_19_normcore_M.jpg', 'W_26093_00_metrosexual_M.jpg', 'W_02983_90_hiphop_M.jpg', 'W_02958_60_mods_M.jpg', 'W_06287_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_24226_10_sportivecasual_M.jpg', 'W_31888_19_normcore_M.jpg', 'W_28141_19_normcore_M.jpg', 'W_25734_10_sportivecasual_M.jpg', 'W_25941_10_sportivecasual_M.jpg', 'W_26881_80_bold_M.jpg', 'W_23971_90_hiphop_M.jpg', 'W_15586_70_hippie_M.jpg', 'W_24493_70_hippie_M.jpg', 'W_26584_50_ivy_M.jpg', 'W_24865_60_mods_M.jpg', 'W_32800_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_27850_50_ivy_M.jpg', 'W_12880_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_49765_50_ivy_M.jpg', 'W_27765_60_mods_M.jpg', 'W_26634_90_hiphop_M.jpg', 'W_25174_70_hippie_M.jpg', 'W_24535_70_hippie_M.jpg', 'W_24493_70_hippie_M.jpg', 'W_23971_90_hiphop_M.jpg', 'W_28141_19_normcore_M.jpg', 'W_32800_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63316\n",
            "  Training Preferred: ['W_06484_19_lounge_W.jpg', 'W_05594_19_genderless_W.jpg', 'W_08480_19_normcore_W.jpg', 'W_05580_10_sportivecasual_W.jpg', 'W_07586_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_02200_19_normcore_W.jpg', 'W_11796_19_genderless_W.jpg', 'W_11950_00_oriental_W.jpg', 'W_18613_00_cityglam_W.jpg', 'W_19165_00_cityglam_W.jpg', 'W_08639_10_sportivecasual_W.jpg', 'W_01192_00_oriental_W.jpg', 'W_14600_90_kitsch_W.jpg', 'W_08115_90_hiphop_W.jpg', 'W_05736_90_kitsch_W.jpg', 'W_13359_80_powersuit_W.jpg', 'W_09524_50_classic_W.jpg', 'W_13755_60_minimal_W.jpg', 'W_19177_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_06498_19_normcore_W.jpg', 'W_05580_10_sportivecasual_W.jpg', 'W_05791_10_sportivecasual_W.jpg']\n",
            "  Validation Not Preferred: ['W_15071_00_cityglam_W.jpg', 'W_13254_80_powersuit_W.jpg', 'W_05736_90_kitsch_W.jpg', 'W_08115_90_hiphop_W.jpg', 'W_02392_50_feminine_W.jpg', 'W_18613_00_cityglam_W.jpg', 'W_19945_70_hippie_W.jpg', 'W_13359_80_powersuit_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63369\n",
            "  Training Preferred: ['W_03000_19_normcore_M.jpg', 'W_06817_19_normcore_M.jpg', 'W_09785_19_normcore_M.jpg', 'W_01428_10_sportivecasual_M.jpg', 'W_06970_10_sportivecasual_M.jpg', 'W_04733_90_hiphop_M.jpg', 'W_15207_60_mods_M.jpg', 'W_09760_60_mods_M.jpg', 'W_01549_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_17288_19_normcore_M.jpg', 'W_04526_00_metrosexual_M.jpg', 'W_04469_90_hiphop_M.jpg', 'W_15442_70_hippie_M.jpg', 'W_16502_90_hiphop_M.jpg', 'W_12487_90_hiphop_M.jpg', 'W_15884_80_bold_M.jpg', 'W_10134_50_ivy_M.jpg', 'W_01509_00_metrosexual_M.jpg', 'W_06563_70_hippie_M.jpg']\n",
            "  Validation Preferred: ['W_10112_50_ivy_M.jpg', 'W_01549_50_ivy_M.jpg', 'W_06525_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_12393_50_ivy_M.jpg', 'W_15486_00_metrosexual_M.jpg', 'W_11067_00_metrosexual_M.jpg', 'W_17539_00_metrosexual_M.jpg', 'W_17841_80_bold_M.jpg', 'W_12298_70_hippie_M.jpg', 'W_12106_80_bold_M.jpg', 'W_15503_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63505\n",
            "  Training Preferred: ['W_11117_19_normcore_M.jpg', 'W_07078_10_sportivecasual_M.jpg', 'W_12683_10_sportivecasual_M.jpg', 'W_17155_19_normcore_M.jpg', 'W_09186_10_sportivecasual_M.jpg', 'W_01474_10_sportivecasual_M.jpg', 'W_17123_19_normcore_M.jpg', 'W_12328_80_bold_M.jpg', 'W_17803_80_bold_M.jpg', 'W_06610_90_hiphop_M.jpg', 'W_17907_00_metrosexual_M.jpg', 'W_19586_70_hippie_M.jpg', 'W_06633_50_ivy_M.jpg', 'W_12393_50_ivy_M.jpg', 'W_10111_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_00507_90_hiphop_M.jpg', 'W_15723_70_hippie_M.jpg']\n",
            "  Validation Preferred: ['W_12393_50_ivy_M.jpg', 'W_17697_50_ivy_M.jpg', 'W_02845_60_mods_M.jpg', 'W_12789_00_metrosexual_M.jpg', 'W_00511_90_hiphop_M.jpg', 'W_12518_90_hiphop_M.jpg', 'W_16219_70_hippie_M.jpg', 'W_15520_70_hippie_M.jpg', 'W_07058_19_normcore_M.jpg', 'W_09278_70_hippie_M.jpg', 'W_02691_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_16699_00_metrosexual_M.jpg', 'W_16698_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63583\n",
            "  Training Preferred: ['W_02100_00_oriental_W.jpg', 'W_08874_10_sportivecasual_W.jpg', 'W_03569_10_sportivecasual_W.jpg', 'W_00385_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_18920_00_oriental_W.jpg', 'W_03693_10_athleisure_W.jpg', 'W_10223_00_oriental_W.jpg', 'W_18030_90_kitsch_W.jpg', 'W_01248_90_hiphop_W.jpg', 'W_08175_70_hippie_W.jpg', 'W_19311_70_punk_W.jpg', 'W_13758_80_bodyconscious_W.jpg', 'W_19964_80_powersuit_W.jpg', 'W_19278_80_bodyconscious_W.jpg', 'W_04901_50_feminine_W.jpg', 'W_18543_60_popart_W.jpg']\n",
            "  Validation Preferred: ['W_04845_19_lounge_W.jpg', 'W_08951_19_normcore_W.jpg', 'W_03663_10_sportivecasual_W.jpg', 'W_05258_90_kitsch_W.jpg', 'W_14512_60_minimal_W.jpg', 'W_03569_10_sportivecasual_W.jpg', 'W_03732_10_sportivecasual_W.jpg', 'W_18058_50_classic_W.jpg']\n",
            "  Validation Not Preferred: ['W_08008_90_hiphop_W.jpg', 'W_19559_00_oriental_W.jpg', 'W_19825_70_hippie_W.jpg', 'W_19278_80_bodyconscious_W.jpg', 'W_07877_70_disco_W.jpg', 'W_03717_10_athleisure_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64216\n",
            "  Training Preferred: ['W_30413_19_normcore_M.jpg', 'W_16442_10_sportivecasual_M.jpg', 'W_17309_10_sportivecasual_M.jpg', 'W_02966_10_sportivecasual_M.jpg', 'W_27674_10_sportivecasual_M.jpg', 'W_17855_90_hiphop_M.jpg', 'W_02816_60_mods_M.jpg', 'W_12793_50_ivy_M.jpg', 'W_04217_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_31918_19_normcore_M.jpg', 'W_25452_19_normcore_M.jpg', 'W_32426_70_hippie_M.jpg', 'W_26288_70_hippie_M.jpg', 'W_24486_70_hippie_M.jpg', 'W_15661_70_hippie_M.jpg', 'W_15666_90_hiphop_M.jpg', 'W_24931_50_ivy_M.jpg', 'W_02685_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_15662_19_normcore_M.jpg', 'W_07271_10_sportivecasual_M.jpg', 'W_02816_60_mods_M.jpg', 'W_27040_80_bold_M.jpg']\n",
            "  Validation Not Preferred: ['W_24931_50_ivy_M.jpg', 'W_24486_70_hippie_M.jpg', 'W_27773_80_bold_M.jpg', 'W_24553_70_hippie_M.jpg', 'W_33002_60_mods_M.jpg', 'W_26288_70_hippie_M.jpg', 'W_15661_70_hippie_M.jpg', 'W_23971_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64662\n",
            "  Training Preferred: ['W_36163_19_lounge_W.jpg', 'W_21314_90_kitsch_W.jpg', 'W_08270_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_41537_10_sportivecasual_W.jpg', 'W_24433_19_genderless_W.jpg', 'W_40520_19_genderless_W.jpg', 'W_22067_19_normcore_W.jpg', 'W_46922_00_cityglam_W.jpg', 'W_14425_10_sportivecasual_W.jpg', 'W_35009_10_sportivecasual_W.jpg', 'W_46562_80_powersuit_W.jpg', 'W_28695_90_kitsch_W.jpg', 'W_29108_90_kitsch_W.jpg', 'W_46905_80_powersuit_W.jpg', 'W_40817_70_military_W.jpg', 'W_34872_70_military_W.jpg', 'W_20551_70_hippie_W.jpg', 'W_22856_60_minimal_W.jpg', 'W_47546_60_minimal_W.jpg', 'W_40322_60_space_W.jpg']\n",
            "  Validation Preferred: ['W_46459_80_powersuit_W.jpg', 'W_08691_10_sportivecasual_W.jpg', 'W_26803_70_hippie_W.jpg']\n",
            "  Validation Not Preferred: ['W_34808_10_sportivecasual_W.jpg', 'W_33876_60_popart_W.jpg', 'W_18391_50_classic_W.jpg', 'W_22623_00_cityglam_W.jpg', 'W_43283_90_grunge_W.jpg', 'W_47546_60_minimal_W.jpg', 'W_36130_00_ecology_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 9096\n",
            "  Training Preferred: ['W_03582_19_normcore_W.jpg', 'W_11899_00_oriental_W.jpg', 'W_03784_00_cityglam_W.jpg', 'W_11694_10_sportivecasual_W.jpg', 'W_06435_10_sportivecasual_W.jpg', 'W_11735_70_hippie_W.jpg', 'W_14376_70_disco_W.jpg', 'W_08797_70_disco_W.jpg', 'W_19987_50_feminine_W.jpg', 'W_14507_60_minimal_W.jpg', 'W_03160_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_03461_19_normcore_W.jpg', 'W_08232_19_normcore_W.jpg', 'W_12033_00_cityglam_W.jpg', 'W_00191_10_sportivecasual_W.jpg', 'W_14393_70_hippie_W.jpg', 'W_05941_60_popart_W.jpg', 'W_14035_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_19205_00_oriental_W.jpg', 'W_19075_50_classic_W.jpg', 'W_14783_60_minimal_W.jpg', 'W_18714_90_kitsch_W.jpg', 'W_01075_10_sportivecasual_W.jpg']\n",
            "  Validation Not Preferred: ['W_00191_10_sportivecasual_W.jpg', 'W_10686_50_classic_W.jpg', 'W_06011_80_powersuit_W.jpg', 'W_05941_60_popart_W.jpg', 'W_14272_80_bodyconscious_W.jpg', 'W_14225_50_feminine_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 66592\n",
            "  Training Preferred: ['T_04656_19_genderless_W.jpg', 'W_42363_10_sportivecasual_W.jpg', 'W_46907_80_powersuit_W.jpg', 'W_53133_90_hiphop_W.jpg', 'W_53583_90_hiphop_W.jpg', 'W_53861_90_kitsch_W.jpg', 'W_10028_50_classic_W.jpg', 'T_00253_60_popart_W.jpg', 'W_44918_60_minimal_W.jpg', 'W_02343_60_space_W.jpg']\n",
            "  Training Not Preferred: ['W_55047_00_oriental_W.jpg', 'W_52969_00_ecology_W.jpg', 'W_52731_90_kitsch_W.jpg', 'W_56834_90_lingerie_W.jpg', 'W_51690_80_powersuit_W.jpg', 'W_41924_70_punk_W.jpg', 'W_05140_50_feminine_W.jpg', 'W_47960_60_popart_W.jpg', 'W_34436_60_space_W.jpg', 'T_07452_50_classic_W.jpg']\n",
            "  Validation Preferred: ['T_00253_60_popart_W.jpg', 'W_10028_50_classic_W.jpg', 'W_46907_80_powersuit_W.jpg', 'W_44918_60_minimal_W.jpg']\n",
            "  Validation Not Preferred: ['W_34436_60_space_W.jpg', 'W_02170_50_feminine_W.jpg', 'W_22056_70_hippie_W.jpg', 'W_35400_80_powersuit_W.jpg', 'W_19352_50_feminine_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59506\n",
            "  Training Preferred: ['W_10017_19_normcore_W.jpg', 'W_09555_19_lounge_W.jpg', 'W_07792_00_oriental_W.jpg', 'W_05437_10_athleisure_W.jpg', 'W_18922_80_powersuit_W.jpg', 'W_09981_70_punk_W.jpg', 'W_02265_70_military_W.jpg', 'W_04117_60_minimal_W.jpg', 'W_07418_50_feminine_W.jpg', 'W_11218_50_feminine_W.jpg', 'W_19670_60_minimal_W.jpg', 'W_13247_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_14620_19_normcore_W.jpg', 'W_13958_00_cityglam_W.jpg', 'W_03529_90_grunge_W.jpg', 'W_19138_90_kitsch_W.jpg', 'W_13990_80_bodyconscious_W.jpg', 'W_19390_70_punk_W.jpg', 'W_06147_80_powersuit_W.jpg']\n",
            "  Validation Preferred: ['W_01294_10_sportivecasual_W.jpg', 'W_03959_50_classic_W.jpg', 'W_11778_00_oriental_W.jpg', 'W_09750_90_hiphop_W.jpg', 'W_09479_70_hippie_W.jpg', 'W_03717_10_athleisure_W.jpg', 'W_05851_70_punk_W.jpg', 'W_08839_10_athleisure_W.jpg']\n",
            "  Validation Not Preferred: ['W_05760_60_minimal_W.jpg', 'W_19430_00_oriental_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62361\n",
            "  Training Preferred: ['W_10511_00_ecology_W.jpg', 'W_02819_19_genderless_W.jpg', 'W_08993_10_athleisure_W.jpg', 'W_01275_10_athleisure_W.jpg', 'W_08094_10_sportivecasual_W.jpg', 'W_13634_10_sportivecasual_W.jpg', 'W_01084_10_sportivecasual_W.jpg', 'W_18792_90_hiphop_W.jpg', 'W_18122_70_disco_W.jpg', 'W_13289_80_powersuit_W.jpg', 'W_09589_70_punk_W.jpg', 'W_13379_80_powersuit_W.jpg', 'W_05933_60_minimal_W.jpg', 'W_14789_60_minimal_W.jpg', 'W_18420_50_classic_W.jpg', 'W_03243_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_09032_19_normcore_W.jpg', 'W_05790_00_cityglam_W.jpg', 'W_07844_00_oriental_W.jpg', 'W_02257_90_lingerie_W.jpg']\n",
            "  Validation Preferred: ['W_02223_19_normcore_W.jpg', 'W_10167_60_minimal_W.jpg', 'W_03951_00_cityglam_W.jpg', 'W_02306_70_disco_W.jpg', 'W_18482_50_feminine_W.jpg']\n",
            "  Validation Not Preferred: ['W_10689_19_genderless_W.jpg', 'W_04973_90_kitsch_W.jpg', 'W_05321_80_bodyconscious_W.jpg', 'W_13574_90_hiphop_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63571\n",
            "  Training Preferred: ['W_12843_19_normcore_M.jpg', 'W_04649_10_sportivecasual_M.jpg', 'W_16082_60_mods_M.jpg', 'W_12458_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_17926_19_normcore_M.jpg', 'W_16299_10_sportivecasual_M.jpg', 'W_02855_10_sportivecasual_M.jpg', 'W_07001_19_normcore_M.jpg', 'W_00815_19_normcore_M.jpg', 'W_02794_90_hiphop_M.jpg', 'W_15623_70_hippie_M.jpg', 'W_12729_00_metrosexual_M.jpg', 'W_15172_00_metrosexual_M.jpg', 'W_17583_80_bold_M.jpg', 'W_17207_00_metrosexual_M.jpg', 'W_02740_50_ivy_M.jpg', 'W_15093_50_ivy_M.jpg', 'W_12805_50_ivy_M.jpg', 'W_15270_60_mods_M.jpg', 'W_00492_50_ivy_M.jpg', 'W_07133_60_mods_M.jpg']\n",
            "  Validation Preferred: []\n",
            "  Validation Not Preferred: ['W_00492_50_ivy_M.jpg', 'W_02794_90_hiphop_M.jpg', 'W_17944_70_hippie_M.jpg', 'W_06739_90_hiphop_M.jpg', 'W_15225_00_metrosexual_M.jpg', 'W_15270_60_mods_M.jpg', 'W_16485_00_metrosexual_M.jpg', 'W_15394_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64747\n",
            "  Training Preferred: ['W_39725_19_normcore_W.jpg', 'W_22057_19_genderless_W.jpg', 'W_34636_00_oriental_W.jpg', 'W_29783_10_sportivecasual_W.jpg', 'W_21223_80_powersuit_W.jpg', 'W_04972_90_kitsch_W.jpg']\n",
            "  Training Not Preferred: ['W_34573_10_sportivecasual_W.jpg', 'W_36644_00_oriental_W.jpg', 'W_47169_70_hippie_W.jpg', 'W_40876_70_punk_W.jpg', 'W_18951_50_feminine_W.jpg', 'W_14102_50_feminine_W.jpg', 'W_42595_60_popart_W.jpg', 'W_02498_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_44330_10_sportivecasual_W.jpg', 'W_38588_19_genderless_W.jpg', 'W_46907_80_powersuit_W.jpg', 'W_22510_80_powersuit_W.jpg', 'W_05628_00_cityglam_W.jpg', 'W_20598_70_military_W.jpg', 'W_39164_00_oriental_W.jpg', 'W_37491_70_military_W.jpg', 'W_30988_90_kitsch_W.jpg']\n",
            "  Validation Not Preferred: ['W_47169_70_hippie_W.jpg', 'W_27828_60_minimal_W.jpg', 'W_02498_50_feminine_W.jpg', 'W_34024_10_sportivecasual_W.jpg', 'W_14102_50_feminine_W.jpg', 'W_11610_90_grunge_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 7905\n",
            "  Training Preferred: ['W_02845_60_mods_M.jpg', 'W_24765_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_28443_10_sportivecasual_M.jpg', 'W_27319_10_sportivecasual_M.jpg', 'W_24557_19_normcore_M.jpg', 'W_07025_10_sportivecasual_M.jpg', 'W_27182_10_sportivecasual_M.jpg', 'W_24573_00_metrosexual_M.jpg', 'W_06805_90_hiphop_M.jpg', 'W_25206_80_bold_M.jpg', 'W_26962_90_hiphop_M.jpg', 'W_24530_70_hippie_M.jpg', 'W_17603_50_ivy_M.jpg', 'W_24758_50_ivy_M.jpg', 'W_24142_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_32034_80_bold_M.jpg', 'W_02845_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_17603_50_ivy_M.jpg', 'W_24758_50_ivy_M.jpg', 'W_15319_50_ivy_M.jpg', 'W_33006_60_mods_M.jpg', 'W_10073_70_hippie_M.jpg', 'W_24535_70_hippie_M.jpg', 'W_24573_00_metrosexual_M.jpg', 'W_26179_60_mods_M.jpg', 'W_07025_10_sportivecasual_M.jpg', 'W_17481_10_sportivecasual_M.jpg', 'W_28964_19_normcore_M.jpg', 'W_28909_19_normcore_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 837\n",
            "  Training Preferred: ['W_28209_10_sportivecasual_M.jpg', 'W_29169_10_sportivecasual_M.jpg', 'W_28211_19_normcore_M.jpg', 'W_28722_10_sportivecasual_M.jpg', 'W_00829_10_sportivecasual_M.jpg', 'W_25073_90_hiphop_M.jpg', 'W_02897_90_hiphop_M.jpg', 'W_02944_00_metrosexual_M.jpg', 'W_17305_70_hippie_M.jpg', 'W_29178_90_hiphop_M.jpg', 'W_09157_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_11107_19_normcore_M.jpg', 'W_07130_19_normcore_M.jpg', 'W_33271_10_sportivecasual_M.jpg', 'W_24845_80_bold_M.jpg', 'W_12610_00_metrosexual_M.jpg', 'W_24381_70_hippie_M.jpg', 'W_16659_00_metrosexual_M.jpg', 'W_17524_00_metrosexual_M.jpg']\n",
            "  Validation Preferred: ['W_00028_50_ivy_M.jpg', 'W_06590_90_hiphop_M.jpg', 'W_17305_70_hippie_M.jpg', 'W_00829_10_sportivecasual_M.jpg', 'W_10104_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_31439_19_normcore_M.jpg', 'W_27700_70_hippie_M.jpg', 'W_15661_70_hippie_M.jpg', 'W_12154_80_bold_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 35514\n",
            "  Training Preferred: ['W_04539_10_sportivecasual_M.jpg', 'W_01716_19_normcore_M.jpg', 'W_01645_90_hiphop_M.jpg', 'W_13627_90_hiphop_M.jpg', 'W_01664_60_mods_M.jpg', 'W_09152_60_mods_M.jpg', 'W_06148_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_06905_19_normcore_M.jpg', 'W_17559_10_sportivecasual_M.jpg', 'W_12634_10_sportivecasual_M.jpg', 'W_16687_00_metrosexual_M.jpg', 'W_15447_70_hippie_M.jpg', 'W_15159_80_bold_M.jpg', 'W_04406_00_metrosexual_M.jpg', 'W_10814_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_06148_50_ivy_M.jpg', 'W_09154_50_ivy_M.jpg', 'W_00851_10_sportivecasual_M.jpg', 'W_15758_10_sportivecasual_M.jpg', 'W_09152_60_mods_M.jpg', 'W_02705_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_04349_00_metrosexual_M.jpg', 'W_16104_60_mods_M.jpg', 'W_15523_70_hippie_M.jpg', 'W_12725_70_hippie_M.jpg', 'W_17796_00_metrosexual_M.jpg', 'W_17559_10_sportivecasual_M.jpg', 'W_06788_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 61104\n",
            "  Training Preferred: ['W_06457_00_ecology_W.jpg', 'W_08810_10_sportivecasual_W.jpg', 'W_08839_10_athleisure_W.jpg', 'W_04919_00_oriental_W.jpg', 'W_02487_10_athleisure_W.jpg', 'W_07906_00_ecology_W.jpg', 'W_18992_70_military_W.jpg', 'W_18911_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_07578_19_lounge_W.jpg', 'W_19430_00_oriental_W.jpg', 'W_07717_90_kitsch_W.jpg', 'W_08511_80_bodyconscious_W.jpg', 'W_07666_70_disco_W.jpg', 'W_14147_70_disco_W.jpg', 'W_06439_50_feminine_W.jpg', 'W_08670_50_classic_W.jpg']\n",
            "  Validation Preferred: ['W_08951_19_normcore_W.jpg', 'W_09085_60_minimal_W.jpg', 'W_18992_70_military_W.jpg', 'W_08839_10_athleisure_W.jpg', 'W_09620_70_hippie_W.jpg']\n",
            "  Validation Not Preferred: ['W_06090_10_athleisure_W.jpg', 'W_19430_00_oriental_W.jpg', 'W_08402_90_grunge_W.jpg', 'W_13991_00_cityglam_W.jpg', 'W_07445_80_bodyconscious_W.jpg', 'W_13354_50_feminine_W.jpg', 'W_14147_70_disco_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 61493\n",
            "  Training Preferred: ['W_02881_10_sportivecasual_M.jpg', 'W_17715_19_normcore_M.jpg', 'W_04679_10_sportivecasual_M.jpg', 'W_04661_10_sportivecasual_M.jpg', 'W_12230_80_bold_M.jpg', 'W_04232_50_ivy_M.jpg', 'W_02818_60_mods_M.jpg', 'W_07290_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_16695_19_normcore_M.jpg', 'W_06791_00_metrosexual_M.jpg', 'W_15795_70_hippie_M.jpg', 'W_00822_90_hiphop_M.jpg', 'W_12345_80_bold_M.jpg', 'W_16014_70_hippie_M.jpg', 'W_02728_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_07290_50_ivy_M.jpg', 'W_09277_10_sportivecasual_M.jpg', 'W_17235_60_mods_M.jpg', 'W_09182_90_hiphop_M.jpg', 'W_10107_60_mods_M.jpg', 'W_03003_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_17787_50_ivy_M.jpg', 'W_02728_60_mods_M.jpg', 'W_06715_00_metrosexual_M.jpg', 'W_15701_90_hiphop_M.jpg', 'W_16247_70_hippie_M.jpg', 'W_17062_19_normcore_M.jpg', 'W_04463_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62349\n",
            "  Training Preferred: ['W_07380_19_normcore_M.jpg', 'W_04689_10_sportivecasual_M.jpg', 'W_16971_19_normcore_M.jpg', 'W_17802_80_bold_M.jpg', 'W_07101_60_mods_M.jpg', 'W_00951_70_hippie_M.jpg', 'W_09157_60_mods_M.jpg', 'W_04678_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_02951_10_sportivecasual_M.jpg', 'W_06232_10_sportivecasual_M.jpg', 'W_16681_70_hippie_M.jpg', 'W_07095_00_metrosexual_M.jpg', 'W_12552_80_bold_M.jpg', 'W_01462_90_hiphop_M.jpg', 'W_15124_80_bold_M.jpg', 'W_06253_90_hiphop_M.jpg', 'W_15153_70_hippie_M.jpg', 'W_17353_50_ivy_M.jpg', 'W_15125_50_ivy_M.jpg', 'W_10816_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_04678_50_ivy_M.jpg', 'W_07226_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_17353_50_ivy_M.jpg', 'W_07099_50_ivy_M.jpg', 'W_15141_70_hippie_M.jpg', 'W_16538_90_hiphop_M.jpg', 'W_06889_90_hiphop_M.jpg', 'W_03026_10_sportivecasual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 21432\n",
            "  Training Preferred: ['W_28523_90_hiphop_M.jpg', 'W_09891_90_hiphop_M.jpg', 'W_29023_00_metrosexual_M.jpg', 'W_15294_50_ivy_M.jpg', 'W_32448_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_26017_10_sportivecasual_M.jpg', 'W_29224_10_sportivecasual_M.jpg', 'W_16505_10_sportivecasual_M.jpg', 'W_24055_19_normcore_M.jpg', 'W_24914_70_hippie_M.jpg', 'W_26397_70_hippie_M.jpg', 'W_24439_00_metrosexual_M.jpg', 'W_16169_80_bold_M.jpg', 'W_12602_00_metrosexual_M.jpg', 'W_12383_80_bold_M.jpg', 'W_26296_70_hippie_M.jpg', 'W_26151_80_bold_M.jpg', 'W_25107_70_hippie_M.jpg', 'W_16651_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_15294_50_ivy_M.jpg', 'W_06148_50_ivy_M.jpg', 'W_06522_50_ivy_M.jpg', 'W_29023_00_metrosexual_M.jpg', 'W_32407_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_16269_80_bold_M.jpg', 'W_16505_10_sportivecasual_M.jpg', 'W_24211_70_hippie_M.jpg', 'W_26397_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62525\n",
            "  Training Preferred: ['W_00760_19_normcore_W.jpg', 'W_19165_00_cityglam_W.jpg', 'W_05751_10_sportivecasual_W.jpg', 'W_09686_90_hiphop_W.jpg', 'W_09425_90_hiphop_W.jpg', 'W_19236_90_grunge_W.jpg', 'W_13631_90_hiphop_W.jpg', 'W_19414_70_hippie_W.jpg', 'W_03477_80_powersuit_W.jpg', 'W_05367_80_bodyconscious_W.jpg', 'W_01207_60_minimal_W.jpg', 'W_18495_50_feminine_W.jpg', 'W_11223_60_popart_W.jpg', 'W_13104_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_13667_00_oriental_W.jpg', 'W_08167_60_minimal_W.jpg', 'W_07447_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_19267_70_disco_W.jpg', 'W_14691_70_military_W.jpg', 'W_13104_50_classic_W.jpg', 'W_19236_90_grunge_W.jpg', 'W_13359_80_powersuit_W.jpg', 'W_10558_50_feminine_W.jpg', 'W_10253_90_grunge_W.jpg']\n",
            "  Validation Not Preferred: ['W_14218_19_genderless_W.jpg', 'W_03685_10_athleisure_W.jpg', 'W_11423_00_ecology_W.jpg', 'W_10504_00_oriental_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62952\n",
            "  Training Preferred: ['W_49351_10_sportivecasual_W.jpg', 'W_38394_19_normcore_W.jpg', 'W_22563_80_powersuit_W.jpg', 'W_04928_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_22330_19_normcore_W.jpg', 'W_46274_19_genderless_W.jpg', 'W_40825_10_sportivecasual_W.jpg', 'W_22350_19_lounge_W.jpg', 'W_36003_19_lounge_W.jpg', 'W_31252_00_ecology_W.jpg', 'W_05818_90_lingerie_W.jpg', 'W_44650_90_kitsch_W.jpg', 'W_42705_70_disco_W.jpg', 'W_44666_70_punk_W.jpg', 'W_19820_50_feminine_W.jpg', 'W_44849_60_space_W.jpg']\n",
            "  Validation Preferred: ['W_47862_19_normcore_W.jpg', 'W_45137_00_ecology_W.jpg', 'W_01178_00_oriental_W.jpg']\n",
            "  Validation Not Preferred: ['W_41158_10_sportivecasual_W.jpg', 'W_28480_60_minimal_W.jpg', 'W_37014_60_minimal_W.jpg', 'W_03771_00_oriental_W.jpg', 'W_34487_10_athleisure_W.jpg', 'W_19820_50_feminine_W.jpg', 'W_14852_50_feminine_W.jpg', 'W_11659_50_feminine_W.jpg', 'W_05818_90_lingerie_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63156\n",
            "  Training Preferred: ['W_01318_10_athleisure_W.jpg', 'W_18526_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_14888_19_normcore_W.jpg', 'W_11504_19_lounge_W.jpg', 'W_09007_19_normcore_W.jpg', 'W_01166_10_sportivecasual_W.jpg', 'W_06396_10_sportivecasual_W.jpg', 'W_19061_90_kitsch_W.jpg', 'W_11900_90_kitsch_W.jpg', 'W_08180_80_bodyconscious_W.jpg', 'W_19740_70_hippie_W.jpg', 'W_00626_70_hippie_W.jpg', 'W_18729_50_classic_W.jpg', 'W_19838_60_popart_W.jpg', 'W_14259_50_feminine_W.jpg', 'W_18616_60_popart_W.jpg', 'W_00217_60_space_W.jpg', 'W_19537_60_popart_W.jpg']\n",
            "  Validation Preferred: ['W_05175_00_ecology_W.jpg', 'W_14796_60_minimal_W.jpg', 'W_10429_60_minimal_W.jpg']\n",
            "  Validation Not Preferred: ['W_14888_19_normcore_W.jpg', 'W_01105_19_genderless_W.jpg', 'W_08673_90_kitsch_W.jpg', 'W_19545_00_oriental_W.jpg', 'W_05502_00_ecology_W.jpg', 'W_19454_90_kitsch_W.jpg', 'W_05271_50_feminine_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 22324\n",
            "  Training Preferred: ['W_04372_10_sportivecasual_M.jpg', 'W_17700_00_metrosexual_M.jpg', 'W_07347_90_hiphop_M.jpg', 'W_02769_90_hiphop_M.jpg', 'W_06551_60_mods_M.jpg', 'W_06800_70_hippie_M.jpg', 'W_02696_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_16374_10_sportivecasual_M.jpg', 'W_17481_10_sportivecasual_M.jpg', 'W_15511_00_metrosexual_M.jpg', 'W_15091_80_bold_M.jpg', 'W_17893_80_bold_M.jpg', 'W_17732_00_metrosexual_M.jpg', 'W_12443_90_hiphop_M.jpg', 'W_15443_70_hippie_M.jpg', 'W_15587_70_hippie_M.jpg', 'W_10779_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_04636_50_ivy_M.jpg', 'W_00931_10_sportivecasual_M.jpg', 'W_07120_19_normcore_M.jpg', 'W_06551_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_04212_50_ivy_M.jpg', 'W_10779_50_ivy_M.jpg', 'W_15791_70_hippie_M.jpg', 'W_04395_80_bold_M.jpg', 'W_17481_10_sportivecasual_M.jpg', 'W_16374_10_sportivecasual_M.jpg', 'W_16104_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63644\n",
            "  Training Preferred: ['W_05127_90_kitsch_W.jpg', 'W_09542_70_disco_W.jpg', 'W_03934_70_hippie_W.jpg', 'W_07688_70_disco_W.jpg', 'W_14787_60_minimal_W.jpg', 'W_07640_60_popart_W.jpg', 'W_18694_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_10189_19_genderless_W.jpg', 'W_05472_10_sportivecasual_W.jpg', 'W_01390_10_sportivecasual_W.jpg', 'W_01326_10_sportivecasual_W.jpg', 'W_10999_10_athleisure_W.jpg', 'W_03653_90_hiphop_W.jpg', 'W_14273_80_bodyconscious_W.jpg', 'W_08324_80_bodyconscious_W.jpg', 'W_18858_50_classic_W.jpg']\n",
            "  Validation Preferred: ['W_09577_19_lounge_W.jpg', 'W_12067_00_ecology_W.jpg', 'W_09475_00_cityglam_W.jpg', 'W_14787_60_minimal_W.jpg', 'W_08621_00_cityglam_W.jpg', 'W_08205_70_punk_W.jpg', 'W_09737_10_sportivecasual_W.jpg', 'W_08040_90_kitsch_W.jpg']\n",
            "  Validation Not Preferred: ['W_18506_80_bodyconscious_W.jpg', 'W_03522_80_powersuit_W.jpg', 'W_09027_60_minimal_W.jpg', 'W_13010_50_classic_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63740\n",
            "  Training Preferred: ['W_04201_19_lounge_W.jpg', 'W_19511_19_genderless_W.jpg', 'W_01179_10_sportivecasual_W.jpg', 'W_13171_70_military_W.jpg', 'W_11824_70_military_W.jpg', 'W_18894_50_feminine_W.jpg', 'W_14975_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_05226_10_sportivecasual_W.jpg', 'W_09896_00_ecology_W.jpg', 'W_08607_90_kitsch_W.jpg', 'W_03656_90_hiphop_W.jpg', 'W_19264_90_kitsch_W.jpg', 'W_08498_80_bodyconscious_W.jpg', 'W_06083_80_bodyconscious_W.jpg', 'W_05353_80_bodyconscious_W.jpg', 'W_07532_70_hippie_W.jpg', 'W_06031_70_punk_W.jpg']\n",
            "  Validation Preferred: ['W_01179_10_sportivecasual_W.jpg', 'W_05979_00_ecology_W.jpg', 'W_03144_50_classic_W.jpg', 'W_03522_80_powersuit_W.jpg']\n",
            "  Validation Not Preferred: ['W_03293_19_normcore_W.jpg', 'W_09752_19_normcore_W.jpg', 'W_03125_80_bodyconscious_W.jpg', 'W_11912_50_feminine_W.jpg', 'W_00625_80_bodyconscious_W.jpg', 'W_12002_60_minimal_W.jpg', 'W_07532_70_hippie_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64252\n",
            "  Training Preferred: ['W_07138_19_normcore_M.jpg', 'W_00032_10_sportivecasual_M.jpg', 'W_07048_90_hiphop_M.jpg', 'W_16606_90_hiphop_M.jpg', 'W_06787_90_hiphop_M.jpg', 'W_24152_60_mods_M.jpg', 'W_05883_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_30450_19_normcore_M.jpg', 'W_17182_10_sportivecasual_M.jpg', 'W_28602_19_normcore_M.jpg', 'W_06730_90_hiphop_M.jpg', 'W_15899_80_bold_M.jpg', 'W_32608_70_hippie_M.jpg', 'W_12150_80_bold_M.jpg', 'W_04510_00_metrosexual_M.jpg', 'W_30290_50_ivy_M.jpg', 'W_12708_50_ivy_M.jpg', 'W_06696_70_hippie_M.jpg', 'W_24101_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_24152_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_30290_50_ivy_M.jpg', 'W_12708_50_ivy_M.jpg', 'W_10781_60_mods_M.jpg', 'W_12460_60_mods_M.jpg', 'W_23958_60_mods_M.jpg', 'W_17478_19_normcore_M.jpg', 'W_30403_60_mods_M.jpg', 'W_17304_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64345\n",
            "  Training Preferred: ['W_17467_19_normcore_M.jpg', 'W_16839_19_normcore_M.jpg', 'W_29596_10_sportivecasual_M.jpg', 'W_28449_10_sportivecasual_M.jpg', 'W_00843_10_sportivecasual_M.jpg', 'W_24506_00_metrosexual_M.jpg', 'W_32150_00_metrosexual_M.jpg', 'W_24296_00_metrosexual_M.jpg', 'W_27156_90_hiphop_M.jpg', 'W_24155_60_mods_M.jpg', 'W_15856_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_25884_90_hiphop_M.jpg', 'W_24352_70_hippie_M.jpg', 'W_11105_00_metrosexual_M.jpg', 'W_24825_80_bold_M.jpg', 'W_15645_70_hippie_M.jpg', 'W_24325_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_00028_50_ivy_M.jpg', 'W_28022_50_ivy_M.jpg', 'W_12847_19_normcore_M.jpg', 'W_15295_60_mods_M.jpg', 'W_15856_60_mods_M.jpg', 'W_23964_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_30593_50_ivy_M.jpg', 'W_25884_90_hiphop_M.jpg', 'W_24923_00_metrosexual_M.jpg', 'W_34080_70_hippie_M.jpg', 'W_12730_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64441\n",
            "  Training Preferred: ['W_28879_10_sportivecasual_M.jpg', 'W_27175_10_sportivecasual_M.jpg', 'W_28739_19_normcore_M.jpg', 'W_25876_10_sportivecasual_M.jpg', 'W_25790_90_hiphop_M.jpg', 'W_04232_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_29920_10_sportivecasual_M.jpg', 'W_27729_70_hippie_M.jpg', 'W_24203_90_hiphop_M.jpg', 'W_24448_70_hippie_M.jpg', 'W_25650_00_metrosexual_M.jpg', 'W_15138_00_metrosexual_M.jpg', 'W_15096_80_bold_M.jpg', 'W_24883_00_metrosexual_M.jpg', 'W_29545_90_hiphop_M.jpg', 'W_24525_70_hippie_M.jpg', 'W_24917_80_bold_M.jpg', 'W_15783_70_hippie_M.jpg', 'W_24797_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_17783_80_bold_M.jpg', 'W_25790_90_hiphop_M.jpg', 'W_24517_70_hippie_M.jpg', 'W_17441_60_mods_M.jpg', 'W_16067_80_bold_M.jpg']\n",
            "  Validation Not Preferred: ['W_24883_00_metrosexual_M.jpg', 'W_24203_90_hiphop_M.jpg', 'W_25235_60_mods_M.jpg', 'W_02820_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64503\n",
            "  Training Preferred: ['W_43631_19_normcore_W.jpg', 'W_43214_19_genderless_W.jpg', 'W_43003_10_sportivecasual_W.jpg', 'W_08808_10_athleisure_W.jpg', 'W_45353_80_powersuit_W.jpg', 'W_40718_90_hiphop_W.jpg', 'W_43570_90_hiphop_W.jpg', 'W_43941_70_hippie_W.jpg', 'W_07755_50_feminine_W.jpg', 'W_36275_60_minimal_W.jpg', 'W_27828_60_minimal_W.jpg', 'W_41444_60_space_W.jpg']\n",
            "  Training Not Preferred: ['W_47959_19_lounge_W.jpg', 'W_47343_19_normcore_W.jpg', 'W_34027_10_sportivecasual_W.jpg', 'W_35053_90_kitsch_W.jpg', 'W_42376_90_grunge_W.jpg', 'W_30932_70_disco_W.jpg', 'W_18249_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_27828_60_minimal_W.jpg', 'W_08988_10_athleisure_W.jpg', 'W_23410_60_minimal_W.jpg', 'W_41444_60_space_W.jpg', 'W_08754_70_military_W.jpg']\n",
            "  Validation Not Preferred: ['W_38869_00_ecology_W.jpg', 'W_18249_50_feminine_W.jpg', 'W_34027_10_sportivecasual_W.jpg', 'W_02243_70_hippie_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 65071\n",
            "  Training Preferred: ['W_33832_19_normcore_W.jpg', 'W_57411_19_genderless_W.jpg', 'W_41736_70_disco_W.jpg', 'W_29245_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_37682_19_normcore_W.jpg', 'W_40998_00_oriental_W.jpg', 'W_49895_00_oriental_W.jpg', 'W_36802_00_oriental_W.jpg', 'W_53650_80_bodyconscious_W.jpg', 'W_46528_70_hippie_W.jpg', 'W_15016_50_feminine_W.jpg', 'W_36156_60_space_W.jpg', 'W_19935_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_34621_90_kitsch_W.jpg', 'W_38785_60_minimal_W.jpg', 'W_38489_80_powersuit_W.jpg']\n",
            "  Validation Not Preferred: ['W_53613_10_sportivecasual_W.jpg', 'W_40642_10_sportivecasual_W.jpg', 'W_26525_60_minimal_W.jpg', 'W_34623_10_sportivecasual_W.jpg', 'W_63188_90_kitsch_W.jpg', 'W_44232_90_kitsch_W.jpg', 'W_42967_80_bodyconscious_W.jpg', 'W_61255_00_cityglam_W.jpg', 'W_62313_00_oriental_W.jpg', 'W_40875_70_punk_W.jpg', 'W_33284_90_kitsch_W.jpg', 'W_03082_50_feminine_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 66513\n",
            "  Training Preferred: ['W_50265_19_normcore_W.jpg', 'W_67405_19_normcore_W.jpg', 'W_44554_90_grunge_W.jpg', 'W_60789_90_lingerie_W.jpg', 'W_14828_50_classic_W.jpg', 'W_19031_50_classic_W.jpg', 'W_35544_60_minimal_W.jpg', 'W_14940_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_56334_10_sportivecasual_W.jpg', 'W_34173_19_normcore_W.jpg', 'W_68199_10_sportivecasual_W.jpg', 'W_60553_00_cityglam_W.jpg', 'W_66976_00_ecology_W.jpg', 'W_61163_80_powersuit_W.jpg', 'W_45743_70_punk_W.jpg', 'W_37404_60_space_W.jpg', 'W_38863_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_14828_50_classic_W.jpg']\n",
            "  Validation Not Preferred: ['W_56334_10_sportivecasual_W.jpg', 'W_14914_50_feminine_W.jpg', 'W_60553_00_cityglam_W.jpg', 'W_53112_90_lingerie_W.jpg', 'W_39793_80_powersuit_W.jpg', 'W_44520_70_punk_W.jpg', 'T_06910_50_classic_W.jpg', 'W_10984_50_feminine_W.jpg', 'W_37404_60_space_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59523\n",
            "  Training Preferred: ['W_09060_19_normcore_W.jpg', 'W_03476_19_lounge_W.jpg', 'W_05673_10_sportivecasual_W.jpg', 'W_03816_90_lingerie_W.jpg', 'W_09533_90_grunge_W.jpg', 'W_05690_70_punk_W.jpg', 'W_18661_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_05665_19_genderless_W.jpg', 'W_13570_00_oriental_W.jpg', 'W_08092_90_hiphop_W.jpg', 'W_08482_80_bodyconscious_W.jpg', 'W_11632_70_punk_W.jpg', 'W_05246_80_bodyconscious_W.jpg', 'W_19742_60_popart_W.jpg', 'W_08765_60_space_W.jpg', 'W_00609_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_13251_19_normcore_W.jpg', 'W_08977_19_normcore_W.jpg', 'W_03927_60_minimal_W.jpg', 'W_13656_80_powersuit_W.jpg', 'W_14572_50_classic_W.jpg']\n",
            "  Validation Not Preferred: ['W_05665_19_genderless_W.jpg', 'W_19207_19_lounge_W.jpg', 'W_18213_10_sportivecasual_W.jpg', 'W_03224_50_feminine_W.jpg', 'W_11632_70_punk_W.jpg', 'W_18160_50_classic_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 67975\n",
            "  Training Preferred: ['W_60183_10_sportivecasual_M.jpg', 'T_17797_19_normcore_M.jpg', 'W_07074_00_metrosexual_M.jpg', 'W_17738_80_bold_M.jpg', 'W_07095_00_metrosexual_M.jpg', 'T_21987_70_hippie_M.jpg', 'W_71936_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['T_17802_19_normcore_M.jpg', 'W_60214_10_sportivecasual_M.jpg', 'W_06920_00_metrosexual_M.jpg', 'W_26965_90_hiphop_M.jpg', 'W_26992_90_hiphop_M.jpg', 'T_21992_70_hippie_M.jpg', 'W_52548_50_ivy_M.jpg', 'T_21986_70_hippie_M.jpg']\n",
            "  Validation Preferred: ['W_52578_50_ivy_M.jpg', 'T_21988_70_hippie_M.jpg', 'W_07074_00_metrosexual_M.jpg', 'W_17738_80_bold_M.jpg']\n",
            "  Validation Not Preferred: ['W_52521_50_ivy_M.jpg', 'W_60184_10_sportivecasual_M.jpg', 'T_21986_70_hippie_M.jpg', 'T_21992_70_hippie_M.jpg', 'W_26965_90_hiphop_M.jpg', 'W_17747_80_bold_M.jpg', 'W_17742_80_bold_M.jpg', 'W_06985_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 60465\n",
            "  Training Preferred: ['W_06195_10_sportivecasual_M.jpg', 'W_17747_80_bold_M.jpg', 'W_01758_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_07194_19_normcore_M.jpg', 'W_16667_19_normcore_M.jpg', 'W_15468_00_metrosexual_M.jpg', 'W_06607_90_hiphop_M.jpg', 'W_12583_70_hippie_M.jpg', 'W_16014_70_hippie_M.jpg', 'W_06629_90_hiphop_M.jpg', 'W_12635_70_hippie_M.jpg', 'W_12467_70_hippie_M.jpg', 'W_16401_00_metrosexual_M.jpg', 'W_06883_60_mods_M.jpg', 'W_02684_60_mods_M.jpg', 'W_09125_60_mods_M.jpg', 'W_15344_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_17221_70_hippie_M.jpg', 'W_17623_19_normcore_M.jpg', 'W_17747_80_bold_M.jpg']\n",
            "  Validation Not Preferred: ['W_12615_50_ivy_M.jpg', 'W_05868_50_ivy_M.jpg', 'W_12817_50_ivy_M.jpg', 'W_16819_00_metrosexual_M.jpg', 'W_12635_70_hippie_M.jpg', 'W_16915_10_sportivecasual_M.jpg', 'W_06883_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 28912\n",
            "  Training Preferred: ['W_04680_10_sportivecasual_M.jpg', 'W_01754_10_sportivecasual_M.jpg', 'W_00072_90_hiphop_M.jpg', 'W_02669_50_ivy_M.jpg', 'W_04251_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_17260_19_normcore_M.jpg', 'W_15440_70_hippie_M.jpg', 'W_15877_80_bold_M.jpg', 'W_04723_90_hiphop_M.jpg', 'W_16090_80_bold_M.jpg', 'W_16725_70_hippie_M.jpg', 'W_12528_00_metrosexual_M.jpg', 'W_15745_80_bold_M.jpg', 'W_15923_80_bold_M.jpg', 'W_15461_70_hippie_M.jpg', 'W_03007_70_hippie_M.jpg', 'W_04242_60_mods_M.jpg', 'W_15246_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_16375_80_bold_M.jpg', 'W_10103_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_00012_50_ivy_M.jpg', 'W_15440_70_hippie_M.jpg', 'W_04324_90_hiphop_M.jpg', 'W_01463_60_mods_M.jpg', 'W_06895_00_metrosexual_M.jpg', 'W_15745_80_bold_M.jpg', 'W_15295_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62113\n",
            "  Training Preferred: ['W_01106_19_normcore_W.jpg', 'W_02567_10_sportivecasual_W.jpg', 'W_04068_10_athleisure_W.jpg', 'W_08486_70_punk_W.jpg', 'W_10554_80_bodyconscious_W.jpg', 'W_08595_80_bodyconscious_W.jpg', 'W_14930_50_classic_W.jpg', 'W_09957_50_feminine_W.jpg', 'W_09639_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_00754_10_sportivecasual_W.jpg', 'W_10278_00_oriental_W.jpg', 'W_13957_80_powersuit_W.jpg', 'W_11853_70_hippie_W.jpg', 'W_19994_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_09747_19_normcore_W.jpg', 'W_06358_60_minimal_W.jpg', 'W_10251_70_punk_W.jpg', 'W_14930_50_classic_W.jpg']\n",
            "  Validation Not Preferred: ['W_19602_19_lounge_W.jpg', 'W_11509_80_bodyconscious_W.jpg', 'W_08862_10_sportivecasual_W.jpg', 'W_01998_90_lingerie_W.jpg', 'W_10749_00_ecology_W.jpg', 'W_09085_60_minimal_W.jpg', 'W_13957_80_powersuit_W.jpg', 'W_14469_60_space_W.jpg', 'W_17785_90_grunge_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62868\n",
            "  Training Preferred: ['W_01810_19_normcore_M.jpg', 'W_01429_90_hiphop_M.jpg', 'W_04673_00_metrosexual_M.jpg', 'W_12628_50_ivy_M.jpg', 'W_16676_90_hiphop_M.jpg']\n",
            "  Training Not Preferred: ['W_10851_19_normcore_M.jpg', 'W_02904_19_normcore_M.jpg', 'W_16930_19_normcore_M.jpg', 'W_17812_10_sportivecasual_M.jpg', 'W_16762_00_metrosexual_M.jpg', 'W_15192_00_metrosexual_M.jpg', 'W_15987_70_hippie_M.jpg', 'W_12807_50_ivy_M.jpg', 'W_02681_60_mods_M.jpg', 'W_06656_60_mods_M.jpg', 'W_16189_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_16693_70_hippie_M.jpg', 'W_06525_60_mods_M.jpg', 'W_12803_70_hippie_M.jpg', 'W_12412_19_normcore_M.jpg', 'W_16704_00_metrosexual_M.jpg']\n",
            "  Validation Not Preferred: ['W_12708_50_ivy_M.jpg', 'W_15192_00_metrosexual_M.jpg', 'W_16341_60_mods_M.jpg', 'W_04396_90_hiphop_M.jpg', 'W_10079_60_mods_M.jpg', 'W_16702_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63526\n",
            "  Training Preferred: ['W_08943_19_genderless_W.jpg', 'W_03388_00_cityglam_W.jpg', 'W_01993_00_oriental_W.jpg', 'W_13735_90_lingerie_W.jpg', 'W_00432_90_hiphop_W.jpg', 'W_11964_70_hippie_W.jpg', 'W_11845_70_hippie_W.jpg', 'W_04869_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_19492_00_ecology_W.jpg', 'W_09352_70_military_W.jpg', 'W_19750_70_hippie_W.jpg', 'W_18797_70_disco_W.jpg', 'W_14461_80_powersuit_W.jpg', 'W_18508_50_feminine_W.jpg', 'W_02383_60_minimal_W.jpg', 'W_14488_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_06502_80_bodyconscious_W.jpg', 'W_05667_10_athleisure_W.jpg', 'W_03623_70_punk_W.jpg', 'W_05787_10_sportivecasual_W.jpg', 'W_03685_10_athleisure_W.jpg', 'W_18057_50_classic_W.jpg', 'W_18670_00_ecology_W.jpg', 'W_12027_90_kitsch_W.jpg']\n",
            "  Validation Not Preferred: ['W_00598_19_normcore_W.jpg', 'W_00299_50_feminine_W.jpg', 'W_14488_60_minimal_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63748\n",
            "  Training Preferred: ['W_07207_10_sportivecasual_M.jpg', 'W_02890_19_normcore_M.jpg', 'W_00829_10_sportivecasual_M.jpg', 'W_16677_70_hippie_M.jpg', 'W_10092_60_mods_M.jpg', 'W_17867_50_ivy_M.jpg', 'W_17174_50_ivy_M.jpg', 'W_15268_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_04484_90_hiphop_M.jpg', 'W_04457_90_hiphop_M.jpg', 'W_16520_90_hiphop_M.jpg', 'W_11030_00_metrosexual_M.jpg', 'W_11144_00_metrosexual_M.jpg', 'W_15116_00_metrosexual_M.jpg', 'W_10079_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_17867_50_ivy_M.jpg', 'W_15843_00_metrosexual_M.jpg', 'W_01410_19_normcore_M.jpg', 'W_00829_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_10079_60_mods_M.jpg', 'W_11144_00_metrosexual_M.jpg', 'W_06955_10_sportivecasual_M.jpg', 'W_12378_80_bold_M.jpg', 'W_12462_90_hiphop_M.jpg', 'W_16446_10_sportivecasual_M.jpg', 'W_00539_10_sportivecasual_M.jpg', 'W_15699_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63927\n",
            "  Training Preferred: ['W_06852_19_normcore_M.jpg', 'W_06824_19_normcore_M.jpg', 'W_09871_19_normcore_M.jpg', 'W_16625_90_hiphop_M.jpg', 'W_06531_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_16412_10_sportivecasual_M.jpg', 'W_12631_10_sportivecasual_M.jpg', 'W_17443_90_hiphop_M.jpg', 'W_15276_00_metrosexual_M.jpg', 'W_12402_00_metrosexual_M.jpg', 'W_15651_70_hippie_M.jpg', 'W_12428_90_hiphop_M.jpg', 'W_17779_80_bold_M.jpg', 'W_12650_90_hiphop_M.jpg', 'W_11143_00_metrosexual_M.jpg', 'W_17947_00_metrosexual_M.jpg', 'W_12233_80_bold_M.jpg', 'W_00105_00_metrosexual_M.jpg', 'W_15080_50_ivy_M.jpg', 'W_10796_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_05892_10_sportivecasual_M.jpg', 'W_06531_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_17603_50_ivy_M.jpg', 'W_09877_50_ivy_M.jpg', 'W_04268_70_hippie_M.jpg', 'W_16516_90_hiphop_M.jpg', 'W_17443_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63930\n",
            "  Training Preferred: ['W_09792_10_sportivecasual_M.jpg', 'W_01558_10_sportivecasual_M.jpg', 'W_12196_80_bold_M.jpg', 'W_09633_90_hiphop_M.jpg', 'W_32039_60_mods_M.jpg', 'W_01539_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_16432_10_sportivecasual_M.jpg', 'W_27174_10_sportivecasual_M.jpg', 'W_27692_70_hippie_M.jpg', 'W_15762_70_hippie_M.jpg', 'W_17795_80_bold_M.jpg', 'W_16291_80_bold_M.jpg', 'W_04675_90_hiphop_M.jpg', 'W_17210_70_hippie_M.jpg', 'W_16362_80_bold_M.jpg', 'W_11008_50_ivy_M.jpg', 'W_10804_50_ivy_M.jpg', 'W_09771_60_mods_M.jpg', 'W_24811_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_27854_50_ivy_M.jpg', 'W_07369_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_15762_70_hippie_M.jpg', 'W_12866_60_mods_M.jpg', 'W_16362_80_bold_M.jpg', 'W_15497_70_hippie_M.jpg', 'W_17967_19_normcore_M.jpg', 'W_16283_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64280\n",
            "  Training Preferred: ['W_26506_19_normcore_M.jpg', 'W_06234_10_sportivecasual_M.jpg', 'W_24628_70_hippie_M.jpg', 'W_30041_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_28915_19_normcore_M.jpg', 'W_24317_70_hippie_M.jpg', 'W_28601_00_metrosexual_M.jpg', 'W_27318_80_bold_M.jpg', 'W_24859_70_hippie_M.jpg', 'W_27791_00_metrosexual_M.jpg', 'W_25272_90_hiphop_M.jpg', 'W_01611_00_metrosexual_M.jpg', 'W_00493_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_24628_70_hippie_M.jpg', 'W_12567_60_mods_M.jpg', 'W_02688_60_mods_M.jpg', 'W_12530_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_28022_50_ivy_M.jpg', 'W_29942_50_ivy_M.jpg', 'W_15740_70_hippie_M.jpg', 'W_27773_80_bold_M.jpg', 'W_01654_90_hiphop_M.jpg', 'W_24747_60_mods_M.jpg', 'W_27791_00_metrosexual_M.jpg', 'W_16393_80_bold_M.jpg', 'W_29063_90_hiphop_M.jpg', 'W_29251_10_sportivecasual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64397\n",
            "  Training Preferred: ['W_17793_19_normcore_M.jpg', 'W_27747_19_normcore_M.jpg', 'W_07344_10_sportivecasual_M.jpg', 'W_24205_80_bold_M.jpg', 'W_24889_50_ivy_M.jpg', 'W_25520_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_16818_19_normcore_M.jpg', 'W_25006_19_normcore_M.jpg', 'W_31360_19_normcore_M.jpg', 'W_06665_00_metrosexual_M.jpg', 'W_32387_90_hiphop_M.jpg', 'W_30015_00_metrosexual_M.jpg', 'W_11080_00_metrosexual_M.jpg', 'W_29830_90_hiphop_M.jpg', 'W_32833_80_bold_M.jpg', 'W_28319_90_hiphop_M.jpg', 'W_24348_70_hippie_M.jpg', 'W_02741_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_09881_10_sportivecasual_M.jpg', 'W_02660_60_mods_M.jpg', 'W_29897_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_07121_80_bold_M.jpg', 'W_15184_60_mods_M.jpg', 'W_25823_80_bold_M.jpg', 'W_15658_00_metrosexual_M.jpg', 'W_04245_70_hippie_M.jpg', 'W_32536_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64460\n",
            "  Training Preferred: ['W_24294_80_bold_M.jpg', 'W_37381_70_hippie_M.jpg', 'W_26530_00_metrosexual_M.jpg', 'W_06514_80_bold_M.jpg', 'W_24934_90_hiphop_M.jpg', 'W_15653_60_mods_M.jpg', 'W_12817_50_ivy_M.jpg', 'W_10792_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_25082_70_hippie_M.jpg', 'W_15721_00_metrosexual_M.jpg', 'W_25069_90_hiphop_M.jpg', 'W_30522_00_metrosexual_M.jpg', 'W_31356_80_bold_M.jpg', 'W_00038_60_mods_M.jpg', 'W_25526_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_12817_50_ivy_M.jpg', 'W_30591_50_ivy_M.jpg', 'W_25715_10_sportivecasual_M.jpg', 'W_23899_19_normcore_M.jpg', 'W_24883_00_metrosexual_M.jpg', 'W_32385_19_normcore_M.jpg', 'W_25649_19_normcore_M.jpg', 'W_16732_70_hippie_M.jpg']\n",
            "  Validation Not Preferred: ['W_17616_70_hippie_M.jpg', 'W_29693_19_normcore_M.jpg', 'W_24685_80_bold_M.jpg', 'W_26227_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 368\n",
            "  Training Preferred: ['W_02804_19_normcore_M.jpg', 'W_06896_10_sportivecasual_M.jpg', 'W_17320_70_hippie_M.jpg', 'W_17455_00_metrosexual_M.jpg', 'W_17536_80_bold_M.jpg', 'W_06843_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_11108_00_metrosexual_M.jpg', 'W_15519_90_hiphop_M.jpg', 'W_02777_90_hiphop_M.jpg', 'W_16157_70_hippie_M.jpg', 'W_15568_70_hippie_M.jpg', 'W_15453_70_hippie_M.jpg', 'W_15340_50_ivy_M.jpg', 'W_15157_60_mods_M.jpg', 'W_12459_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_12817_50_ivy_M.jpg', 'W_04678_50_ivy_M.jpg', 'W_06864_10_sportivecasual_M.jpg', 'W_01703_00_metrosexual_M.jpg', 'W_04622_60_mods_M.jpg', 'W_00551_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_15340_50_ivy_M.jpg', 'W_06551_60_mods_M.jpg', 'W_16034_80_bold_M.jpg', 'W_16848_19_normcore_M.jpg', 'W_15791_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62625\n",
            "  Training Preferred: ['W_01999_19_normcore_W.jpg', 'W_09363_19_genderless_W.jpg', 'W_02508_10_athleisure_W.jpg', 'W_01998_90_lingerie_W.jpg', 'W_05247_90_hiphop_W.jpg', 'W_07950_70_military_W.jpg', 'W_11537_50_feminine_W.jpg', 'W_10465_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_08477_19_normcore_W.jpg', 'W_14036_00_cityglam_W.jpg', 'W_08119_10_athleisure_W.jpg', 'W_01955_80_bodyconscious_W.jpg', 'W_11938_70_hippie_W.jpg', 'W_18943_80_powersuit_W.jpg', 'W_13068_80_powersuit_W.jpg', 'W_18601_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_09363_19_genderless_W.jpg', 'W_10429_60_minimal_W.jpg', 'W_03334_90_kitsch_W.jpg', 'W_09001_10_athleisure_W.jpg', 'W_01998_90_lingerie_W.jpg', 'W_09027_60_minimal_W.jpg', 'W_07916_80_powersuit_W.jpg', 'W_14785_00_cityglam_W.jpg']\n",
            "  Validation Not Preferred: ['W_07753_70_hippie_W.jpg', 'W_04840_50_feminine_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63057\n",
            "  Training Preferred: ['W_07997_19_normcore_W.jpg', 'W_10523_00_ecology_W.jpg', 'W_01899_10_sportivecasual_W.jpg', 'W_14615_90_kitsch_W.jpg', 'W_07839_70_hippie_W.jpg', 'W_10880_60_minimal_W.jpg', 'W_14866_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_07757_19_genderless_W.jpg', 'W_19221_19_normcore_W.jpg', 'W_08866_10_sportivecasual_W.jpg', 'W_04179_00_cityglam_W.jpg', 'W_08525_90_lingerie_W.jpg', 'W_13863_60_minimal_W.jpg', 'W_07450_50_feminine_W.jpg', 'W_13137_60_minimal_W.jpg', 'W_01374_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_01035_70_military_W.jpg', 'W_03447_70_military_W.jpg', 'W_03624_10_sportivecasual_W.jpg', 'W_13186_80_powersuit_W.jpg', 'W_06448_10_sportivecasual_W.jpg']\n",
            "  Validation Not Preferred: ['W_13278_19_normcore_W.jpg', 'W_13098_70_punk_W.jpg', 'W_02651_50_feminine_W.jpg', 'W_08866_10_sportivecasual_W.jpg', 'W_05526_10_sportivecasual_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63392\n",
            "  Training Preferred: ['W_12784_10_sportivecasual_M.jpg', 'W_15370_50_ivy_M.jpg', 'W_04242_60_mods_M.jpg', 'W_07123_70_hippie_M.jpg']\n",
            "  Training Not Preferred: ['W_17728_10_sportivecasual_M.jpg', 'W_16319_10_sportivecasual_M.jpg', 'W_17815_00_metrosexual_M.jpg', 'W_01602_00_metrosexual_M.jpg', 'W_04614_00_metrosexual_M.jpg', 'W_17603_50_ivy_M.jpg', 'W_11052_70_hippie_M.jpg', 'W_12896_60_mods_M.jpg', 'W_06249_70_hippie_M.jpg']\n",
            "  Validation Preferred: ['W_06576_50_ivy_M.jpg', 'W_10820_50_ivy_M.jpg', 'W_15370_50_ivy_M.jpg', 'W_15248_50_ivy_M.jpg', 'W_07279_80_bold_M.jpg', 'W_00865_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_15756_70_hippie_M.jpg', 'W_17603_50_ivy_M.jpg', 'W_16075_80_bold_M.jpg', 'W_16503_70_hippie_M.jpg', 'W_12128_80_bold_M.jpg', 'W_12702_10_sportivecasual_M.jpg', 'W_17235_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63479\n",
            "  Training Preferred: ['W_09086_19_normcore_W.jpg', 'W_01329_19_lounge_W.jpg', 'W_19413_00_oriental_W.jpg', 'W_14584_50_classic_W.jpg', 'W_18202_60_minimal_W.jpg', 'W_04994_60_popart_W.jpg']\n",
            "  Training Not Preferred: ['W_11753_19_genderless_W.jpg', 'W_18878_19_genderless_W.jpg', 'W_10256_90_lingerie_W.jpg', 'W_13650_90_hiphop_W.jpg', 'W_00631_70_disco_W.jpg', 'W_19921_70_punk_W.jpg', 'W_00153_60_minimal_W.jpg', 'W_14711_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_07811_80_powersuit_W.jpg', 'W_18202_60_minimal_W.jpg', 'W_00974_10_sportivecasual_W.jpg', 'W_07871_00_cityglam_W.jpg', 'W_06438_00_ecology_W.jpg', 'W_09085_60_minimal_W.jpg', 'W_04994_60_popart_W.jpg']\n",
            "  Validation Not Preferred: ['W_18878_19_genderless_W.jpg', 'W_03717_10_athleisure_W.jpg', 'W_11936_00_oriental_W.jpg', 'W_00624_80_bodyconscious_W.jpg', 'W_18095_90_kitsch_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64223\n",
            "  Training Preferred: ['W_04537_19_normcore_M.jpg', 'W_17796_00_metrosexual_M.jpg', 'W_24100_60_mods_M.jpg', 'W_32045_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_01687_19_normcore_M.jpg', 'W_24958_90_hiphop_M.jpg', 'W_25748_90_hiphop_M.jpg', 'W_15815_70_hippie_M.jpg', 'W_26292_90_hiphop_M.jpg', 'W_02715_70_hippie_M.jpg', 'W_11024_70_hippie_M.jpg', 'W_07324_50_ivy_M.jpg', 'W_02736_60_mods_M.jpg', 'W_27848_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_32136_50_ivy_M.jpg', 'W_17796_00_metrosexual_M.jpg', 'W_00117_19_normcore_M.jpg', 'W_12668_10_sportivecasual_M.jpg', 'W_28719_10_sportivecasual_M.jpg', 'W_06814_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_32407_60_mods_M.jpg', 'W_02736_60_mods_M.jpg', 'W_11024_70_hippie_M.jpg', 'W_26324_70_hippie_M.jpg', 'W_15381_80_bold_M.jpg', 'W_02816_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64310\n",
            "  Training Preferred: ['W_25934_90_hiphop_M.jpg', 'W_26375_70_hippie_M.jpg', 'W_04692_90_hiphop_M.jpg', 'W_16007_70_hippie_M.jpg', 'W_05880_60_mods_M.jpg']\n",
            "  Training Not Preferred: ['W_32159_19_normcore_M.jpg', 'W_28801_19_normcore_M.jpg', 'W_28741_19_normcore_M.jpg', 'W_00882_19_normcore_M.jpg', 'W_16259_80_bold_M.jpg', 'W_31790_00_metrosexual_M.jpg', 'W_01799_00_metrosexual_M.jpg', 'W_15740_70_hippie_M.jpg', 'W_31120_90_hiphop_M.jpg', 'W_10848_50_ivy_M.jpg', 'W_32131_50_ivy_M.jpg', 'W_25380_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_25934_90_hiphop_M.jpg']\n",
            "  Validation Not Preferred: ['W_30559_50_ivy_M.jpg', 'W_15740_70_hippie_M.jpg', 'W_04237_60_mods_M.jpg', 'W_31790_00_metrosexual_M.jpg', 'W_15217_00_metrosexual_M.jpg', 'W_15362_60_mods_M.jpg', 'W_32233_00_metrosexual_M.jpg', 'W_24543_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64571\n",
            "  Training Preferred: ['W_00794_19_normcore_M.jpg', 'W_12547_90_hiphop_M.jpg', 'W_04514_70_hippie_M.jpg']\n",
            "  Training Not Preferred: ['W_31502_19_normcore_M.jpg', 'W_25909_10_sportivecasual_M.jpg', 'W_29383_10_sportivecasual_M.jpg', 'W_32797_90_hiphop_M.jpg', 'W_18424_80_bold_M.jpg', 'W_15448_70_hippie_M.jpg', 'W_11145_00_metrosexual_M.jpg', 'W_25406_00_metrosexual_M.jpg', 'W_32860_80_bold_M.jpg', 'W_16985_70_hippie_M.jpg', 'W_24180_60_mods_M.jpg', 'W_24059_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_23848_50_ivy_M.jpg', 'W_24102_60_mods_M.jpg']\n",
            "  Validation Not Preferred: ['W_30223_19_normcore_M.jpg', 'W_07026_10_sportivecasual_M.jpg', 'W_32233_00_metrosexual_M.jpg', 'W_17738_80_bold_M.jpg', 'W_24947_90_hiphop_M.jpg', 'W_32445_60_mods_M.jpg', 'W_26965_90_hiphop_M.jpg', 'W_25909_10_sportivecasual_M.jpg', 'W_25406_00_metrosexual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64598\n",
            "  Training Preferred: ['W_48074_10_sportivecasual_W.jpg', 'W_21732_10_sportivecasual_W.jpg', 'W_00638_90_hiphop_W.jpg', 'W_28488_80_powersuit_W.jpg', 'W_27930_80_powersuit_W.jpg', 'W_39905_70_punk_W.jpg', 'W_32949_70_punk_W.jpg', 'W_04895_50_classic_W.jpg', 'W_09961_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_37648_10_sportivecasual_W.jpg', 'W_11262_00_oriental_W.jpg', 'W_36408_10_sportivecasual_W.jpg', 'W_31881_80_powersuit_W.jpg', 'W_14139_90_lingerie_W.jpg', 'W_27619_80_powersuit_W.jpg', 'W_19335_50_feminine_W.jpg', 'W_02442_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_41341_19_lounge_W.jpg', 'W_47967_19_normcore_W.jpg', 'W_34952_19_genderless_W.jpg', 'W_45386_00_oriental_W.jpg', 'W_30431_80_powersuit_W.jpg']\n",
            "  Validation Not Preferred: ['W_11262_00_oriental_W.jpg', 'W_28338_80_powersuit_W.jpg', 'W_19335_50_feminine_W.jpg', 'W_20593_70_punk_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 7658\n",
            "  Training Preferred: ['W_08708_10_sportivecasual_W.jpg', 'W_01234_10_sportivecasual_W.jpg']\n",
            "  Training Not Preferred: ['W_08680_00_cityglam_W.jpg', 'W_02456_10_sportivecasual_W.jpg', 'W_08383_10_athleisure_W.jpg', 'W_08112_90_hiphop_W.jpg', 'W_00344_90_grunge_W.jpg', 'W_14380_90_hiphop_W.jpg', 'W_18658_80_powersuit_W.jpg', 'W_05312_80_bodyconscious_W.jpg', 'W_07851_70_disco_W.jpg', 'W_07975_80_powersuit_W.jpg', 'W_10510_60_space_W.jpg', 'W_18996_50_feminine_W.jpg', 'W_13271_60_minimal_W.jpg', 'W_13941_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_09731_19_genderless_W.jpg', 'W_01234_10_sportivecasual_W.jpg', 'W_04927_50_feminine_W.jpg']\n",
            "  Validation Not Preferred: ['W_14923_60_minimal_W.jpg', 'W_10510_60_space_W.jpg', 'W_05312_80_bodyconscious_W.jpg', 'W_02345_60_space_W.jpg', 'W_13535_80_powersuit_W.jpg', 'W_13688_90_hiphop_W.jpg', 'W_19003_50_feminine_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 62155\n",
            "  Training Preferred: ['W_01540_19_normcore_M.jpg', 'W_31063_19_normcore_M.jpg', 'W_27854_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_17513_19_normcore_M.jpg', 'W_23876_19_normcore_M.jpg', 'W_15666_90_hiphop_M.jpg', 'W_24880_00_metrosexual_M.jpg', 'W_32383_00_metrosexual_M.jpg', 'W_15600_70_hippie_M.jpg', 'W_24569_70_hippie_M.jpg', 'W_24492_70_hippie_M.jpg', 'W_17353_50_ivy_M.jpg', 'W_12265_00_metrosexual_M.jpg', 'W_06186_60_mods_M.jpg', 'W_01726_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_00804_50_ivy_M.jpg', 'W_27854_50_ivy_M.jpg', 'W_17004_10_sportivecasual_M.jpg']\n",
            "  Validation Not Preferred: ['W_32383_00_metrosexual_M.jpg', 'W_00492_50_ivy_M.jpg', 'W_17353_50_ivy_M.jpg', 'W_27773_80_bold_M.jpg', 'W_26120_19_normcore_M.jpg', 'W_06186_60_mods_M.jpg', 'W_28203_10_sportivecasual_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63430\n",
            "  Training Preferred: ['W_08809_19_lounge_W.jpg', 'W_10412_00_oriental_W.jpg', 'W_05469_10_athleisure_W.jpg', 'W_00570_90_lingerie_W.jpg', 'W_13510_80_powersuit_W.jpg']\n",
            "  Training Not Preferred: ['W_03532_19_normcore_W.jpg', 'W_13574_90_hiphop_W.jpg', 'W_14173_90_kitsch_W.jpg', 'W_02282_70_hippie_W.jpg', 'W_18618_80_powersuit_W.jpg', 'W_08501_70_hippie_W.jpg', 'W_14852_50_feminine_W.jpg', 'W_00607_60_space_W.jpg', 'W_04865_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_01056_00_cityglam_W.jpg', 'W_10598_60_minimal_W.jpg', 'W_13510_80_powersuit_W.jpg', 'W_13973_90_lingerie_W.jpg', 'W_02557_00_ecology_W.jpg']\n",
            "  Validation Not Preferred: ['W_10186_80_powersuit_W.jpg', 'W_10191_00_oriental_W.jpg', 'W_14852_50_feminine_W.jpg', 'W_13574_90_hiphop_W.jpg', 'W_18093_00_ecology_W.jpg', 'W_10722_60_space_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 30790\n",
            "  Training Preferred: ['W_33023_10_sportivecasual_M.jpg', 'W_31568_19_normcore_M.jpg', 'W_26425_90_hiphop_M.jpg', 'W_06863_60_mods_M.jpg', 'W_06511_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_25835_10_sportivecasual_M.jpg', 'W_29485_10_sportivecasual_M.jpg', 'W_28604_10_sportivecasual_M.jpg', 'W_26489_70_hippie_M.jpg', 'W_26359_19_normcore_M.jpg', 'W_12210_80_bold_M.jpg', 'W_24886_70_hippie_M.jpg', 'W_32975_80_bold_M.jpg', 'W_07252_90_hiphop_M.jpg', 'W_06519_50_ivy_M.jpg', 'W_24769_60_mods_M.jpg']\n",
            "  Validation Preferred: []\n",
            "  Validation Not Preferred: ['W_10823_50_ivy_M.jpg', 'W_15661_70_hippie_M.jpg', 'W_24923_00_metrosexual_M.jpg', 'W_48687_60_mods_M.jpg', 'W_17767_19_normcore_M.jpg', 'W_27042_60_mods_M.jpg', 'W_31823_19_normcore_M.jpg', 'W_07187_70_hippie_M.jpg', 'W_25411_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63569\n",
            "  Training Preferred: ['W_05725_19_lounge_W.jpg', 'W_09109_10_sportivecasual_W.jpg', 'W_02403_70_punk_W.jpg', 'W_03536_70_military_W.jpg', 'W_19192_60_minimal_W.jpg']\n",
            "  Training Not Preferred: ['W_07840_19_normcore_W.jpg', 'W_08957_19_normcore_W.jpg', 'W_05950_00_cityglam_W.jpg', 'W_08845_10_sportivecasual_W.jpg', 'W_08139_10_athleisure_W.jpg', 'W_06476_00_cityglam_W.jpg', 'W_13663_90_hiphop_W.jpg', 'W_14173_90_kitsch_W.jpg', 'W_18353_80_powersuit_W.jpg', 'W_18739_70_military_W.jpg', 'W_02390_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_14785_00_cityglam_W.jpg', 'W_03536_70_military_W.jpg']\n",
            "  Validation Not Preferred: ['W_11375_19_normcore_W.jpg', 'W_01020_50_feminine_W.jpg', 'W_08139_10_athleisure_W.jpg', 'W_05619_00_ecology_W.jpg', 'W_18353_80_powersuit_W.jpg', 'W_13329_50_feminine_W.jpg', 'W_02277_80_bodyconscious_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63742\n",
            "  Training Preferred: []\n",
            "  Training Not Preferred: ['W_03440_19_genderless_W.jpg', 'W_00191_10_sportivecasual_W.jpg', 'W_08047_90_hiphop_W.jpg', 'W_13399_90_kitsch_W.jpg', 'W_14310_80_powersuit_W.jpg', 'W_05957_70_disco_W.jpg', 'W_14791_70_hippie_W.jpg', 'W_03952_70_hippie_W.jpg', 'W_08589_80_bodyconscious_W.jpg', 'W_10561_50_classic_W.jpg', 'W_18707_60_space_W.jpg', 'W_01956_50_feminine_W.jpg', 'W_01187_50_feminine_W.jpg']\n",
            "  Validation Preferred: []\n",
            "  Validation Not Preferred: ['W_11214_50_feminine_W.jpg', 'W_05653_80_bodyconscious_W.jpg', 'W_03412_50_classic_W.jpg', 'W_03791_70_disco_W.jpg', 'W_14777_80_powersuit_W.jpg', 'W_00191_10_sportivecasual_W.jpg', 'W_09376_00_cityglam_W.jpg', 'W_19940_00_oriental_W.jpg', 'W_03927_60_minimal_W.jpg', 'W_00709_60_popart_W.jpg', 'W_14468_10_sportivecasual_W.jpg', 'W_05562_10_sportivecasual_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64295\n",
            "  Training Preferred: ['W_28460_10_sportivecasual_M.jpg', 'W_16297_80_bold_M.jpg', 'W_10098_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_04683_10_sportivecasual_M.jpg', 'W_16374_10_sportivecasual_M.jpg', 'W_26062_80_bold_M.jpg', 'W_02726_00_metrosexual_M.jpg', 'W_04237_60_mods_M.jpg', 'W_02742_60_mods_M.jpg', 'W_26196_50_ivy_M.jpg', 'W_27750_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_30027_50_ivy_M.jpg', 'W_33329_50_ivy_M.jpg', 'W_27750_60_mods_M.jpg', 'W_28563_90_hiphop_M.jpg', 'W_12803_70_hippie_M.jpg']\n",
            "  Validation Not Preferred: ['W_23900_50_ivy_M.jpg', 'W_32314_19_normcore_M.jpg', 'W_31478_19_normcore_M.jpg', 'W_15729_90_hiphop_M.jpg', 'W_25761_90_hiphop_M.jpg', 'W_24598_80_bold_M.jpg', 'W_04237_60_mods_M.jpg', 'W_16374_10_sportivecasual_M.jpg', 'W_27750_60_mods_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64561\n",
            "  Training Preferred: ['W_36907_19_genderless_W.jpg', 'W_35091_80_powersuit_W.jpg', 'W_18205_50_feminine_W.jpg', 'W_18759_50_feminine_W.jpg', 'W_18066_50_classic_W.jpg', 'W_22239_60_space_W.jpg']\n",
            "  Training Not Preferred: ['W_41279_19_genderless_W.jpg', 'W_42868_10_sportivecasual_W.jpg', 'W_26946_19_lounge_W.jpg', 'W_32248_80_powersuit_W.jpg', 'W_49287_70_punk_W.jpg', 'W_02232_70_hippie_W.jpg', 'W_33622_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_38656_10_sportivecasual_W.jpg', 'W_41448_10_sportivecasual_W.jpg', 'W_22239_60_space_W.jpg', 'W_18205_50_feminine_W.jpg', 'W_35091_80_powersuit_W.jpg', 'W_30671_70_hippie_W.jpg', 'W_06046_10_sportivecasual_W.jpg', 'W_33305_60_space_W.jpg']\n",
            "  Validation Not Preferred: ['W_23519_60_minimal_W.jpg', 'W_33240_80_bodyconscious_W.jpg', 'W_22943_10_athleisure_W.jpg', 'W_48457_60_minimal_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 20768\n",
            "  Training Preferred: ['W_13225_19_normcore_W.jpg', 'W_09011_10_sportivecasual_W.jpg', 'W_12030_80_powersuit_W.jpg', 'W_18900_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_05272_10_sportivecasual_W.jpg', 'W_08773_90_lingerie_W.jpg', 'W_04769_90_kitsch_W.jpg', 'W_11868_90_grunge_W.jpg', 'W_13238_80_powersuit_W.jpg', 'W_00148_60_popart_W.jpg', 'W_06318_50_classic_W.jpg', 'W_18730_50_feminine_W.jpg', 'W_09899_50_classic_W.jpg']\n",
            "  Validation Preferred: ['W_18373_50_classic_W.jpg']\n",
            "  Validation Not Preferred: ['W_02140_10_sportivecasual_W.jpg', 'W_10768_00_ecology_W.jpg', 'W_10768_00_ecology_W.jpg', 'W_13519_00_oriental_W.jpg', 'W_08837_10_sportivecasual_W.jpg', 'W_13696_90_kitsch_W.jpg', 'W_19960_70_punk_W.jpg', 'W_11680_00_cityglam_W.jpg', 'W_18730_50_feminine_W.jpg', 'W_11200_00_oriental_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63359\n",
            "  Training Preferred: ['W_00410_19_genderless_W.jpg', 'W_01958_00_cityglam_W.jpg', 'W_08052_90_hiphop_W.jpg', 'W_06038_90_hiphop_W.jpg', 'W_03557_70_hippie_W.jpg', 'W_13518_80_powersuit_W.jpg', 'W_08140_50_feminine_W.jpg', 'W_18057_50_classic_W.jpg']\n",
            "  Training Not Preferred: ['W_10207_00_oriental_W.jpg', 'W_10289_00_oriental_W.jpg', 'W_13858_80_bodyconscious_W.jpg', 'W_19530_60_popart_W.jpg', 'W_13941_60_minimal_W.jpg', 'W_12019_50_feminine_W.jpg', 'W_07682_50_feminine_W.jpg']\n",
            "  Validation Preferred: ['W_03727_19_genderless_W.jpg', 'W_13518_80_powersuit_W.jpg', 'W_18057_50_classic_W.jpg', 'W_00161_60_space_W.jpg', 'W_01389_10_sportivecasual_W.jpg', 'W_01000_10_sportivecasual_W.jpg']\n",
            "  Validation Not Preferred: ['W_13359_80_powersuit_W.jpg', 'W_14417_10_sportivecasual_W.jpg', 'W_19559_00_oriental_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63473\n",
            "  Training Preferred: ['W_05699_10_athleisure_W.jpg', 'W_03601_10_sportivecasual_W.jpg', 'W_09426_90_kitsch_W.jpg', 'W_14824_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_19502_19_lounge_W.jpg', 'W_04179_00_cityglam_W.jpg', 'W_09404_10_sportivecasual_W.jpg', 'W_15005_90_kitsch_W.jpg', 'W_02151_90_hiphop_W.jpg', 'W_05003_70_hippie_W.jpg', 'W_18562_80_powersuit_W.jpg', 'W_18546_50_classic_W.jpg', 'W_11818_50_feminine_W.jpg', 'W_18622_60_minimal_W.jpg', 'W_14831_60_space_W.jpg']\n",
            "  Validation Preferred: ['W_11495_19_genderless_W.jpg', 'W_09295_50_classic_W.jpg']\n",
            "  Validation Not Preferred: ['W_13519_00_oriental_W.jpg', 'W_13398_80_powersuit_W.jpg', 'W_18622_60_minimal_W.jpg', 'W_18546_50_classic_W.jpg', 'W_09307_60_popart_W.jpg', 'W_09021_60_minimal_W.jpg', 'W_19576_90_grunge_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63759\n",
            "  Training Preferred: ['W_01329_19_lounge_W.jpg', 'W_09611_10_sportivecasual_W.jpg', 'W_08063_90_hiphop_W.jpg', 'W_05821_90_kitsch_W.jpg', 'W_07935_70_hippie_W.jpg', 'W_05715_70_military_W.jpg']\n",
            "  Training Not Preferred: ['W_18199_19_normcore_W.jpg', 'W_01334_19_normcore_W.jpg', 'W_03258_00_ecology_W.jpg', 'W_10177_00_oriental_W.jpg', 'W_14903_10_athleisure_W.jpg', 'W_04031_80_bodyconscious_W.jpg', 'W_19515_70_punk_W.jpg', 'W_18549_60_minimal_W.jpg']\n",
            "  Validation Preferred: ['W_07811_80_powersuit_W.jpg']\n",
            "  Validation Not Preferred: ['W_19967_50_feminine_W.jpg', 'W_03258_00_ecology_W.jpg', 'W_02170_50_feminine_W.jpg', 'W_13789_60_space_W.jpg', 'W_11685_50_classic_W.jpg', 'W_05181_50_feminine_W.jpg', 'W_08467_80_bodyconscious_W.jpg', 'W_11266_60_popart_W.jpg', 'W_18026_60_space_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 58251\n",
            "  Training Preferred: ['T_08663_19_normcore_W.jpg', 'W_15018_19_normcore_W.jpg', 'W_01166_10_sportivecasual_W.jpg', 'W_04996_90_kitsch_W.jpg', 'W_01259_90_lingerie_W.jpg']\n",
            "  Training Not Preferred: ['W_64047_10_sportivecasual_W.jpg', 'W_08886_10_athleisure_W.jpg', 'W_63956_80_powersuit_W.jpg', 'W_13086_80_powersuit_W.jpg', 'W_19145_70_hippie_W.jpg', 'W_02342_70_disco_W.jpg', 'W_34247_70_hippie_W.jpg', 'W_13952_80_bodyconscious_W.jpg']\n",
            "  Validation Preferred: ['T_14538_00_cityglam_W.jpg', 'W_14785_00_cityglam_W.jpg', 'W_00716_60_minimal_W.jpg', 'W_03992_70_punk_W.jpg', 'W_04854_50_feminine_W.jpg', 'W_19520_50_feminine_W.jpg']\n",
            "  Validation Not Preferred: ['W_04101_19_lounge_W.jpg', 'W_64047_10_sportivecasual_W.jpg', 'W_08886_10_athleisure_W.jpg', 'W_09551_00_cityglam_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 66731\n",
            "  Training Preferred: ['W_67492_19_lounge_W.jpg', 'W_01088_70_military_W.jpg', 'T_00770_60_minimal_W.jpg', 'W_04781_50_feminine_W.jpg']\n",
            "  Training Not Preferred: ['W_40003_10_sportivecasual_W.jpg', 'T_11421_00_cityglam_W.jpg', 'W_35100_10_sportivecasual_W.jpg', 'W_29733_10_sportivecasual_W.jpg', 'W_55996_90_lingerie_W.jpg', 'W_64332_80_powersuit_W.jpg', 'W_36393_70_hippie_W.jpg', 'T_07471_80_bodyconscious_W.jpg', 'W_33100_70_punk_W.jpg', 'W_39065_60_minimal_W.jpg', 'W_04852_50_feminine_W.jpg']\n",
            "  Validation Preferred: []\n",
            "  Validation Not Preferred: ['W_39812_90_kitsch_W.jpg', 'W_37014_60_minimal_W.jpg', 'W_33901_90_kitsch_W.jpg', 'W_29733_10_sportivecasual_W.jpg', 'W_22783_70_hippie_W.jpg', 'W_47122_80_powersuit_W.jpg', 'W_64332_80_powersuit_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59637\n",
            "  Training Preferred: ['W_00784_19_normcore_W.jpg', 'W_08042_10_athleisure_W.jpg', 'W_01355_10_sportivecasual_W.jpg', 'W_19870_00_oriental_W.jpg', 'W_09626_10_athleisure_W.jpg', 'W_03580_60_minimal_W.jpg', 'W_10455_60_space_W.jpg']\n",
            "  Training Not Preferred: ['W_18644_19_genderless_W.jpg', 'W_14410_19_genderless_W.jpg', 'W_03430_90_lingerie_W.jpg', 'W_18462_90_kitsch_W.jpg', 'W_08467_80_bodyconscious_W.jpg', 'W_03936_70_hippie_W.jpg', 'W_10952_60_minimal_W.jpg', 'W_18160_50_classic_W.jpg']\n",
            "  Validation Preferred: ['W_10455_60_space_W.jpg']\n",
            "  Validation Not Preferred: ['W_08467_80_bodyconscious_W.jpg', 'W_02333_90_hiphop_W.jpg', 'W_07981_70_military_W.jpg', 'W_05818_90_lingerie_W.jpg', 'W_06000_80_powersuit_W.jpg', 'W_18160_50_classic_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63508\n",
            "  Training Preferred: ['W_15768_19_normcore_M.jpg', 'W_17117_19_normcore_M.jpg', 'W_15156_00_metrosexual_M.jpg', 'W_12698_80_bold_M.jpg', 'W_15488_00_metrosexual_M.jpg', 'W_16295_70_hippie_M.jpg', 'W_10834_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_07043_10_sportivecasual_M.jpg', 'W_16409_10_sportivecasual_M.jpg', 'W_09861_10_sportivecasual_M.jpg', 'W_11071_00_metrosexual_M.jpg', 'W_13458_80_bold_M.jpg', 'W_16180_50_ivy_M.jpg', 'W_10817_60_mods_M.jpg', 'W_12807_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_15294_50_ivy_M.jpg', 'W_16295_70_hippie_M.jpg', 'W_06917_19_normcore_M.jpg']\n",
            "  Validation Not Preferred: ['W_12378_80_bold_M.jpg', 'W_12214_70_hippie_M.jpg', 'W_06214_90_hiphop_M.jpg', 'W_16578_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63601\n",
            "  Training Preferred: ['W_11313_19_genderless_W.jpg', 'W_07569_00_cityglam_W.jpg', 'W_10321_00_cityglam_W.jpg', 'W_09083_00_ecology_W.jpg', 'W_14443_10_sportivecasual_W.jpg']\n",
            "  Training Not Preferred: ['W_11897_00_oriental_W.jpg', 'W_10398_00_ecology_W.jpg', 'W_05526_10_sportivecasual_W.jpg', 'W_01969_90_lingerie_W.jpg', 'W_03825_90_lingerie_W.jpg', 'W_07657_60_popart_W.jpg']\n",
            "  Validation Preferred: ['W_03859_19_normcore_W.jpg', 'W_13781_60_minimal_W.jpg', 'W_01925_10_sportivecasual_W.jpg', 'W_04836_50_feminine_W.jpg', 'W_09083_00_ecology_W.jpg', 'W_07490_80_powersuit_W.jpg', 'W_06453_10_athleisure_W.jpg']\n",
            "  Validation Not Preferred: ['W_18080_90_kitsch_W.jpg', 'W_11903_00_oriental_W.jpg', 'W_05526_10_sportivecasual_W.jpg', 'W_13304_80_powersuit_W.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 28571\n",
            "  Training Preferred: ['W_07141_10_sportivecasual_M.jpg', 'W_02943_90_hiphop_M.jpg', 'W_09140_60_mods_M.jpg', 'W_12826_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_10791_19_normcore_M.jpg', 'W_15596_70_hippie_M.jpg', 'W_12128_80_bold_M.jpg', 'W_12360_80_bold_M.jpg', 'W_15388_00_metrosexual_M.jpg', 'W_16203_90_hiphop_M.jpg', 'W_06735_50_ivy_M.jpg', 'W_10056_60_mods_M.jpg']\n",
            "  Validation Preferred: ['W_00073_50_ivy_M.jpg']\n",
            "  Validation Not Preferred: ['W_06576_50_ivy_M.jpg', 'W_12128_80_bold_M.jpg', 'W_16465_10_sportivecasual_M.jpg', 'W_15910_60_mods_M.jpg', 'W_16247_70_hippie_M.jpg', 'W_17532_70_hippie_M.jpg', 'W_16452_70_hippie_M.jpg', 'W_15716_90_hiphop_M.jpg']\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64336\n",
            "  Training Preferred: ['W_32135_19_normcore_M.jpg', 'W_04328_19_normcore_M.jpg', 'W_01413_10_sportivecasual_M.jpg', 'W_24493_70_hippie_M.jpg', 'W_06603_90_hiphop_M.jpg', 'W_00479_60_mods_M.jpg', 'W_32459_50_ivy_M.jpg']\n",
            "  Training Not Preferred: ['W_25202_90_hiphop_M.jpg', 'W_24347_00_metrosexual_M.jpg', 'W_15920_00_metrosexual_M.jpg', 'W_26487_50_ivy_M.jpg', 'W_27903_50_ivy_M.jpg']\n",
            "  Validation Preferred: ['W_06557_60_mods_M.jpg', 'W_12312_80_bold_M.jpg', 'W_24493_70_hippie_M.jpg', 'W_12635_70_hippie_M.jpg']\n",
            "  Validation Not Preferred: ['W_12315_80_bold_M.jpg', 'W_25202_90_hiphop_M.jpg', 'W_16172_70_hippie_M.jpg']\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[3-2] 최종?"
      ],
      "metadata": {
        "id": "_ydOtz386WeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import warnings\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 경고 메시지 무시\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(weights=None)\n",
        "        state_dict = torch.load(model_path, weights_only=True)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 코사인 유사도 및 유클리디안 거리 계산 함수 (배치 처리 적용)\n",
        "def calculate_similarity_scores(val_features, train_features, batch_size=100):\n",
        "    cosine_similarity_list = []\n",
        "    euclidean_distance_list = []\n",
        "\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(val_features), batch_size):\n",
        "            val_batch = val_features[i:i + batch_size]\n",
        "\n",
        "            # 코사인 유사도 계산\n",
        "            val_norm = val_batch / val_batch.norm(dim=1, keepdim=True)\n",
        "            train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "            cosine_sim_batch = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "            cosine_similarity_list.append(cosine_sim_batch)\n",
        "\n",
        "            # 유클리디안 거리 계산 (CPU에서 수행)\n",
        "            val_batch_cpu = val_batch.cpu().numpy()\n",
        "            train_features_cpu = train_features.cpu().numpy()\n",
        "            euclidean_dist_batch = -np.linalg.norm(val_batch_cpu[:, None, :] - train_features_cpu[None, :, :], axis=2)\n",
        "            euclidean_distance_list.append(euclidean_dist_batch)\n",
        "\n",
        "    cosine_similarity = np.vstack(cosine_similarity_list)\n",
        "    euclidean_distance = np.vstack(euclidean_distance_list)\n",
        "\n",
        "    return cosine_similarity, euclidean_distance\n",
        "\n",
        "# 결합된 유사도 스코어 계산 함수\n",
        "def combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=0.5):\n",
        "    return alpha * cosine_similarity + (1 - alpha) * euclidean_distance\n",
        "\n",
        "# 최적 alpha 찾기 함수\n",
        "def find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels):\n",
        "    best_alpha = 0.5\n",
        "    best_f1 = 0\n",
        "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
        "        combined_score = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha)\n",
        "        predicted_preferences = predict_style_preference(combined_score, train_preferences)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_alpha = alpha\n",
        "    return best_alpha\n",
        "\n",
        "# 최적 threshold 찾기 함수\n",
        "def find_optimal_threshold(similarity_scores, train_preferences, val_labels):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    train_len = len(train_preferences)\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = min(np.argmax(score_row), train_len - 1)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        actual, predicted, average='weighted', zero_division=0\n",
        "    )\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 데이터 불러오기 및 준비\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "train_preferences = [1] * len(train_features)\n",
        "\n",
        "# 유사도 계산 및 결합 점수 산출\n",
        "cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features, batch_size=100)\n",
        "optimal_alpha = find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels)\n",
        "combined_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=optimal_alpha)\n",
        "\n",
        "# 최적 threshold 찾기\n",
        "optimal_threshold = find_optimal_threshold(combined_scores, train_preferences, val_labels)\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}, Optimal Alpha: {optimal_alpha:.2f}\")\n",
        "\n",
        "# 최적 threshold로 예측 및 성능 평가\n",
        "predicted_preferences = predict_style_preference(combined_scores, train_preferences, optimal_threshold)\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "print(f\"Final Prediction Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Final Precision: {precision*100:.2f}%\")\n",
        "print(f\"Final Recall: {recall*100:.2f}%\")\n",
        "print(f\"Final F1-Score: {f1*100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "voFkGiHPR_5Y",
        "outputId": "58346547-b4b9-4fcf-a010-c152efb90375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:05<00:00, 116.92it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:08<00:00, 131.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Threshold: 0.10, Optimal Alpha: 0.60\n",
            "Final Prediction Accuracy: 57.89%\n",
            "Final Precision: 52.30%\n",
            "Final Recall: 57.89%\n",
            "Final F1-Score: 49.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 경로 설정 및 데이터 준비\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'\n",
        "excel_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 엑셀 파일에서 데이터 추출 함수\n",
        "def extract_preferences_from_excel(file_path):\n",
        "    preferences_dict = {}\n",
        "    preferences_df = pd.read_excel(file_path)\n",
        "\n",
        "    for idx, row in preferences_df.iterrows():\n",
        "        respondent_id = row['Respondent ID']\n",
        "        training_preferred = row['Training Style Preferred']\n",
        "        training_not_preferred = row['Training Style Not Preferred']\n",
        "        validation_preferred = row['Validation Style Preferred']\n",
        "        validation_not_preferred = row['Validation Style Not Preferred']\n",
        "\n",
        "        # 리스트 형태로 변환\n",
        "        training_preferred_list = training_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_preferred) else []\n",
        "        training_not_preferred_list = training_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_not_preferred) else []\n",
        "        validation_preferred_list = validation_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_preferred) else []\n",
        "        validation_not_preferred_list = validation_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_not_preferred) else []\n",
        "\n",
        "        preferences_dict[respondent_id] = {\n",
        "            'training_preferred': training_preferred_list,\n",
        "            'training_not_preferred': training_not_preferred_list,\n",
        "            'validation_preferred': validation_preferred_list,\n",
        "            'validation_not_preferred': validation_not_preferred_list\n",
        "        }\n",
        "\n",
        "    return preferences_dict\n",
        "\n",
        "# 결합된 유사도 스코어 계산 함수\n",
        "def combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=0.5):\n",
        "    return alpha * cosine_similarity + (1 - alpha) * euclidean_distance\n",
        "\n",
        "# 코사인 유사도 및 유클리디안 거리 계산 함수 (배치 처리 적용)\n",
        "def calculate_similarity_scores(val_features, train_features, batch_size=100):\n",
        "    cosine_similarity_list = []\n",
        "    euclidean_distance_list = []\n",
        "\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(val_features), batch_size):\n",
        "            val_batch = val_features[i:i + batch_size]\n",
        "\n",
        "            # 코사인 유사도 계산\n",
        "            val_norm = val_batch / val_batch.norm(dim=1, keepdim=True)\n",
        "            train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "            cosine_sim_batch = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "            cosine_similarity_list.append(cosine_sim_batch)\n",
        "\n",
        "            # 유클리디안 거리 계산\n",
        "            val_batch_cpu = val_batch.cpu().numpy()\n",
        "            train_features_cpu = train_features.cpu().numpy()\n",
        "            euclidean_dist_batch = -np.linalg.norm(val_batch_cpu[:, None, :] - train_features_cpu[None, :, :], axis=2)\n",
        "            euclidean_distance_list.append(euclidean_dist_batch)\n",
        "\n",
        "    cosine_similarity = np.vstack(cosine_similarity_list)\n",
        "    euclidean_distance = np.vstack(euclidean_distance_list)\n",
        "\n",
        "    return cosine_similarity, euclidean_distance\n",
        "\n",
        "# 최적 alpha 찾기 함수\n",
        "def find_optimal_alpha(cosine_similarity, euclidean_distance, train_preferences, val_labels):\n",
        "    best_alpha = 0.5\n",
        "    best_f1 = 0\n",
        "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
        "        combined_score = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha)\n",
        "        predicted_preferences = predict_style_preference(combined_score, train_preferences)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_alpha = alpha\n",
        "    return best_alpha\n",
        "\n",
        "# 최적 threshold 찾기 함수\n",
        "def find_optimal_threshold(similarity_scores, train_preferences, val_labels):\n",
        "    best_threshold = 0.5\n",
        "    best_f1 = 0\n",
        "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1 = f1\n",
        "            best_threshold = threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 유사도를 기반으로 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    train_len = len(train_preferences)\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        if max_similarity > threshold:\n",
        "            most_similar_index = min(np.argmax(score_row), train_len - 1)\n",
        "            predicted_label = train_preferences[most_similar_index]\n",
        "            predicted_preferences.append(predicted_label)\n",
        "        else:\n",
        "            predicted_preferences.append(0)\n",
        "    return predicted_preferences\n",
        "\n",
        "# 정확도, 정밀도, 재현율, F1 점수 계산 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        actual, predicted, average='weighted', zero_division=0\n",
        "    )\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# 실행\n",
        "if __name__ == \"__main__\":\n",
        "    # 장치 설정 및 특징 추출기 로드\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "    # 엑셀 파일에서 선호도 데이터 추출\n",
        "    preferences_dict = extract_preferences_from_excel(excel_file_path)\n",
        "\n",
        "    # 학습 및 검증 데이터 준비\n",
        "    train_style = [img for resp in preferences_dict.values() for img in resp['training_preferred']]\n",
        "    val_style = [img for resp in preferences_dict.values() for img in resp['validation_preferred'] + resp['validation_not_preferred']]\n",
        "    val_labels = [1] * sum(len(resp['validation_preferred']) for resp in preferences_dict.values()) + [0] * sum(len(resp['validation_not_preferred']) for resp in preferences_dict.values())\n",
        "\n",
        "    train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "    val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "    # 이미지 특징 추출\n",
        "    train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "    val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 유사도 계산 및 결합 점수 산출\n",
        "cosine_similarity, euclidean_distance = calculate_similarity_scores(val_features, train_features, batch_size=100)\n",
        "optimal_alpha = find_optimal_alpha(cosine_similarity, euclidean_distance, [1] * len(train_features), val_labels)\n",
        "combined_scores = combine_similarity_scores(cosine_similarity, euclidean_distance, alpha=optimal_alpha)\n",
        "\n",
        "# 최적 threshold 찾기\n",
        "optimal_threshold = find_optimal_threshold(combined_scores, [1] * len(train_features), val_labels)\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}, Optimal Alpha: {optimal_alpha:.2f}\")\n",
        "\n",
        "# 최적 threshold로 예측 및 성능 평가\n",
        "predicted_preferences = predict_style_preference(combined_scores, [1] * len(train_features), threshold=optimal_threshold)\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "\n",
        "print(f\"Final Prediction Accuracy: {accuracy*100:.2f}%\")\n",
        "print(f\"Final Precision: {precision*100:.2f}%\")\n",
        "print(f\"Final Recall: {recall*100:.2f}%\")\n",
        "print(f\"Final F1-Score: {f1*100:.2f}%\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jr65mM-zV8ry",
        "outputId": "fedd60c6-dbc8-4bfd-a2f3-05faa4381662"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Extracting Features: 100%|██████████| 674/674 [00:04<00:00, 135.09it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:08<00:00, 128.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Threshold: 0.10, Optimal Alpha: 0.60\n",
            "Final Prediction Accuracy: 57.89%\n",
            "Final Precision: 52.30%\n",
            "Final Recall: 57.89%\n",
            "Final F1-Score: 49.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 경로 설정\n",
        "train_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned'\n",
        "val_image_dir = '/content/drive/MyDrive/dataset/processed_segmentation_cleaned_for_val'\n",
        "model_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/model_final5.pth'\n",
        "excel_file_path = '/content/drive/MyDrive/데이터 크리에이터 캠프 최종 정리/김진/preferences0.xlsx'\n",
        "\n",
        "# ResNet 특징 추출기 클래스 정의 (fc 레이어 제외)\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self, model_path):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        resnet = models.resnet18(pretrained=False)\n",
        "        state_dict = torch.load(model_path)\n",
        "        state_dict = {k: v for k, v in state_dict.items() if not k.startswith(\"fc.\")}\n",
        "        resnet.load_state_dict(state_dict, strict=False)\n",
        "        self.features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.features(x)\n",
        "\n",
        "# 이미지 전처리 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# 이미지 로드 및 전처리 함수\n",
        "def load_and_preprocess_image(image_path, device):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "    return image\n",
        "\n",
        "# 데이터셋에서 이미지들의 특징 벡터를 추출하는 함수\n",
        "def extract_features_for_dataset(image_paths, feature_extractor, device):\n",
        "    features = []\n",
        "    feature_extractor.eval()\n",
        "    with torch.no_grad():\n",
        "        for image_path in tqdm(image_paths, desc=\"Extracting Features\"):\n",
        "            if os.path.exists(image_path):\n",
        "                image_tensor = load_and_preprocess_image(image_path, device)\n",
        "                feature_vector = feature_extractor(image_tensor).squeeze().cpu().numpy()\n",
        "                features.append(feature_vector)\n",
        "            else:\n",
        "                print(f\"File not found: {image_path}\")\n",
        "    return np.array(features)\n",
        "\n",
        "# 엑셀 파일에서 데이터 추출 함수\n",
        "def extract_preferences_from_excel(file_path):\n",
        "    preferences_dict = {}\n",
        "    preferences_df = pd.read_excel(file_path)\n",
        "\n",
        "    for idx, row in preferences_df.iterrows():\n",
        "        respondent_id = row['Respondent ID']\n",
        "        training_preferred = row['Training Style Preferred']\n",
        "        training_not_preferred = row['Training Style Not Preferred']\n",
        "        validation_preferred = row['Validation Style Preferred']\n",
        "        validation_not_preferred = row['Validation Style Not Preferred']\n",
        "\n",
        "        training_preferred_list = training_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_preferred) else []\n",
        "        training_not_preferred_list = training_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(training_not_preferred) else []\n",
        "        validation_preferred_list = validation_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_preferred) else []\n",
        "        validation_not_preferred_list = validation_not_preferred.strip(\"[]\").replace(\"'\", \"\").split(\", \") if pd.notna(validation_not_preferred) else []\n",
        "\n",
        "        preferences_dict[respondent_id] = {\n",
        "            'training_preferred': training_preferred_list,\n",
        "            'training_not_preferred': training_not_preferred_list,\n",
        "            'validation_preferred': validation_preferred_list,\n",
        "            'validation_not_preferred': validation_not_preferred_list\n",
        "        }\n",
        "\n",
        "    return preferences_dict\n",
        "\n",
        "# ResNet 특징 추출기 초기화 및 가중치 로드\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "feature_extractor = ResNetFeatureExtractor(model_path).to(device)\n",
        "\n",
        "# 엑셀 파일에서 선호 및 비선호 이미지 리스트 추출\n",
        "preferences_dict = extract_preferences_from_excel(excel_file_path)\n",
        "\n",
        "# Training Style Preferred 리스트 추출\n",
        "train_style = []\n",
        "for respondent_id, prefs in preferences_dict.items():\n",
        "    train_style.extend(prefs['training_preferred'])\n",
        "\n",
        "# Validation Style Preferred 및 Not Preferred 리스트 추출 및 스타일 선호도 할당\n",
        "val_style = []\n",
        "val_labels = []  # 검증 레이블 리스트 초기화\n",
        "for respondent_id, prefs in preferences_dict.items():\n",
        "    val_style.extend(prefs['validation_preferred'])\n",
        "    val_style.extend(prefs['validation_not_preferred'])\n",
        "    val_labels.extend([1] * len(prefs['validation_preferred']))\n",
        "    val_labels.extend([0] * len(prefs['validation_not_preferred']))\n",
        "\n",
        "# 이미지 경로로 변환\n",
        "train_image_paths = [os.path.join(train_image_dir, f\"segmented_{img.strip()}\") for img in train_style]\n",
        "val_image_paths = [os.path.join(val_image_dir, f\"segmented_{img.strip()}\") for img in val_style]\n",
        "\n",
        "# 학습 및 검증 이미지의 특징 벡터 추출\n",
        "train_features = extract_features_for_dataset(train_image_paths, feature_extractor, device)\n",
        "val_features = extract_features_for_dataset(val_image_paths, feature_extractor, device)\n",
        "\n",
        "# 유사도 계산 함수\n",
        "def calculate_cosine_similarity_gpu(val_features, train_features):\n",
        "    val_features = torch.tensor(val_features).to(device)\n",
        "    train_features = torch.tensor(train_features).to(device)\n",
        "    val_features = val_features.view(val_features.size(0), -1)\n",
        "    train_features = train_features.view(train_features.size(0), -1)\n",
        "    val_norm = val_features / val_features.norm(dim=1, keepdim=True)\n",
        "    train_norm = train_features / train_features.norm(dim=1, keepdim=True)\n",
        "    similarity_scores = torch.mm(val_norm, train_norm.T).cpu().numpy()\n",
        "    return similarity_scores\n",
        "\n",
        "# 스타일 선호도 예측\n",
        "similarity_scores = calculate_cosine_similarity_gpu(val_features, train_features)\n",
        "train_preferences = [1] * len(train_features)\n",
        "\n",
        "# 최적 alpha 찾기\n",
        "def find_optimal_alpha(cosine_similarity, train_preferences, val_labels):\n",
        "    best_alpha, best_f1 = 0.5, 0\n",
        "    for alpha in np.arange(0.1, 1.0, 0.1):\n",
        "        predicted_preferences = predict_style_preference(cosine_similarity * alpha, train_preferences)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_alpha = f1, alpha\n",
        "    return best_alpha\n",
        "\n",
        "# 최적 threshold 찾기\n",
        "def find_optimal_threshold(similarity_scores, train_preferences, val_labels):\n",
        "    best_threshold, best_f1 = 0.5, 0\n",
        "    for threshold in np.arange(0.1, 0.9, 0.01):\n",
        "        predicted_preferences = predict_style_preference(similarity_scores, train_preferences, threshold)\n",
        "        _, _, _, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "        if f1 > best_f1:\n",
        "            best_f1, best_threshold = f1, threshold\n",
        "    return best_threshold\n",
        "\n",
        "# 스타일 선호도 예측\n",
        "def predict_style_preference(similarity_scores, train_preferences, threshold=0.5):\n",
        "    predicted_preferences = []\n",
        "    for score_row in similarity_scores:\n",
        "        max_similarity = np.max(score_row)\n",
        "        predicted_label = train_preferences[np.argmax(score_row)] if max_similarity > threshold else 0\n",
        "        predicted_preferences.append(predicted_label)\n",
        "    return predicted_preferences\n",
        "\n",
        "# 성능 평가 함수\n",
        "def calculate_metrics(predicted, actual):\n",
        "    accuracy = accuracy_score(actual, predicted) * 100\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(actual, predicted, average='weighted', zero_division=0)\n",
        "    return accuracy, precision * 100, recall * 100, f1 * 100\n",
        "\n",
        "# 최적 alpha 및 threshold 찾기 및 성능 평가\n",
        "optimal_alpha = find_optimal_alpha(similarity_scores, train_preferences, val_labels)\n",
        "optimal_threshold = find_optimal_threshold(similarity_scores * optimal_alpha, train_preferences, val_labels)\n",
        "predicted_preferences = predict_style_preference(similarity_scores * optimal_alpha, train_preferences, optimal_threshold)\n",
        "\n",
        "accuracy, precision, recall, f1 = calculate_metrics(predicted_preferences, val_labels)\n",
        "print(f\"Optimal Threshold: {optimal_threshold:.2f}, Optimal Alpha: {optimal_alpha:.2f}\")\n",
        "print(f\"Final Prediction Accuracy: {accuracy:.2f}%\")\n",
        "print(f\"Final Precision: {precision:.2f}%\")\n",
        "print(f\"Final Recall: {recall:.2f}%\")\n",
        "print(f\"Final F1-Score: {f1:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tS4Onrjda2D1",
        "outputId": "ca75226b-9c38-4265-8afc-da3c086c0671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-18-f51310dcd5c8>:22: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path)\n",
            "Extracting Features: 100%|██████████| 674/674 [00:04<00:00, 147.01it/s]\n",
            "Extracting Features: 100%|██████████| 1102/1102 [00:07<00:00, 143.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal Threshold: 0.50, Optimal Alpha: 0.50\n",
            "Final Prediction Accuracy: 64.61%\n",
            "Final Precision: 72.33%\n",
            "Final Recall: 64.61%\n",
            "Final F1-Score: 55.75%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 예측 결과와 실제 레이블 샘플링 함수\n",
        "def sample_predictions(predicted, actual, val_image_paths, sample_size=10):\n",
        "    samples = random.sample(range(len(predicted)), sample_size)  # 샘플링할 인덱스 선택\n",
        "    print(\"\\nSample Prediction Results (Predicted vs. Actual):\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    for i in samples:\n",
        "        image_path = val_image_paths[i]\n",
        "        print(f\"Image: {image_path.split('/')[-1]}\")\n",
        "        print(f\"Predicted: {predicted[i]}, Actual: {actual[i]}\")\n",
        "        print(\"--------------------------------------------------\")\n",
        "\n",
        "# 예측 결과 샘플링하여 출력\n",
        "sample_predictions(predicted_preferences, val_labels, val_image_paths, sample_size=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNbOrLyuiAzN",
        "outputId": "dd9ef8f7-8fc9-46c8-a981-e6eede2cf883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Prediction Results (Predicted vs. Actual):\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_15766_00_metrosexual_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_03587_10_sportivecasual_W.jpg\n",
            "Predicted: 1, Actual: 1\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_27854_50_ivy_M.jpg\n",
            "Predicted: 1, Actual: 1\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_38656_10_sportivecasual_W.jpg\n",
            "Predicted: 0, Actual: 1\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_02394_10_sportivecasual_W.jpg\n",
            "Predicted: 0, Actual: 1\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_60184_10_sportivecasual_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_32800_60_mods_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_15998_80_bold_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_03732_10_sportivecasual_W.jpg\n",
            "Predicted: 0, Actual: 1\n",
            "--------------------------------------------------\n",
            "Image: segmented_W_09551_00_cityglam_W.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# 각 이미지 경로에 맞는 Respondent ID 리스트 생성\n",
        "val_respondent_ids = []\n",
        "for respondent_id, prefs in preferences_dict.items():\n",
        "    val_respondent_ids.extend([respondent_id] * (len(prefs['validation_preferred']) + len(prefs['validation_not_preferred'])))\n",
        "\n",
        "# 예측 결과와 실제 레이블 샘플링 함수 (유저 ID 포함)\n",
        "def sample_predictions(predicted, actual, val_image_paths, respondent_ids, sample_size=10):\n",
        "    samples = random.sample(range(len(predicted)), sample_size)  # 샘플링할 인덱스 선택\n",
        "    print(\"\\nSample Prediction Results (Predicted vs. Actual):\")\n",
        "    print(\"--------------------------------------------------\")\n",
        "\n",
        "    for i in samples:\n",
        "        image_path = val_image_paths[i]\n",
        "        respondent_id = respondent_ids[i]\n",
        "        print(f\"Respondent ID: {respondent_id}\")\n",
        "        print(f\"Image: {image_path.split('/')[-1]}\")\n",
        "        print(f\"Predicted: {predicted[i]}, Actual: {actual[i]}\")\n",
        "        print(\"--------------------------------------------------\")\n",
        "\n",
        "# 예측 결과 샘플링하여 출력\n",
        "sample_predictions(predicted_preferences, val_labels, val_image_paths, val_respondent_ids, sample_size=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w0PecraFlqhY",
        "outputId": "86b392c6-135c-4276-bb31-d40c1511c1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Prediction Results (Predicted vs. Actual):\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63207\n",
            "Image: segmented_W_17135_00_metrosexual_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63910\n",
            "Image: segmented_W_16851_10_sportivecasual_M.jpg\n",
            "Predicted: 0, Actual: 1\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63748\n",
            "Image: segmented_W_11144_00_metrosexual_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63424\n",
            "Image: segmented_W_13533_19_normcore_W.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63481\n",
            "Image: segmented_W_06867_60_mods_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Respondent ID: 59704\n",
            "Image: segmented_W_19833_50_ivy_M.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63424\n",
            "Image: segmented_W_03717_10_athleisure_W.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Respondent ID: 9096\n",
            "Image: segmented_W_05941_60_popart_W.jpg\n",
            "Predicted: 0, Actual: 0\n",
            "--------------------------------------------------\n",
            "Respondent ID: 63392\n",
            "Image: segmented_W_15370_50_ivy_M.jpg\n",
            "Predicted: 1, Actual: 1\n",
            "--------------------------------------------------\n",
            "Respondent ID: 64295\n",
            "Image: segmented_W_27750_60_mods_M.jpg\n",
            "Predicted: 0, Actual: 1\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}
